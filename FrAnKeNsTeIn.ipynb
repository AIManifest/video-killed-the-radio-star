{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIManifest/video-killed-the-radio-star/blob/main/FrAnKeNsTeIn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgXxoDhMAiti"
      },
      "source": [
        "# $ \\text{Video Killed The Radio Star}$ $\\color{green}{...FrAnKeNsTeInfusion}$\n",
        "\n",
        "All rights and licences belong to their respective owners, I am simply sharing this notebook for fun use!\n",
        "\n",
        "This notebook contains a bunch of code, tools, libraries, and functions all pertinent to AI and AI Art Animations, and some customizations by me. Again, all RIGHTS belong to their RESPECTIVE OWNERS. But the way I set this notebook up dominantly caters to AI Animations for music videos. You'll see the order of cells start with VKTRS which transcribes youtube vids or audio to text and then animates images based off of that. Scroll all the way to the bottom or open up the `DigThatData is a Master` cell for more info on how to run it. Generally, you'd run this cell from top to bottom, but NEVER RUN ALL CELLS. Lol there's way too many moving parts in here to run all and I've even implement multiple `disconnect runtime` cells just to be sure those precious colab units aren't wasted. If you're unsure about how to use the notebook, just message me and we'll figure it out together! I'm having a blast using this notebook. Hope you do too!\n",
        "\n",
        "Start here to input your Youtube video/audio through Whisper from OpenAI!\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MOUNT COLAB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Grh7PwKlQSba",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "m2ZZ33VY1yxa"
      },
      "outputs": [],
      "source": [
        "# @title ## DigThatData is a Master\n",
        "\n",
        "##########################################################################################################################################################################################################################################################################################################################################################################################\n",
        "# \"\"\"\n",
        "# Notebook by David Marx ([@DigThatData](https://twitter.com/digthatdata))\n",
        "\n",
        "# Shared under MIT license\n",
        "\n",
        "\n",
        "# # $\\text{FAQ}$\n",
        "\n",
        "# **What is this?**\n",
        "\n",
        "# Point this notebook at a youtube url and it'll make a music video for you.\n",
        "\n",
        "# **How does this animation technique work?**\n",
        "\n",
        "# For each text prompt you provide, the notebook will...\n",
        "\n",
        "# 1. Generate an image based on that text prompt (using stable diffusion)\n",
        "# 2. Use the generated image as the `init_image` to recombine with the text prompt to generate variations similar to the first image. This produces a sequence of extremely similar images based on the original text prompt\n",
        "# 3. Images are then intelligently reordered to find the smoothest animation sequence of those frames\n",
        "# 3. This image sequence is then repeated to pad out the animation duration as needed\n",
        "\n",
        "# The technique demonstrated in this notebook was inspired by a [video](https://www.youtube.com/watch?v=WJaxFbdjm8c) created by Ben Gillin.\n",
        "\n",
        "# **How are lyrics transcribed?**\n",
        "\n",
        "# This notebook uses openai's recently released 'whisper' model for performing automatic speech recognition. \n",
        "# OpenAI was kind enough to offer several different sizes of this model which each have their own pros and cons. \n",
        "# This notebook uses the largest whisper model for transcribing the actual lyrics. Additionally, we use the \n",
        "# smallest model for performing the lyric segmentation. Neither of these models is perfect, but the results \n",
        "# so far seem pretty decent.\n",
        "\n",
        "# The first draft of this notebook relied on subtitles from youtube videos to determine timing, which was\n",
        "# then aligned with user-provided lyrics. Youtube's automated captions are powerful and I'll update the\n",
        "# notebook shortly to leverage those again, but for the time being we're just using whisper for everything\n",
        "# and not referencing user-provided captions at all.\n",
        "\n",
        "# **Something didn't work quite right in the transcription process. How do fix the timing or the actual lyrics?**\n",
        "\n",
        "# The notebook is divided into several steps. Between each step, a \"storyboard\" file is updated. If you want to\n",
        "# make modifications, you can edit this file directly and those edits should be reflected when you next load the\n",
        "# file. Depending on what you changed and what step you run next, your changes may be ignored or even overwritten.\n",
        "# Still playing with different solutions here.\n",
        "\n",
        "# **Can I provide my own images to 'bring to life' and associate with certain lyrics/sequences?**\n",
        "\n",
        "# Yes, you can! As described above: you just need to modify the storyboard. Will describe this functionality in\n",
        "# greater detail after the implementation stabilizes a bit more.\n",
        "\n",
        "# **This gave me an idea and I'd like to use just a part of your process here. What's the best way to reuse just some of the machinery you've developed here?**\n",
        "\n",
        "# Most of the functionality in this notebook has been offloaded to library I published to pypi called `vktrs`. I strongly encourage you to import anything you need \n",
        "# from there rather than cutting and pasting function into a notebook. Similarly, if you have ideas for improvements, please don't hesitate to submit a PR!\n",
        "\n",
        "# **How can I support your work or work like it?**\n",
        "\n",
        "# This notebook was made possible thanks to ongoing support from [stability.ai](https://stability.ai/). The best way to support my work is to share it with your friends, [report bugs](https://github.com/dmarx/video-killed-the-radio-star/issues/new), [suggest features](https://github.com/dmarx/video-killed-the-radio-star/discussions) or to donate to open source non-profits :) \n",
        "\n",
        "# \"\"\"\n",
        "##########################################################################################################################################################################################################################################################################################################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM147HP4kAdY"
      },
      "source": [
        "## $0.$ Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_wjIBqEs1PJ"
      },
      "source": [
        "vktrs location /usr/local/lib/python3.7/dist-packages/vktrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZnTe8clZuZuj"
      },
      "outputs": [],
      "source": [
        "# @title # 📊 Check GPU Status\n",
        "\n",
        "try:\n",
        "    from vktrs.utils import gpu_info\n",
        "except:\n",
        "    import pandas as pd\n",
        "    import subprocess\n",
        "    \n",
        "    def gpu_info():\n",
        "        outv = subprocess.run([\n",
        "            'nvidia-smi',\n",
        "                # these lines concatenate into a single query string\n",
        "                '--query-gpu='\n",
        "                'timestamp,'\n",
        "                'name,'\n",
        "                'utilization.gpu,'\n",
        "                'utilization.memory,'\n",
        "                'memory.used,'\n",
        "                'memory.free,'\n",
        "                ,\n",
        "            '--format=csv'\n",
        "            ],\n",
        "            stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "\n",
        "        header, rec = outv.split('\\n')[:-1]\n",
        "        return pd.DataFrame({' '.join(k.strip().split('.')).capitalize():v for k,v in zip(header.split(','), rec.split(','))}, index=[0]).T\n",
        "\n",
        "gpu_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPbeyWtesAoh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title # 🛠️ Installations\n",
        "!pip install vktrs[api,hf]\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper\n",
        "\n",
        "# these are only needed for hf\n",
        "!pip install \"ipywidgets>=7,<8\"\n",
        "!sudo apt -qq install git-lfs\n",
        "!git config --global credential.helper store\n",
        "\n",
        "!pip install panel prefetch_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cM8cux9b7F4v"
      },
      "outputs": [],
      "source": [
        "# @title # 🔑 Provide your API Key\n",
        "# @markdown Running this cell will prompt you to enter your API Key below. \n",
        "\n",
        "# @markdown To get your API key, visit https://beta.dreamstudio.ai/membership\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown A note on security best practices: **don't publish your API key.**\n",
        "\n",
        "# @markdown We're using a form field designed for sensitive data like passwords.\n",
        "# @markdown This notebook does not save your API key in the notebook itself,\n",
        "# @markdown but instead loads your API Key into the colab environment. This way,\n",
        "# @markdown you can make changes to this notebook and share it without concern\n",
        "# @markdown that you might accidentally share your API Key. \n",
        "# @markdown \n",
        "\n",
        "use_stability_api = False # @param {type:'boolean'}\n",
        "mount_gdrive = True # @param {type:'boolean'}\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "\n",
        "os.environ['XDG_CACHE_HOME'] = os.environ.get(\n",
        "    'XDG_CACHE_HOME',\n",
        "    str(Path('~/.cache').expanduser())\n",
        ")\n",
        "if mount_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    Path('/content/drive/MyDrive/AI/models/.cache/').mkdir(parents=True, exist_ok=True)\n",
        "    # This rm+ln solution is not great. Be careful not to run this locally. \n",
        "    # Low risk, but could be annoying    \n",
        "    !rm -rf /root/.cache\n",
        "    !ln -sf /content/drive/MyDrive/AI/models/.cache/ /root/\n",
        "    # Following line will be sufficient pending merge of https://github.com/openai/whisper/pull/257\n",
        "    os.environ['XDG_CACHE_HOME']='/content/drive/MyDrive/AI/models/.cache'\n",
        "\n",
        "vktrs_model = False # @param {type: 'boolean'}\n",
        "\n",
        "if vktrs_model:\n",
        "  model_dir_str=str(Path(os.environ['XDG_CACHE_HOME'])) \n",
        "  proj_root_str = '${active_project}'\n",
        "  if mount_gdrive:\n",
        "    proj_root_str = '/content/drive/MyDrive/AI/VideoKilledTheRadioStar/${active_project}'\n",
        "\n",
        "else:\n",
        "  model_dir_str='runwayml/stable-diffusion-v1-5' # ['str(Path(os.environ['XDG_CACHE_HOME']))', 'str(Path(os.environ['v1-5-pruned']))'] @param {type: 'string'}\n",
        "  proj_root_str = '${active_project}'\n",
        "  if mount_gdrive:\n",
        "    proj_root_str = '/content/drive/MyDrive/AI/VideoKilledTheRadioStar/${active_project}'\n",
        "\n",
        "# notebook config\n",
        "cfg = OmegaConf.create({\n",
        "    'active_project':str(time.time()),\n",
        "    'project_root':proj_root_str,\n",
        "    'gdrive_mounted':mount_gdrive,\n",
        "    'use_stability_api':use_stability_api,\n",
        "    'model_dir':model_dir_str,\n",
        "    'output_dir':'${active_project}/frames'\n",
        "})\n",
        "\n",
        "with open('config.yaml','w') as fp:\n",
        "    OmegaConf.save(config=cfg, f=fp.name)\n",
        "\n",
        "###################\n",
        "\n",
        "if use_stability_api:\n",
        "    import os, getpass\n",
        "    os.environ['STABILITY_KEY'] = getpass.getpass('Enter your API Key')\n",
        "else:\n",
        "    try:\n",
        "        from google.colab import output\n",
        "        output.enable_custom_widget_manager()\n",
        "    except ImportError:\n",
        "        # assume local use\n",
        "        pass\n",
        "    \n",
        "    from huggingface_hub import notebook_login\n",
        "\n",
        "    # to do: if gdrive mounted, check for API token... somewhere on drive?\n",
        "    # looks like we should be able to find the token through an environment variable\n",
        "    notebook_login()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt9Mu97fk_bp"
      },
      "source": [
        "## $1.$ 📋 Set Project Name (create/resume)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "s-9xjgy0iHhS"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "from vktrs.utils import sanitize_folder_name\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "project_name = 'wellerman' # @param {type:'string'}\n",
        "if not project_name:\n",
        "    project_name = str(time.time())\n",
        "\n",
        "project_name = sanitize_folder_name(project_name)\n",
        "\n",
        "workspace = OmegaConf.load('config.yaml')\n",
        "workspace.active_project = project_name\n",
        "\n",
        "with open('config.yaml','w') as fp:\n",
        "    OmegaConf.save(config=workspace, f=fp.name)\n",
        "\n",
        "    print(f\"(Saved to {project_name})\")\n",
        "# @markdown To create a new project, enter a unique project name.\n",
        "# @markdown If you leave `project_name` blank, the current unix timestamp will be used\n",
        "# @markdown  (seconds since 1970-01-01 00:00).\n",
        "\n",
        "# @markdown If you use the name of an existing project, the workspace will switch to that project.\n",
        "\n",
        "# @markdown Non-alphanumeric characters (excluding '-' and '_') will be replaced with hyphens.\n",
        "\n",
        "\n",
        "# reset workspace\n",
        "if 'df' in locals():\n",
        "    del df\n",
        "if 'df_regen' in locals():\n",
        "    del df_regen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eTPNhcBomtL"
      },
      "source": [
        "## $2.$ 🔊 Infer speech from audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9zT0u4-q_fMF"
      },
      "outputs": [],
      "source": [
        "from omegaconf import OmegaConf\n",
        "from pathlib import Path\n",
        "\n",
        "workspace = OmegaConf.load('config.yaml')\n",
        "use_stability_api = workspace.use_stability_api\n",
        "model_dir = workspace.model_dir\n",
        "\n",
        "root = workspace.project_root\n",
        "root = Path(root)\n",
        "root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "import copy\n",
        "import datetime as dt\n",
        "import gc\n",
        "from itertools import chain, cycle\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from subprocess import Popen, PIPE\n",
        "import textwrap\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import panel as pn\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "import tokenizations\n",
        "import webvtt\n",
        "import whisper\n",
        "\n",
        "from vktrs.utils import remove_punctuation\n",
        "from vktrs.utils import get_audio_duration_seconds\n",
        "from vktrs.youtube import (\n",
        "    YoutubeHelper,\n",
        "    parse_timestamp,\n",
        "    vtt_to_token_timestamps,\n",
        "    srv2_to_token_timestamps,\n",
        ")\n",
        "\n",
        "storyboard = OmegaConf.create()\n",
        "\n",
        "d_ = dict(\n",
        "    # all this does is make it so each of the following lines can be preceded with a comma\n",
        "    # otw the first parameter would be offset from the other in the colab form\n",
        "    _=\"\"\n",
        "\n",
        "    , video_url = 'https://www.youtube.com/watch?v=bNQSMTNSnUw' # @param {type:'string'}\n",
        "    , audio_fpath = '' # @param {type:'string'}\n",
        "    , whisper_seg = True # @param {type:'boolean'}\n",
        ")\n",
        "d_.pop('_')\n",
        "storyboard.params = d_\n",
        "\n",
        "if not storyboard.params.audio_fpath:\n",
        "    storyboard.params.audio_fpath = None\n",
        "\n",
        "\n",
        "#@markdown `video_url` - URL of a youtube video to download as a source for audio and potentially for text transcription as well.\n",
        "\n",
        "#@markdown `audio_fpath` - Optionally provide an audio file instead of relying on a youtube download. Name it something other than 'audio.mp3', \n",
        "#@markdown                 otherwise it might get overwritten accidentally.\n",
        "\n",
        "#@markdown `whisper_seg` - Whether or not to use openai's whisper model for lyric segmentation. This is currently the only option, but that will change in a few days.\n",
        "\n",
        "\n",
        "storyboard_fname = root / 'storyboard.yaml'\n",
        "with open(storyboard_fname,'wb') as fp:\n",
        "    OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "\n",
        "###############################\n",
        "# Download audio from youtube #\n",
        "###############################\n",
        "\n",
        "video_url = storyboard.params.video_url\n",
        "\n",
        "if video_url:\n",
        "    # check if user provided an audio filepath (or we already have one from youtube) before attempting to download\n",
        "    if storyboard.params.get('audio_fpath') is None:\n",
        "        helper = YoutubeHelper(\n",
        "            video_url,\n",
        "            ydl_opts = {\n",
        "                'outtmpl':{'default':str( root / f\"ytdlp_content.%(ext)s\" )},\n",
        "                'writeautomaticsub':True,\n",
        "                'subtitlesformat':'srv2/vtt'\n",
        "                },\n",
        "        )\n",
        "\n",
        "        # estimate video end\n",
        "        video_duration = dt.timedelta(seconds=helper.info['duration'])\n",
        "        storyboard.params['video_duration'] = video_duration.total_seconds()\n",
        "\n",
        "        audio_fpath = str( root / 'audio.mp3' )\n",
        "        input_audio = helper.info['requested_downloads'][-1]['filepath']\n",
        "        !ffmpeg -y -i \"{input_audio}\" -acodec libmp3lame {audio_fpath}\n",
        "\n",
        "        # to do: write audio and subtitle paths/meta to storyboard\n",
        "        storyboard.params.audio_fpath = audio_fpath\n",
        "\n",
        "        if False:\n",
        "            subtitle_format = helper.info['requested_subtitles']['en']['ext']\n",
        "            subtitle_fpath = helper.info['requested_subtitles']['en']['filepath']\n",
        "\n",
        "            if subtitle_format == 'srv2':\n",
        "                with open(subtitle_fpath, 'r') as f:\n",
        "                    srv2_xml = f.read() \n",
        "                token_start_times = srv2_to_token_timestamps(srv2_xml)\n",
        "                # to do: handle timedeltas...\n",
        "                #storyboard.params.token_start_times = token_start_times\n",
        "\n",
        "            elif subtitle_format == 'vtt':\n",
        "                captions = webvtt.read(subtitle_fpath)\n",
        "                token_start_times = vtt_to_token_timestamps(captions)\n",
        "                # to do: handle timedeltas...\n",
        "                #storyboard.params.token_start_times = token_start_times\n",
        "\n",
        "            # If unable to download supported subtitles, force use whisper\n",
        "            else:\n",
        "                storyboard.params.whisper_seg = True\n",
        "\n",
        "\n",
        "# estimate video end\n",
        "if storyboard.params.get('video_duration') is None:\n",
        "    # estimate duration from audio file\n",
        "    audio_fpath = storyboard.params['audio_fpath']\n",
        "    storyboard.params['video_duration'] = get_audio_duration_seconds(audio_fpath)\n",
        "\n",
        "if storyboard.params.get('video_duration') is None:\n",
        "    raise RuntimeError('unable to determine audio duration. was a video url or path to a file supplied?')\n",
        "\n",
        "# force use\n",
        "storyboard.params.whisper_seg = True\n",
        "\n",
        "with open(storyboard_fname,'wb') as fp:\n",
        "    OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "whisper_seg = storyboard.params.whisper_seg\n",
        "\n",
        "###################################################\n",
        "# 💬 Transcribe and segment speech using whisper #\n",
        "###################################################\n",
        "\n",
        "# handle OOM... or try to, anyway\n",
        "if 'hf_helper' in locals():\n",
        "    del hf_helper.img2img\n",
        "    del hf_helper.text2img\n",
        "    del hf_helper\n",
        "\n",
        "\n",
        "if whisper_seg:\n",
        "    from vktrs.asr import (\n",
        "        #whisper_lyrics,\n",
        "        #whisper_transcribe,\n",
        "        #whisper_align,\n",
        "        whisper_transmit_meta_across_alignment,\n",
        "        whisper_segment_transcription,\n",
        "    )\n",
        "\n",
        "    #prompt_starts = whisper_lyrics(audio_fpath=storyboard.params.audio_fpath)\n",
        "\n",
        "    audio_fpath = storyboard.params.audio_fpath\n",
        "    #whispers = whisper_transcribe(audio_fpath)\n",
        "\n",
        "    # to do: dropdown selectors\n",
        "    segmentation_model = 'tiny'\n",
        "    transcription_model = 'large'\n",
        "\n",
        "    storyboard.params.whisper = dict(\n",
        "        segmentation_model = segmentation_model\n",
        "        ,transcription_model = transcription_model\n",
        "    )\n",
        "\n",
        "    whispers = {\n",
        "        #'tiny':None, # 5.83 s\n",
        "        #'large':None # 3.73 s\n",
        "    }\n",
        "    # accelerated runtime required for whisper\n",
        "    # to do: pypi package for whisper\n",
        "\n",
        "    # to do: use transcripts we've already built if we have them\n",
        "    #scripts = storyboard.params.whisper.get('transcriptions')\n",
        "    \n",
        "    for k in set([segmentation_model, transcription_model]):\n",
        "        #if k in scripts:\n",
        "\n",
        "        options = whisper.DecodingOptions(\n",
        "            language='en',\n",
        "        )\n",
        "        # to do: be more proactive about cleaning up these models when we're done with them\n",
        "        model = whisper.load_model(k).to('cuda')\n",
        "        start = time.time()\n",
        "        print(f\"Transcribing audio with whisper-{k}\")\n",
        "        \n",
        "        # to do: calling transcribe like this unnecessarily re-processes audio each time.\n",
        "        whispers[k] = model.transcribe(audio_fpath) # re-processes audio each time, ~10s overhead?\n",
        "        print(f\"elapsed: {time.time()-start}\")\n",
        "        del model\n",
        "        gc.collect()\n",
        "    \n",
        "    #######################\n",
        "    # save transcriptions #\n",
        "    #######################\n",
        "\n",
        "    transcriptions = {}\n",
        "    transcription_root = root / 'whispers'\n",
        "    transcription_root.mkdir(parents=True, exist_ok=True)\n",
        "    for k in whispers:\n",
        "        outpath = str( transcription_root / f\"{k}.vtt\" )\n",
        "        transcriptions[k] = outpath\n",
        "        with open(outpath,'w') as f:\n",
        "            # to do: upstream PR to control verbosity\n",
        "            whisper.utils.write_vtt(\n",
        "                whispers[k][\"segments\"], # ...really?\n",
        "                file=f\n",
        "            )\n",
        "    storyboard.params.whisper.transcriptions = transcriptions\n",
        "\n",
        "    #tiny2large, large2tiny, whispers_tokens = whisper_align(whispers)\n",
        "    # sanitize and tokenize\n",
        "    whispers_tokens = {}\n",
        "    for k in whispers:\n",
        "        whispers_tokens[k] = [\n",
        "        remove_punctuation(tok) for tok in whispers[k]['text'].split()\n",
        "        ]\n",
        "\n",
        "    # align sequences\n",
        "    tiny2large, large2tiny = tokenizations.get_alignments(\n",
        "        whispers_tokens[segmentation_model], #whispers_tokens['tiny'],\n",
        "        whispers_tokens[transcription_model] #whispers_tokens['large']\n",
        "    )\n",
        "    #return tiny2large, large2tiny, whispers_tokens\n",
        "\n",
        "    token_large_index_segmentations = whisper_transmit_meta_across_alignment(\n",
        "        whispers,\n",
        "        large2tiny,\n",
        "        whispers_tokens,\n",
        "    )\n",
        "    prompt_starts = whisper_segment_transcription(\n",
        "        token_large_index_segmentations,\n",
        "    )\n",
        "\n",
        "\n",
        "    ### checkpoint the processing work we've done to this point\n",
        "\n",
        "    prompt_starts_copy = copy.deepcopy(prompt_starts)\n",
        "    \n",
        "    # to do: deal with timedeltas in asr.py and yt.py\n",
        "    for rec in prompt_starts_copy:\n",
        "        for k,v in list(rec.items()):\n",
        "            if isinstance(v, dt.timedelta):\n",
        "                rec[k] = v.total_seconds()\n",
        "    \n",
        "    storyboard.prompt_starts = prompt_starts_copy\n",
        "\n",
        "    with open(storyboard_fname) as fp:\n",
        "        OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "##############################\n",
        "#Review/Modify transcription#\n",
        "##############################\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown NB: When this cell finishes running, a table will appear\n",
        "#@markdown at the bottom of the output window. This table is editable\n",
        "#@markdown and can be used to correct errors in the transcription.\n",
        "#@markdown\n",
        "#@markdown additionally, the `override_prompt` field can be used to provide an \n",
        "#@markdown alternative text prompt for image generation. If this feature is\n",
        "#@markdown used, both the lyric and the theme prompt (which you will specify \n",
        "#@markdown in the cell that follows this) will be ignored. If you want to use\n",
        "#@markdown an `override_prompt` and also want to stay on theme, you will have \n",
        "#@markdown to append the desired `theme_prompt` to the end of the \n",
        "#@markdown `override_prompt` manually.\n",
        "\n",
        "\n",
        "# https://panel.holoviz.org/reference/widgets/Tabulator.html\n",
        "\n",
        "pn.extension('tabulator') # I don't know that specifying 'tabulator' here is even necessary...\n",
        "pn.widgets.Tabulator.theme = 'site'\n",
        "\n",
        "tabulator_formatters = {\n",
        "    'bool': {'type': 'tickCross'}\n",
        "}\n",
        "\n",
        "theme_prompt = \"very very detailed, super resolution, cinematic, 4k, 8k, 32k, trending on artstation, very very aesthetic, ultra high quality\"\n",
        "\n",
        "df = pd.DataFrame(prompt_starts).rename(\n",
        "    columns={\n",
        "        'ts':'Timestamp (sec)',\n",
        "        'prompt':'Lyric'\n",
        "    }\n",
        ")\n",
        "df_pre = copy.deepcopy(df)\n",
        "download_df = pn.widgets.Tabulator(df, formatters=tabulator_formatters)\n",
        "\n",
        "filename, button = download_df.download_menu(\n",
        "    text_kwargs={'name': 'Enter filename', 'value': 'default.csv'},\n",
        "    button_kwargs={'name': 'Download table'}\n",
        ")\n",
        "pn.Row(\n",
        "    pn.Column(filename, button),\n",
        "    download_df\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odoRmSLfyQnl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title RUNTIME DISCONNECT\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hvkteG_WB67R"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import datetime as dt\n",
        "from pathlib import Path\n",
        "import random\n",
        "import string\n",
        "\n",
        "from bokeh.models.widgets.tables import (\n",
        "    NumberFormatter, \n",
        "    BooleanFormatter,\n",
        "    CheckboxEditor,\n",
        ")\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf, DictConfig\n",
        "import pandas as pd\n",
        "import panel as pn\n",
        "import PIL\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "from vktrs.tsp import (\n",
        "    tsp_permute_frames,\n",
        "    batched_tsp_permute_frames,\n",
        ")\n",
        "\n",
        "from vktrs.utils import (\n",
        "    add_caption2image,\n",
        "    save_frame,\n",
        "    remove_punctuation,\n",
        "    get_image_sequence,\n",
        "    archive_images,\n",
        ")\n",
        "\n",
        "# to do: is there a way to check if this is in the env already?\n",
        "pn.extension('tabulator')\n",
        "\n",
        "# this processes optional edits to the transcription (above) \n",
        "if ('prompt_starts' in locals()) \\\n",
        "and ('df_pre' in locals()):\n",
        "    if isinstance(prompt_starts, DictConfig):\n",
        "        prompt_starts = OmegaConf.to_container(prompt_starts)\n",
        "    # update prompt_starts if any changes were made above\n",
        "    if not np.all(df_pre.values == df.values):\n",
        "        df_pre = copy.deepcopy(df)\n",
        "        for i, rec in enumerate(prompt_starts):\n",
        "            rec['ts'] = float(df.loc[i,'Timestamp (sec)'])\n",
        "            rec['prompt'] = df.loc[i,'Lyric']\n",
        "            rec['override_prompt'] = df.loc[i,'override_prompt']\n",
        "        \n",
        "        # ...actually, I think the above code might not do anything\n",
        "        # probably need to checkpoint prompt_starts into the storyboard on disk.\n",
        "        # let's do that here just to be safe.    \n",
        "        workspace = OmegaConf.load('config.yaml')\n",
        "        root = Path(workspace.project_root)\n",
        "\n",
        "        storyboard_fname = root / 'storyboard.yaml'\n",
        "        storyboard = OmegaConf.load(storyboard_fname)\n",
        "\n",
        "        storyboard.prompt_starts = prompt_starts\n",
        "        with open(storyboard_fname) as fp:\n",
        "            OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "\n",
        "#####################################\n",
        "# @title ## Run This cell to Define Necessary Params\n",
        "#####################################\n",
        "\n",
        "workspace = OmegaConf.load('config.yaml')\n",
        "root = Path(workspace.project_root)\n",
        "\n",
        "storyboard_fname = root / 'storyboard.yaml'\n",
        "storyboard = OmegaConf.load(storyboard_fname)\n",
        "\n",
        "prompt_starts = storyboard.prompt_starts\n",
        "use_stability_api = workspace.use_stability_api\n",
        "use_custom_model = False # @param {type: 'boolean'}\n",
        "model_dir = workspace.model_dir\n",
        "\n",
        "# if use_stability_api:\n",
        "#     from vktrs.api import get_image_for_prompt\n",
        "\n",
        "# elif use_custom_model:\n",
        "#   model_path='/content/drive/MyDrive/AI/models/v1-5-pruned.ckpt/'\n",
        "\n",
        "# else 'hf_helper' not in locals():\n",
        "#   from vktrs.hf import HfHelper\n",
        "#     # this needs to not be in the same cell as the login.\n",
        "#     # some sort of stupid race condition.\n",
        "#   try:\n",
        "#       hf_helper = HfHelper(\n",
        "#           download=False,\n",
        "#           model_path=str(Path(model_dir) / 'huggingface' / 'diffusers')\n",
        "#       )\n",
        "#   except:\n",
        "#       hf_helper = HfHelper(\n",
        "#           download=True,\n",
        "#           model_path=str(Path(model_dir) / 'huggingface' / 'diffusers')\n",
        "#       )\n",
        "\n",
        "# I give up.\n",
        "#def get_image_for_prompt(*args, **kargs):\n",
        "#        result = hf_helper.get_image_for_prompt(*args, **kargs)\n",
        "#        return result.images\n",
        "\n",
        "\n",
        "#def get_variations_w_init(prompt, init_image, **kargs):\n",
        "#    return list(get_image_for_prompt(prompt=prompt, init_image=init_image, **kargs))\n",
        "\n",
        "#def get_close_variations_from_prompt(prompt, n_variations=2, image_consistency=.7):\n",
        "#    \"\"\"\n",
        "#    prompt: a text prompt\n",
        "#    n_variations: total number of images to return\n",
        "#    image_consistency: float in [0,1], controls similarity between images generated by the prompt.\n",
        "#                        you can think of this as controlling how much \"visual vibration\" there will be.\n",
        "#                        - 0=regenerate each iandely identical\n",
        "#    \"\"\"\n",
        "#   images = list(get_image_for_prompt(prompt))\n",
        "#    for _ in range(n_variations - 1):\n",
        "#        img = get_variations_w_init(prompt, images[0], start_schedule=(1-image_consistency))[0]\n",
        "#        images.append(img)\n",
        "#    return images\n",
        "\n",
        "\n",
        "d_ = dict(\n",
        "    _=''\n",
        "    , theme_prompt = \"lovecraftian horror, ominous settings, very very detailed, 4k, 8k, 32k, trending on artstation, ultra high quality, scary pirate theme\" # @param {type:'string'}\n",
        "    , height = 512 # @param {type:'integer'}\n",
        "    , width = 896 # @param {type:'integer'}\n",
        "    , display_frames_as_we_get_them = False # @param {type:'boolean'}\n",
        ")\n",
        "d_.pop('_')\n",
        "\n",
        "regenerate_all_init_images = False # @param {type:'boolean'}\n",
        "\n",
        "prompt_lag = True # @param {type:'boolean'}\n",
        "\n",
        "# @markdown `theme_prompt` - Text that will be appended to the end of each lyric, useful for e.g. applying a consistent aesthetic style\n",
        "\n",
        "# @markdown `display_frames_as_we_get_them` - Displaying frames will make the notebook slightly slower\n",
        "\n",
        "# regenerate all images if the theme prompt has changed or user specifies\n",
        "\n",
        "# @markdown `prompt_lag` - Extend prompt with lyrics from previous frame. Can improve temporal consistency of narrative. \n",
        "# @markdown  Especially useful for lyrics segmented into short prompts.\n",
        "\n",
        "if d_['theme_prompt'] != storyboard.params.get('theme_prompt'):\n",
        "    regenerate_all_init_images = True\n",
        "\n",
        "storyboard.params.update(d_)\n",
        "\n",
        "# if regenerate_all_init_images:\n",
        "#     for i, rec in enumerate(prompt_starts):\n",
        "#         rec['frame0_fpath'] = None\n",
        "#         archive_images(i, root=root)\n",
        "#     print(\"archival process complete\")\n",
        "\n",
        "# anchor images will be regenerated if there's no associated frame0_fpath\n",
        "# regenerate specific images if\n",
        "# * manually tagged by user in df_regen\n",
        "# * associated fpath doesn't exist (i.e. deleted)\n",
        "# if 'df_regen' in locals():\n",
        "#     for i, _ in df_regen.iterrows():\n",
        "#         rec = prompt_starts[i]\n",
        "#         regen = not _['keep']\n",
        "#         if rec.get('frame0_fpath') is None:\n",
        "#             regen = True\n",
        "#         elif not Path(rec['frame0_fpath']).exists():\n",
        "#             regen=True\n",
        "#         if regen:\n",
        "#             rec['frame0_fpath'] = None\n",
        "#             rec['prompt'] = df_regen.loc[i, 'Lyric']\n",
        "#             rec['override_prompt'] = df_regen.loc[i, 'override_prompt']\n",
        "#             print(rec)\n",
        "#             archive_images(i, root=root)\n",
        "#     print(\"archival process complete\")\n",
        "\n",
        "\n",
        "theme_prompt = storyboard.params.theme_prompt\n",
        "display_frames_as_we_get_them = storyboard.params.display_frames_as_we_get_them\n",
        "height = storyboard.params.height\n",
        "width = storyboard.params.width\n",
        "\n",
        "proj_name = workspace.active_project\n",
        "\n",
        "# print(\"Ensuring each prompt has an associated image\")\n",
        "# for idx, rec in enumerate(prompt_starts):\n",
        "#     lyric = rec['prompt']\n",
        "#     prompt = f\"{lyric}, {theme_prompt}\"\n",
        "#     override = rec.get('override_prompt','').strip()\n",
        "#     if override:\n",
        "#         print('override prompt detected')\n",
        "#         prompt = override\n",
        "#     print(\n",
        "#         f\"\\n[{idx} | {rec['ts']}] - {lyric} - {prompt}\"\n",
        "#     )\n",
        "for idx, rec in enumerate(prompt_starts):\n",
        "  lyric = rec['prompt']\n",
        "prompt = f\"{lyric}, {theme_prompt}\"\n",
        "override = rec.get('override_prompt','').strip()\n",
        "if override:\n",
        "  print('override prompt detected')\n",
        "  prompt = override\n",
        "  print(\n",
        "    f\"\\n[{rec['ts']}] - {lyric} - {prompt}\"\n",
        "  )\n",
        "\n",
        "#     if prompt_lag and (idx > 0):\n",
        "#         rec_prev = prompt_starts[idx -1]\n",
        "#         prev_prompt = rec_prev.get('override_prompt','').strip()\n",
        "#         if not prev_prompt:\n",
        "#             prev_prompt = rec_prev['prompt']\n",
        "#         prompt = f\"{prev_prompt}, {prompt}\"\n",
        "#     if rec.get('frame0_fpath') is None:\n",
        "#         init_image = list(get_image_for_prompt(\n",
        "#               prompt,\n",
        "#               height=height,\n",
        "#               width=width,\n",
        "#               )\n",
        "#           )[0]\n",
        "#     # this shouldn't be necessary, but is a consequence of\n",
        "#     # the globbing thing we're doing atm\n",
        "#     if 'anchor' not in str(rec.get('frame0_fpath')):\n",
        "#         rec['frame0_fpath'] = save_frame(\n",
        "#             init_image,\n",
        "#             idx,\n",
        "#             root_path = root / 'frames',\n",
        "#             name='anchor',\n",
        "#             )\n",
        "\n",
        "#         if display_frames_as_we_get_them:\n",
        "#             print(lyric)\n",
        "#             display(init_image)\n",
        "\n",
        "\n",
        "##############\n",
        "# checkpoint #\n",
        "##############\n",
        "\n",
        "prompt_starts_copy = copy.deepcopy(prompt_starts)\n",
        "storyboard.prompt_starts = prompt_starts_copy\n",
        "\n",
        "with open(storyboard_fname) as fp:\n",
        "    OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "\n",
        "###############\n",
        "# flag regens #\n",
        "###############\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown NB: When this cell finishes running, a table will appear at the bottom of the output window. This table is editable and can be used to correct errors in the transcription (see above).\n",
        "\n",
        "# @markdown Additionally, this table can be used to trigger regeneration of\n",
        "# @markdown images you don't want to keep. On the far left of the table, you\n",
        "# @markdown you should see a `keep` column that defaults to \"true\". Double \n",
        "# @markdown clicking this value should flip it to \"false\". Rerunning this cell\n",
        "# @markdown will regenerate the `init_image` for all scenes where `keep=false`.\n",
        "# @markdown Images that are flagged for regeneration will be moved to the\n",
        "# @markdown project's `archive` folder.\n",
        "\n",
        "# @markdown Image regeneration can also be triggered by deleting the image from \n",
        "# @markdown the `frames` folder.\n",
        "\n",
        "\n",
        "# df_regen = pd.DataFrame(prompt_starts)\n",
        "# if 'override_prompt' not in df_regen:\n",
        "#     df_regen['override_prompt'] = ''\n",
        "\n",
        "# df_regen = df_regen[['ts','prompt','override_prompt']].rename(\n",
        "#     columns={\n",
        "#         'ts':'Timestamp (sec)',\n",
        "#         'prompt':'Lyric',\n",
        "#     }\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "# df_regen['keep'] = True\n",
        "\n",
        "# # move the \"keep\" column to the front\n",
        "# df_regen= df_regen[['keep', 'Timestamp (sec)', 'Lyric', 'override_prompt']]\n",
        "\n",
        "# pn.widgets.Tabulator(\n",
        "#     #df_regen,\n",
        "#     formatters={'bool': BooleanFormatter()},\n",
        "#     editors={'bool':CheckboxEditor()}\n",
        "#     )\n",
        "\n",
        "# print(\n",
        "#     f\"\\n[{rec['ts']}] - {lyric} - {prompt}\"\n",
        "#  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV8RqARZ4UPI"
      },
      "source": [
        "# **Get Your Audio Reactive Keyframes Here, then separate stems using Spleeter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_6Ram1lmc1F"
      },
      "outputs": [],
      "source": [
        "#@title INSTALL SPLEETER\n",
        "!pip install spleeter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "W0LktyMypXqE"
      },
      "outputs": [],
      "source": [
        "#@markdown Split Stems\n",
        "from omegaconf import OmegaConf, DictConfig\n",
        "\n",
        "workspace = OmegaConf.load('config.yaml')\n",
        "root = Path(workspace.project_root)\n",
        "\n",
        "storyboard_fname = root / 'storyboard.yaml'\n",
        "storyboard = OmegaConf.load(storyboard_fname)\n",
        "\n",
        "audio = storyboard.params.audio_fpath\n",
        "\n",
        "!spleeter separate -o audio_output -p spleeter:4stems $audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8fZI9EsAMoD"
      },
      "outputs": [],
      "source": [
        "#@markdown Get your Drums Audio for Keyframes, it'll appear in `/content/`\n",
        "\n",
        "drums = '/content/audio_output/audio/drums.wav'\n",
        "drums_mp3 = '/content/drive/MyDrive/drums.mp3'\n",
        "!ffmpeg -i $drums -y $drums_mp3\n",
        "\n",
        "other = '/content/audio_output/audio/other.wav'\n",
        "other_mp3 = '/content/drive\u0010/MyDrive/other.mp3'\n",
        "!ffmpeg -i $other $other_mp3 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsHRDIhU4o1T"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#ctrl+click>>> https://www.chigozie.co.uk/audio-keyframe-generator/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByGXyiHZWM_q"
      },
      "source": [
        "# **Deforum Stable Diffusion v0.6**\n",
        "[Stable Diffusion](https://github.com/CompVis/stable-diffusion) by Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer and the [Stability.ai](https://stability.ai/) Team. [K Diffusion](https://github.com/crowsonkb/k-diffusion) by [Katherine Crowson](https://twitter.com/RiversHaveWings).\n",
        "\n",
        "[Quick Guide](https://docs.google.com/document/d/1RrQv7FntzOuLg4ohjRZPVL7iptIyBhwwbcEYEW2OfcI/edit?usp=sharing) to Deforum v0.6\n",
        "\n",
        "Notebook by [deforum](https://discord.gg/upmXXsrwZc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IJjzzkKlWM_s"
      },
      "outputs": [],
      "source": [
        "#@markdown **NVIDIA GPU**\n",
        "import subprocess, os, sys\n",
        "sub_p_res = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.free', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(f\"{sub_p_res[:-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA8-efH-WM_t"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0D2HQO-PWM_t"
      },
      "outputs": [],
      "source": [
        "import subprocess, time, gc, os, sys\n",
        "from tqdm.autonotebook import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "clone_to_drive = True # @param{type: 'boolean'}\n",
        "\n",
        "def setup_environment():\n",
        "    start_time = time.time()\n",
        "    print_subprocess = True\n",
        "    use_xformers_for_colab = True\n",
        "    try:\n",
        "        ipy = get_ipython()\n",
        "    except:\n",
        "        ipy = 'could not get_ipython'\n",
        "    if 'google.colab' in str(ipy):\n",
        "        print(\"..setting up environment\")\n",
        "        \n",
        "        all_process = [\n",
        "            ['pip', 'install', 'torch==1.12.1+cu113', 'torchvision==0.13.1+cu113', '--extra-index-url', 'https://download.pytorch.org/whl/cu113'],\n",
        "            ['pip', 'install', 'omegaconf==2.2.3', 'einops==0.4.1', 'pytorch-lightning==1.7.4', 'torchmetrics==0.9.3', 'torchtext==0.13.1', 'transformers==4.21.2', 'kornia==0.6.7'],\n",
        "            ['git', 'clone', '-b', 'dev', 'https://github.com/deforum-art/deforum-stable-diffusion'],\n",
        "            ['pip', 'install', 'accelerate', 'ftfy', 'jsonmerge', 'matplotlib', 'resize-right', 'timm', 'torchdiffeq','scikit-learn','torchsde','open_clip_torch'],\n",
        "        ]\n",
        "        for process in tqdm(all_process):\n",
        "            running = subprocess.run(process,stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            if print_subprocess:\n",
        "                print(running)\n",
        "        with open('deforum-stable-diffusion/src/k_diffusion/__init__.py', 'w') as f:\n",
        "            f.write('')\n",
        "        sys.path.extend([\n",
        "            'deforum-stable-diffusion/',\n",
        "            'deforum-stable-diffusion/src',\n",
        "        ])\n",
        "        if use_xformers_for_colab:\n",
        "\n",
        "            print(\"..installing xformers\")\n",
        "\n",
        "            all_process = [['pip', 'install', 'triton==2.0.0.dev20220701']]\n",
        "            for process in tqdm(all_process):\n",
        "                running = subprocess.run(process,stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "                if print_subprocess:\n",
        "                    print(running)\n",
        "\n",
        "            v_card_name = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            if 't4' in v_card_name.lower():\n",
        "                name_to_download = 'T4'\n",
        "            elif 'v100' in v_card_name.lower():\n",
        "                name_to_download = 'V100'\n",
        "            elif 'a100' in v_card_name.lower():\n",
        "                name_to_download = 'A100'\n",
        "            elif 'p100' in v_card_name.lower():\n",
        "                name_to_download = 'P100'\n",
        "            elif 'a4000' in v_card_name.lower():\n",
        "                name_to_download = 'Non-Colab/Paperspace/A4000'\n",
        "            elif 'p5000' in v_card_name.lower():\n",
        "                name_to_download = 'Non-Colab/Paperspace/P5000'\n",
        "            elif 'quadro m4000' in v_card_name.lower():\n",
        "                name_to_download = 'Non-Colab/Paperspace/Quadro M4000'\n",
        "            elif 'rtx 4000' in v_card_name.lower():\n",
        "                name_to_download = 'Non-Colab/Paperspace/RTX 4000'\n",
        "            elif 'rtx 5000' in v_card_name.lower():\n",
        "                name_to_download = 'Non-Colab/Paperspace/RTX 5000'\n",
        "            else:\n",
        "                print(v_card_name + ' is currently not supported with xformers flash attention in deforum!')\n",
        "\n",
        "            if 'Non-Colab' in name_to_download:\n",
        "                x_ver = 'xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl'\n",
        "            else:\n",
        "                x_ver = 'xformers-0.0.13.dev0-py3-none-any.whl'\n",
        "\n",
        "            x_link = 'https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/' + name_to_download + '/' + x_ver\n",
        "\n",
        "            all_process = [\n",
        "                ['wget', '--no-verbose', '--no-clobber', x_link],\n",
        "                ['pip', 'install', x_ver],\n",
        "                ['cp', 'deforum-stable-diffusion/src/ldm/modules/attention.py', 'deforum-stable-diffusion/src/ldm/modules/attention_backup.py'],\n",
        "                ['cp', 'deforum-stable-diffusion/src/ldm/modules/attention_xformers.py', 'deforum-stable-diffusion/src/ldm/modules/attention.py'],\n",
        "            ]\n",
        "\n",
        "            for process in tqdm(all_process):\n",
        "                running = subprocess.run(process,stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "                if print_subprocess:\n",
        "                    print(running)\n",
        "    else:\n",
        "        sys.path.extend([\n",
        "            'src'\n",
        "        ])\n",
        "    end_time = time.time()\n",
        "    print(f\"..environment set up in {end_time-start_time:.0f} seconds\")\n",
        "    return\n",
        "\n",
        "if clone_to_drive:\n",
        "  %cd '/content/drive/MyDrive'\n",
        "  setup_environment()\n",
        "else:\n",
        "  setup_environment()\n",
        "\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import clip\n",
        "from IPython import display\n",
        "from types import SimpleNamespace\n",
        "from helpers.save_images import get_output_folder\n",
        "from helpers.settings import load_args\n",
        "from helpers.render import render_animation, render_input_video, render_image_batch, render_interpolation\n",
        "from helpers.model_load import make_linear_decode, load_model, get_model_output_paths\n",
        "from helpers.aesthetics import load_aesthetics_model\n",
        "\n",
        "#@markdown **Path Setup**\n",
        "\n",
        "def Root():\n",
        "    models_path = \"models\" #@param {type:\"string\"}\n",
        "    configs_path = \"configs\" #@param {type:\"string\"}\n",
        "    output_path = \"output\" #@param {type:\"string\"}\n",
        "    mount_google_drive = True #@param {type:\"boolean\"}\n",
        "    models_path_gdrive = \"/content/drive/MyDrive/AI/models\" #@param {type:\"string\"}\n",
        "    output_path_gdrive = \"/content/drive/MyDrive/AI/StableDiffusion\" #@param {type:\"string\"}\n",
        "\n",
        "    #@markdown **Model Setup**\n",
        "    model_config = \"v2-inference.yaml\" #@param [\"custom\",\"v2-inference.yaml\",\"v1-inference.yaml\"]\n",
        "    model_checkpoint =  \"512-base-ema.ckpt\" #@param [\"custom\",\"512-base-ema.ckpt\",\"v1-5-pruned.ckpt\",\"v1-5-pruned-emaonly.ckpt\",\"sd-v1-4-full-ema.ckpt\",\"sd-v1-4.ckpt\",\"sd-v1-3-full-ema.ckpt\",\"sd-v1-3.ckpt\",\"sd-v1-2-full-ema.ckpt\",\"sd-v1-2.ckpt\",\"sd-v1-1-full-ema.ckpt\",\"sd-v1-1.ckpt\", \"robo-diffusion-v1.ckpt\",\"wd-v1-3-float16.ckpt\"]\n",
        "    custom_config_path = \"\" #@param {type:\"string\"}\n",
        "    custom_checkpoint_path = \"\" #@param {type:\"string\"}\n",
        "    half_precision = True\n",
        "    return locals()\n",
        "\n",
        "root_to_drive = False # @param{type: 'boolean'}\n",
        "\n",
        "if root_to_drive:\n",
        "  %cd '/content/drive/MyDrive/deforum-stable-diffusion/'\n",
        "  root = Root()\n",
        "  root = SimpleNamespace(**root)\n",
        "\n",
        "  root.models_path, root.output_path = get_model_output_paths(root)\n",
        "  root.model, root.device = load_model(root, \n",
        "                                      load_on_run_all=True\n",
        "                                      , \n",
        "                                      check_sha256=True\n",
        "                                      )\n",
        "  \n",
        "else:\n",
        "  root = Root()\n",
        "  root = SimpleNamespace(**root)\n",
        "\n",
        "  root.models_path, root.output_path = get_model_output_paths(root)\n",
        "  root.model, root.device = load_model(root, \n",
        "                                      load_on_run_all=True\n",
        "                                      , \n",
        "                                      check_sha256=True\n",
        "                                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lVmec0HGKqM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title MAY NEED TO RUN THIS IS K-DIFFUSION IS NOT IN SRC\n",
        "if clone_to_drive:\n",
        "  %cd '/content/drive/MyDrive/deforum-stable-diffusion/src'\n",
        "  !git clone https://github.com/crowsonkb/k-diffusion.git\n",
        "else:\n",
        "  !git clone https://github.com/crowsonkb/k-diffusion.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CHANGE DIRECTORY TO DRIVE\n",
        "%cd '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "38hB8KuYkuJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JxwhBwtWM_t"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E0tJVYA4WM_u"
      },
      "outputs": [],
      "source": [
        "def DeforumAnimArgs():\n",
        "\n",
        "    #@markdown ####**Animation:**\n",
        "    animation_mode = 'Interpolation' #@param ['None', '2D', '3D', 'Video Input', 'Interpolation'] {type:'string'}\n",
        "    max_frames = 300 #@param {type:\"number\"}\n",
        "    border = 'wrap' #@param ['wrap', 'replicate'] {type:'string'}\n",
        "\n",
        "    #@markdown ####**Motion Parameters:**\n",
        "    angle = \"0:(0)\"#@param {type:\"string\"}\n",
        "    zoom = \"0:(1.04)\"#@param {type:\"string\"}\n",
        "    translation_x = \"0:(0)\"#@param {type:\"string\"}\n",
        "    translation_y = \"0:(0)\"#@param {type:\"string\"}\n",
        "    translation_z = \"0: (0.00)\"#@param {type:\"string\"}\n",
        "    rotation_3d_x = \"0:(0)\"#@param {type:\"string\"}\n",
        "    rotation_3d_y = \"0: (0)\"#@param {type:\"string\"}\n",
        "    rotation_3d_z = \"0:(0)\"#@param {type:\"string\"}\n",
        "    flip_2d_perspective = False #@param {type:\"boolean\"}\n",
        "    perspective_flip_theta = \"0:(0)\"#@param {type:\"string\"}\n",
        "    perspective_flip_phi = \"0:(t%15)\"#@param {type:\"string\"}\n",
        "    perspective_flip_gamma = \"0:(0)\"#@param {type:\"string\"}\n",
        "    perspective_flip_fv = \"0:(53)\"#@param {type:\"string\"}\n",
        "    noise_schedule = \"0: (0.03)\"#@param {type:\"string\"}\n",
        "    strength_schedule = \"0: (0.650)\"#@param {type:\"string\"}\n",
        "    contrast_schedule = \"0: (1.0)\"#@param {type:\"string\"}\n",
        "\n",
        "    #@markdown ####**Coherence:**\n",
        "    color_coherence = 'Match Frame 0 LAB' #@param ['None', 'Match Frame 0 HSV', 'Match Frame 0 LAB', 'Match Frame 0 RGB'] {type:'string'}\n",
        "    diffusion_cadence = '6' #@param ['1','2','3','4','5','6','7','8'] {type:'string'}\n",
        "\n",
        "    #@markdown ####**3D Depth Warping:**\n",
        "    use_depth_warping = True #@param {type:\"boolean\"}\n",
        "    midas_weight = 0.3#@param {type:\"number\"}\n",
        "    near_plane = 200\n",
        "    far_plane = 10000\n",
        "    fov = 60#@param {type:\"number\"}\n",
        "    padding_mode = 'border'#@param ['border', 'reflection', 'zeros'] {type:'string'}\n",
        "    sampling_mode = 'bicubic'#@param ['bicubic', 'bilinear', 'nearest'] {type:'string'}\n",
        "    save_depth_maps = False #@param {type:\"boolean\"}\n",
        "\n",
        "    #@markdown ####**Video Input:**\n",
        "    video_init_path =''#@param {type:\"string\"}\n",
        "    extract_nth_frame = 1#@param {type:\"number\"}\n",
        "    overwrite_extracted_frames = True #@param {type:\"boolean\"}\n",
        "    use_mask_video = False #@param {type:\"boolean\"}\n",
        "    video_mask_path =''#@param {type:\"string\"}\n",
        "\n",
        "    #@markdown ####**Interpolation:**\n",
        "    interpolate_key_frames = True #@param {type:\"boolean\"}\n",
        "    interpolate_x_frames = 4 #@param {type:\"number\"}\n",
        "    \n",
        "    #@markdown ####**Resume Animation:**\n",
        "    resume_from_timestring = False #@param {type:\"boolean\"}\n",
        "    resume_timestring = \"20221124193707\" #@param {type:\"string\"}\n",
        "\n",
        "    return locals()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBGWCBZF62K3"
      },
      "outputs": [],
      "source": [
        "#\"@title\",\n",
        "\n",
        "prompts = [\n",
        "    \"a black on black battle spaceship in a cyberpunk city, trending on Artstation, 4K, 8K, 32K, cinematic, ultra detailed, sharp, focused, intricate\", # the first prompt I want\n",
        "    #\"a beautiful portrait of a woman by Artgerm, trending on Artstation\", # the second prompt I want\n",
        "    #\"this prompt I don't want it I commented it out\",\n",
        "    #\"a nousr robot, trending on Artstation\", # use \"nousr robot\" with the robot diffusion model (see model_checkpoint setting)\n",
        "    #\"touhou 1girl komeiji_koishi portrait, green hair\", # waifu diffusion prompts can use danbooru tag groups (see model_checkpoint)\n",
        "    #\"this prompt has weights if prompt weighting enabled:2 can also do negative:-2\", # (see prompt_weighting)\n",
        "]\n",
        "\n",
        "animation_prompts = {\n",
        "\n",
        "0: \"a black on black battle spaceship in a cyberpunk city, trending on Artstation, 4K, 8K, 32K, cinematic, ultra detailed, sharp, focused, intricate\",\n",
        "120: \"a black on black alien armada in a cyberpunk city, trending on Artstation, 4K, 8K, 32K, cinematic, ultra detailed, sharp, focused, intricate\",\n",
        "240: \"a black on black dreadnought in a cyberpunk city, trending on Artstation, 4K, 8K, 32K, cinematic, ultra detailed, sharp, focused, intricate\",\n",
        "\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XVzhbmizWM_u"
      },
      "outputs": [],
      "source": [
        "#@markdown **Load Settings**\n",
        "override_settings_with_file = False #@param {type:\"boolean\"}\n",
        "settings_file = \"custom\" #@param [\"custom\", \"512x512_aesthetic_0.json\",\"512x512_aesthetic_1.json\",\"512x512_colormatch_0.json\",\"512x512_colormatch_1.json\",\"512x512_colormatch_2.json\",\"512x512_colormatch_3.json\"]\n",
        "custom_settings_file = \"/content/drive/MyDrive/Settings.txt\"#@param {type:\"string\"}\n",
        "\n",
        "def DeforumArgs():\n",
        "    #@markdown **Image Settings**\n",
        "    W = 896 #@param\n",
        "    H = 512 #@param\n",
        "    W, H = map(lambda x: x - x % 64, (W, H))  # resize to integer multiple of 64\n",
        "\n",
        "    #@markdown **Sampling Settings**\n",
        "    seed = -1 #@param\n",
        "    sampler = 'dpm2_ancestral' #@param [\"klms\",\"dpm2\",\"dpm2_ancestral\",\"heun\",\"euler\",\"euler_ancestral\",\"plms\", \"ddim\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_a\", \"dpmpp_2m\"]\n",
        "    steps = 80 #@param\n",
        "    scale = 12.5 #@param\n",
        "    ddim_eta = 0.0 #@param\n",
        "    dynamic_threshold = None\n",
        "    static_threshold = None   \n",
        "\n",
        "    #@markdown **Save & Display Settings**\n",
        "    save_samples = True #@param {type:\"boolean\"}\n",
        "    save_settings = True #@param {type:\"boolean\"}\n",
        "    display_samples = True #@param {type:\"boolean\"}\n",
        "    save_sample_per_step = False #@param {type:\"boolean\"}\n",
        "    show_sample_per_step = False #@param {type:\"boolean\"}\n",
        "\n",
        "    #@markdown **Prompt Settings**\n",
        "    prompt_weighting = True #@param {type:\"boolean\"}\n",
        "    normalize_prompt_weights = True #@param {type:\"boolean\"}\n",
        "    log_weighted_subprompts = False #@param {type:\"boolean\"}\n",
        "\n",
        "    #@markdown **Batch Settings**\n",
        "    n_batch = 20 #@param\n",
        "    batch_name = \"dark_cyberpunk\" #@param {type:\"string\"}\n",
        "    filename_format = \"{timestring}_{index}_{prompt}.png\" #@param [\"{timestring}_{index}_{seed}.png\",\"{timestring}_{index}_{prompt}.png\"]\n",
        "    seed_behavior = \"iter\" #@param [\"iter\",\"fixed\",\"random\"]\n",
        "    make_grid = False #@param {type:\"boolean\"}\n",
        "    grid_rows = 2 #@param \n",
        "    outdir = get_output_folder(root.output_path, batch_name)\n",
        "\n",
        "    #@markdown **Init Settings**\n",
        "    use_init = False #@param {type:\"boolean\"}\n",
        "    strength = 0.0 #@param {type:\"number\"}\n",
        "    strength_0_no_init = True # Set the strength to 0 automatically when no init image is used\n",
        "    init_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\" #@param {type:\"string\"}\n",
        "    # Whiter areas of the mask are areas that change more\n",
        "    use_mask = False #@param {type:\"boolean\"}\n",
        "    use_alpha_as_mask = False # use the alpha channel of the init image as the mask\n",
        "    mask_file = \"https://www.filterforge.com/wiki/images/archive/b/b7/20080927223728%21Polygonal_gradient_thumb.jpg\" #@param {type:\"string\"}\n",
        "    invert_mask = False #@param {type:\"boolean\"}\n",
        "    # Adjust mask image, 1.0 is no adjustment. Should be positive numbers.\n",
        "    mask_brightness_adjust = 1.0  #@param {type:\"number\"}\n",
        "    mask_contrast_adjust = 1.0  #@param {type:\"number\"}\n",
        "    # Overlay the masked image at the end of the generation so it does not get degraded by encoding and decoding\n",
        "    overlay_mask = True  # {type:\"boolean\"}\n",
        "    # Blur edges of final overlay mask, if used. Minimum = 0 (no blur)\n",
        "    mask_overlay_blur = 5 # {type:\"number\"}\n",
        "\n",
        "    #@markdown **Exposure/Contrast Conditional Settings**\n",
        "    mean_scale = 0 #@param {type:\"number\"}\n",
        "    var_scale = 0 #@param {type:\"number\"}\n",
        "    exposure_scale = 0 #@param {type:\"number\"}\n",
        "    exposure_target = 0.5 #@param {type:\"number\"}\n",
        "\n",
        "    #@markdown **Color Match Conditional Settings**\n",
        "    colormatch_scale = 0 #@param {type:\"number\"}\n",
        "    colormatch_image = \"https://www.saasdesign.io/wp-content/uploads/2021/02/palette-3-min-980x588.png\" #@param {type:\"string\"}\n",
        "    colormatch_n_colors = 4 #@param {type:\"number\"}\n",
        "    ignore_sat_weight = 0 #@param {type:\"number\"}\n",
        "\n",
        "    #@markdown **CLIP\\Aesthetics Conditional Settings**\n",
        "    clip_name = 'ViT-L/14@336px' #@param ['ViT-L/14', 'ViT-L/14@336px', 'ViT-B/16', 'ViT-B/32']\n",
        "    clip_scale = 1 #@param {type:\"number\"}\n",
        "    aesthetics_scale = 0 #@param {type:\"number\"}\n",
        "    cutn = 2 #@param {type:\"number\"}\n",
        "    cut_pow = 0.0002 #@param {type:\"number\"}\n",
        "\n",
        "    #@markdown **Other Conditional Settings**\n",
        "    init_mse_scale = 0 #@param {type:\"number\"}\n",
        "    init_mse_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\" #@param {type:\"string\"}\n",
        "\n",
        "    blue_scale = 0 #@param {type:\"number\"}\n",
        "    \n",
        "    #@markdown **Conditional Gradient Settings**\n",
        "    gradient_wrt = 'x0_pred' #@param [\"x\", \"x0_pred\"]\n",
        "    gradient_add_to = 'both' #@param [\"cond\", \"uncond\", \"both\"]\n",
        "    decode_method = 'linear' #@param [\"autoencoder\",\"linear\"]\n",
        "    grad_threshold_type = 'dynamic' #@param [\"dynamic\", \"static\", \"mean\", \"schedule\"]\n",
        "    clamp_grad_threshold = 0.2 #@param {type:\"number\"}\n",
        "    clamp_start = 0.2 #@param\n",
        "    clamp_stop = 0.01 #@param\n",
        "    grad_inject_timing = list(range(1,10)) #@param\n",
        "\n",
        "    #@markdown **Speed vs VRAM Settings**\n",
        "    cond_uncond_sync = True #@param {type:\"boolean\"}\n",
        "\n",
        "    n_samples = 1 # doesnt do anything\n",
        "    precision = 'autocast' \n",
        "    C = 4\n",
        "    f = 8\n",
        "\n",
        "    prompt = \"\"\n",
        "    timestring = \"\"\n",
        "    init_latent = None\n",
        "    init_sample = None\n",
        "    init_sample_raw = None\n",
        "    mask_sample = None\n",
        "    init_c = None\n",
        "\n",
        "    return locals()\n",
        "\n",
        "args_dict = DeforumArgs()\n",
        "anim_args_dict = DeforumAnimArgs()\n",
        "\n",
        "if override_settings_with_file:\n",
        "    load_args(args_dict, anim_args_dict, settings_file, custom_settings_file, verbose=False)\n",
        "\n",
        "args = SimpleNamespace(**args_dict)\n",
        "anim_args = SimpleNamespace(**anim_args_dict)\n",
        "\n",
        "args.timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "args.strength = max(0.0, min(1.0, args.strength))\n",
        "\n",
        "# Load clip model if using clip guidance\n",
        "if (args.clip_scale > 0) or (args.aesthetics_scale > 0):\n",
        "    root.clip_model = clip.load(args.clip_name, jit=False)[0].eval().requires_grad_(False).to(root.device)\n",
        "    if (args.aesthetics_scale > 0):\n",
        "        root.aesthetics_model = load_aesthetics_model(args, root)\n",
        "\n",
        "if args.seed == -1:\n",
        "    args.seed = random.randint(0, 2**32 - 1)\n",
        "if not args.use_init:\n",
        "    args.init_image = None\n",
        "if args.sampler == 'plms' and (args.use_init or anim_args.animation_mode != 'None'):\n",
        "    print(f\"Init images aren't supported with PLMS yet, switching to KLMS\")\n",
        "    args.sampler = 'klms'\n",
        "if args.sampler != 'ddim':\n",
        "    args.ddim_eta = 0\n",
        "\n",
        "if anim_args.animation_mode == 'None':\n",
        "    anim_args.max_frames = 1\n",
        "elif anim_args.animation_mode == 'Video Input':\n",
        "    args.use_init = True\n",
        "\n",
        "# clean up unused memory\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(args.timestring)\n",
        "# dispatch to appropriate renderer\n",
        "if anim_args.animation_mode == '2D' or anim_args.animation_mode == '3D':\n",
        "    render_animation(args, anim_args, animation_prompts, root)\n",
        "   \n",
        "elif anim_args.animation_mode == 'Video Input':\n",
        "    render_input_video(args, anim_args, animation_prompts, root)\n",
        "elif anim_args.animation_mode == 'Interpolation':\n",
        "    render_interpolation(args, anim_args, animation_prompts, root)\n",
        "else:\n",
        "    render_image_batch(args, prompts, root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNaJTRjTCy8Y",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title RUN THIS CELL TO PREVIEW THE CURRENT ANIMATION, MAKE SURE TO CHANGE THE NECESSARY ELEMENTS THAT NEED CHANGING\n",
        "%cd '/content/drive/MyDrive/AI/StableDiffusion/2022-11/emmett'\n",
        "!python3 /content/drive/MyDrive/ffprogress/main.py -y -framerate 12 -pattern_type glob -i '*.png' -y \"/content/drive/MyDrive/temp.mp4\" -loglevel trace\n",
        "%cd '/content/'\n",
        "!python3 /content/drive/MyDrive/ffprogress/main.py -i '/content/drive/MyDrive/temp.mp4' -c:v libx264 -rc vbr -cq 21 -pix_fmt yuv420p -b:v 0 '/content/drive/MyDrive/healingjourney.mp4' -loglevel trace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pij4x101gU7H",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title DISCONNECT RUNTIME\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ88kZ2-WM_v"
      },
      "source": [
        "# Create Video From Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XQGeqaGAWM_v"
      },
      "outputs": [],
      "source": [
        "skip_video_for_run_all = True #@param {type: 'boolean'}\n",
        "fps = 12 #@param {type:\"number\"}\n",
        "#@markdown **Manual Settings**\n",
        "use_manual_settings = False #@param {type:\"boolean\"}\n",
        "image_path = \"/content/drive/MyDrive/AI/StableDiffusion/2022-09/20220903000939_%05d.png\" #@param {type:\"string\"}\n",
        "mp4_path = \"/content/drive/MyDrive/AI/StableDiffusion/2022-09/20220903000939.mp4\" #@param {type:\"string\"}\n",
        "render_steps = False  #@param {type: 'boolean'}\n",
        "path_name_modifier = \"x0_pred\" #@param [\"x0_pred\",\"x\"]\n",
        "make_gif = False\n",
        "\n",
        "if skip_video_for_run_all == True:\n",
        "    print('Skipping video creation, uncheck skip_video_for_run_all if you want to run it')\n",
        "else:\n",
        "    import os\n",
        "    import subprocess\n",
        "    from base64 import b64encode\n",
        "\n",
        "    print(f\"{image_path} -> {mp4_path}\")\n",
        "\n",
        "    if use_manual_settings:\n",
        "        max_frames = \"200\" #@param {type:\"string\"}\n",
        "    else:\n",
        "        if render_steps: # render steps from a single image\n",
        "            fname = f\"{path_name_modifier}_%05d.png\"\n",
        "            all_step_dirs = [os.path.join(args.outdir, d) for d in os.listdir(args.outdir) if os.path.isdir(os.path.join(args.outdir,d))]\n",
        "            newest_dir = max(all_step_dirs, key=os.path.getmtime)\n",
        "            image_path = os.path.join(newest_dir, fname)\n",
        "            print(f\"Reading images from {image_path}\")\n",
        "            mp4_path = os.path.join(newest_dir, f\"{args.timestring}_{path_name_modifier}.mp4\")\n",
        "            max_frames = str(args.steps)\n",
        "        else: # render images for a video\n",
        "            image_path = os.path.join(args.outdir, f\"{args.timestring}_%05d.png\")\n",
        "            mp4_path = os.path.join(args.outdir, f\"{args.timestring}.mp4\")\n",
        "            max_frames = str(anim_args.max_frames)\n",
        "\n",
        "    # make video\n",
        "    cmd = [\n",
        "        'ffmpeg',\n",
        "        '-y',\n",
        "        '-vcodec', 'png',\n",
        "        '-r', str(fps),\n",
        "        '-start_number', str(0),\n",
        "        '-i', image_path,\n",
        "        '-frames:v', max_frames,\n",
        "        '-c:v', 'libx264',\n",
        "        '-vf',\n",
        "        f'fps={fps}',\n",
        "        '-pix_fmt', 'yuv420p',\n",
        "        '-crf', '17',\n",
        "        '-preset', 'veryfast',\n",
        "        '-pattern_type', 'sequence',\n",
        "        mp4_path\n",
        "    ]\n",
        "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    stdout, stderr = process.communicate()\n",
        "    if process.returncode != 0:\n",
        "        print(stderr)\n",
        "        raise RuntimeError(stderr)\n",
        "\n",
        "    mp4 = open(mp4_path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display.display(display.HTML(f'<video controls loop><source src=\"{data_url}\" type=\"video/mp4\"></video>') )\n",
        "    \n",
        "    if make_gif:\n",
        "         gif_path = os.path.splitext(mp4_path)[0]+'.gif'\n",
        "         cmd_gif = [\n",
        "             'ffmpeg',\n",
        "             '-y',\n",
        "             '-i', mp4_path,\n",
        "             '-r', str(fps),\n",
        "             gif_path\n",
        "         ]\n",
        "         process_gif = subprocess.Popen(cmd_gif, stdout=subprocess.PIPE, stderr=subprocess.PIPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MMpAcyrYWM_v"
      },
      "outputs": [],
      "source": [
        "skip_disconnect_for_run_all = True #@param {type: 'boolean'}\n",
        "\n",
        "if skip_disconnect_for_run_all == True:\n",
        "    print('Skipping disconnect, uncheck skip_disconnect_for_run_all if you want to run it')\n",
        "else:\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzqhU6rufVr7"
      },
      "source": [
        "# **ANIMATION KIT COMMENCE!** \n",
        "DOWNLOAD ALL THE STUFF! --> All Dependencies and Libraries --> RUN IT\n",
        "\n",
        "All in one upscaler, interpolator, and video compression!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5sx6yhNRfVr-"
      },
      "outputs": [],
      "source": [
        "#@title # Mount Google Drive, Install Libraries, Load Functions{ form-width: \"300px\" }\n",
        "#@markdown *Note: This project has been tested around Google Drive and may not yet support non-Drive configurations.*\n",
        "#https://unix.stackexchange.com/questions/70963/difference-between-2-2-dev-null-dev-null-and-dev-null-21\n",
        "import os, sys, re, gc  #>/dev/null\n",
        "gc.collect()\n",
        "from multiprocessing import Process\n",
        "\n",
        "def Dir_check(a):\n",
        "  import os.path\n",
        "  from os import path\n",
        "  if not path.exists(a):\n",
        "    print(\"ERROR: \"+a+\" does not exist!\")\n",
        "\n",
        "def Dir_make(a):\n",
        "  import os.path\n",
        "  from os import path\n",
        "  if not path.exists(a):\n",
        "    print(\"Creating \"+a+\" ...\")\n",
        "    !mkdir -p $a\n",
        "\n",
        "def File_check(a):\n",
        "  import os.path\n",
        "  from os import path\n",
        "  if not path.isfile(a):\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "\n",
        "# def need_file(a):\n",
        "#   import os.path\n",
        "#   from os import path\n",
        "#   if not path.isfile(a):\n",
        "#     print(\"Creating\"+a+\"...\")\n",
        "#     !mkdir -p $a\n",
        "\n",
        "\n",
        "\n",
        "# def File_check(a):\n",
        "#   import os.path\n",
        "#   from os import path\n",
        "#   if not path.isfile(a):\n",
        "#     print(\"ERROR: \"+a+\" does not exist!\")\n",
        "\n",
        "\n",
        "class AnKit:\n",
        "  #def __init__(self):\n",
        "  #  pass\n",
        "  import os.path\n",
        "  from os import path\n",
        "  #video tools\n",
        "  def video_sortFrames(sourceframes, destframes):  #takes frames from input folder, moves to init_frame_storage\n",
        "    Dir_check(sourceframes)\n",
        "    Dir_make(destframes)\n",
        "    %cd $sourceframes\n",
        "    print(\"Copying frames to \"+destframes+\" for processing...\")\n",
        "    !find -maxdepth 1 -name '*.png' -print0 | xargs -0 cp -t $destframes\n",
        "    %cd $destframes\n",
        "    #!find -maxdepth 1 -name '*.png' -print0 | xargs -0 'mv \"$0\" \"${0##*_}\"' \n",
        "    #!find . -type f -name \"*_*.png\" -execdir bash -c 'mv \"$0\" \"${0##*_}\"' {} \\;  #removes anything not numbers\n",
        "    !find . -type f -name \"*.png\" -execdir bash -c 'mv \"$0\" \"${0##*_}\"' {} \\;  #removes anything not numbers\n",
        "    #print(\"Padding filenames in \"+destframes+\".\")\n",
        "    !rename 's/\\d+/sprintf(\"%05d\",$&)/e' *  #adds padding to numbers\n",
        "    print(\"Finished copying frames to \"+destframes+\".\")\n",
        "  def video_splitFrames(sourcefile, destframes):\n",
        "    File_check(sourcefile)\n",
        "    Dir_make(destframes)\n",
        "    !ffmpeg -y -r 1 -i $sourcefile -r 1 $destframes/frame%05d.png\n",
        "  def frames2video(sourceframes,fps,outputmp4):\n",
        "    Dir_check(sourceframes)\n",
        "    %cd $sourceframes\n",
        "    !ffmpeg -framerate $fps -pattern_type glob -i '*.png' -y $outputmp4\n",
        "    \n",
        "    #!ffmpeg -framerate $fps -pattern_type glob -i '*.png' -vcodec hevc_nvenc -y $outputmp4\n",
        "    #this vcodec doesnt work with a100; nixing for now\n",
        "\n",
        "  def video_runUpscale(esrgan,mname,scale,input,output):\n",
        "    Dir_check(input)\n",
        "    Dir_make(output)\n",
        "    %cd $esrgan\n",
        "    !python inference_realesrgan.py --model_name $mname --input $input --output $output\n",
        "  def RIFE_video(fps,exp,input,scale,output):\n",
        "    %cd /content/Practical-RIFE\n",
        "    !python3 /content/Practical-RIFE/inference_video.py --fps=$fps --exp=$exp --video=$input --scale $scale --output=$output\n",
        "  def RIFE_frames(fps,exp,input,scale,output):  #not currently working right\n",
        "    %cd /content/Practical-RIFE\n",
        "    input = input + '/'\n",
        "    !python3 /content/Practical-RIFE/inference_video.py --fps=$fps --exp=$exp --img=$input --scale $scale --output=$output\n",
        "  def detect_fps(input): #needs portable\n",
        "    import re\n",
        "    fps_ffprobe = !ffprobe -v error -select_streams v -of default=noprint_wrappers=1:nokey=1 -show_entries stream=avg_frame_rate $input\n",
        "    fps_unfinished = [str(i) for i in fps_ffprobe] # Converting integers into strings\n",
        "    fps_unfinishedTwo = str(\"\".join(fps_unfinished)) # Join the string values into one string\n",
        "    numbers = re.findall('[0-9]+', fps_unfinishedTwo)\n",
        "    newNum = numbers[0:1]\n",
        "    strings = [str(integer) for integer in newNum]\n",
        "    a_string = \"\".join(strings)\n",
        "    fps = int(a_string)\n",
        "    #print(\"Detected FPS is\",fps)\n",
        "    return fps\n",
        "  def detect_duration(input):  #needs portable\n",
        "    import re\n",
        "    duration_ffprobe = !ffprobe -v error -select_streams v:0 -show_entries stream=duration -of default=noprint_wrappers=1:nokey=1 $input\n",
        "    duration_unfinished = [str(i) for i in duration_ffprobe] # Converting integers into strings\n",
        "    duration_unfinishedTwo = str(\"\".join(duration_unfinished)) # Join the string values into one string\n",
        "    numbers = re.findall('[0-9]+', duration_unfinishedTwo)\n",
        "    newNum = numbers[0:1]\n",
        "    strings = [str(integer) for integer in newNum]\n",
        "    a_string = \"\".join(strings)\n",
        "    duration = float(int(a_string))\n",
        "    #print(\"Detected duration INTEGER (in seconds) is\",duration)\n",
        "    return duration\n",
        "  def exp_calc(measured_duration,_target_length_seconds): #needs portable\n",
        "    import numpy as np\n",
        "    a = measured_fps * measured_duration\n",
        "    b = _target_fps * _target_length_seconds\n",
        "    c = b / a\n",
        "    l = np.log(c) / np.log(2)\n",
        "    print(\"Un-rounded --exp is\",l)\n",
        "    x = round(l)\n",
        "    if x < 1:\n",
        "      x = 1\n",
        "    print(\"Rounding up to an --exp of \",x)\n",
        "    return x\n",
        "  #installation for Colab (untested on other platforms)\n",
        "  #\n",
        "  #\n",
        "  def install_ESRGAN():\n",
        "    print(\"Installing libraries for Real-ESRGAN upscaling.\")\n",
        "    #!git clone https://github.com/xinntao/Real-ESRGAN.git &> /dev/null #using own fork for longevity\n",
        "    !git clone https://github.com/xinntao/Real-ESRGAN.git Real-ESRGAN &> /dev/null #using own fork for longevity\n",
        "    %cd Real-ESRGAN\n",
        "    !pip -q install basicsr\n",
        "    !pip -q install facexlib\n",
        "    !pip -q install gfpgan\n",
        "    !pip -q install -r requirements.txt   &> /dev/null\n",
        "    !python setup.py develop              &> /dev/null\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models              &> /dev/null\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth -P experiments/pretrained_models   &> /dev/null\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth -P experiments/pretrained_models              &> /dev/null\n",
        "    !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth -P experiments/pretrained_models              &> /dev/null\n",
        "    print(\"Finished Installing libraries for Real-ESRGAN upscaling.\")\n",
        "    #\n",
        "  def install_RIFE():\n",
        "    %cd /content/\n",
        "    print(\"Installing libraries for RIFE motion smoothing.\")\n",
        "    #!git clone https://github.com/hzwer/Practical-RIFE Practical-RIFE &> /dev/null  #using my own archive for longevity\n",
        "    !git clone https://github.com/sadnow/Practical-RIFE_AnimationKit Practical-RIFE &> /dev/null  #using my own archive for longevity\n",
        "    #!gdown --id 1O5KfS3KzZCY3imeCr2LCsntLhutKuAqj &> /dev/null  #DEPRECATED 3.8 MODEL\n",
        "    !gdown --id 1mUK9iON6Es14oK46-cCflRoPTeGiI_A9 &> /dev/null  #NEWER 4.0 MODEL\n",
        "    #!7z e RIFE_trained_model_v3.8.zip &> /dev/null\n",
        "    !7z e RIFE_trained_model_v4.0.zip &> /dev/null\n",
        "    !mkdir /content/Practical-RIFE/train_log  &> /dev/null\n",
        "    !mv *.py /content/Practical-RIFE/train_log/ &> /dev/null\n",
        "    !mv *.pkl /content/Practical-RIFE/train_log/  &> /dev/null\n",
        "    %cd /content/Practical-RIFE/\n",
        "    #!gdown --id 1i3xlKb7ax7Y70khcTcuePi6E7crO_dFc   &> /dev/null  #useless - mp4 demo \n",
        "    !pip3 install -r requirements.txt &> /dev/null\n",
        "    print(\"Finsihed Installing libraries for RIFE motion smoothing.\")\n",
        "    #  \n",
        "    %cd /content/\n",
        "  def depcrecated_installOldRIFE():\n",
        "    print(\"Installing libraries for RIFE motion smoothing.\")\n",
        "    !git clone https://github.com/hzwer/arXiv2020-RIFE RIFE\n",
        "    !gdown --id 1wsQIhHZ3Eg4_AfCXItFKqqyDMB4NS0Yd\n",
        "    !7z e RIFE_trained_model_HDv2.zip\n",
        "    !mkdir /content/RIFE/train_log\n",
        "    !mv *.pkl /content/RIFE/train_log/\n",
        "    %cd /content/RIFE/\n",
        "    !gdown --id 1i3xlKb7ax7Y70khcTcuePi6E7crO_dFc\n",
        "    !pip3 install -r requirements.txt\n",
        "    print(\"Done.\")\n",
        "    print(\"Finsihed Installing libraries for RIFE motion smoothing.\")\n",
        "  %cd /content/\n",
        "  \n",
        "  def install_3dinpainting(): #untested as a function\n",
        "    !pip3 install torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "    !pip3 install opencv-python==4.2.0.32\n",
        "    !pip3 install vispy==0.6.4\n",
        "    !pip3 install moviepy==1.0.2\n",
        "    !pip3 install transforms3d==0.3.1\n",
        "    !pip3 install networkx==2.3\n",
        "    !sudo apt install sed\n",
        "    %cd /content/\n",
        "    !git clone https://github.com/sadnow/3d-photo-inpainting.git\n",
        "    %cd 3d-photo-inpainting\n",
        "    !sh download.sh\n",
        "    !sed -i 's/offscreen_rendering: True/offscreen_rendering: False/g' argument.yml\n",
        "\n",
        "  def run_3dinpainting(): #untested as a function\n",
        "    !mkdir image\n",
        "    !mkdir video\n",
        "    %cd image\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "      print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "          name=fn, length=len(uploaded[fn])))\n",
        "    %cd ..\n",
        "    !python main.py --config argument.yml\n",
        "###\n",
        "\n",
        "\n",
        "###############################################################\n",
        "\n",
        "#\n",
        "#If RIFE (P2) stops for no reason, go to Runtime>Change Runtime type and set the notebook to \"high memory\"\n",
        "\n",
        "#Params\n",
        "mount_google_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "#Mount Google Drive\n",
        "if mount_google_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "#install dependencies\n",
        "#AnKit.install_ESRGAN()\n",
        "#AnKit.install_RIFE()\n",
        "!pip install lpips datetime -q  #for overwrite protection\n",
        "####################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zPfby3z5HNb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title UNCOMMENT THIS CELL TO CLONE NECESSARY REPOSITORIES, NEEDS TO BE RUN ONCE ONLY.\n",
        "# !git clone https://github.com/xinntao/Real-ESRGAN.git '/content/drive/MyDrive/Real-ESRGAN' &> /dev/null #using own fork for longevity\n",
        "# %cd '/content/drive/MyDrive/Real-ESRGAN'\n",
        "# %cd '/content/drive/MyDrive/'\n",
        "# !git clone https://github.com/hzwer/Practical-RIFE.git #&> /dev/null  #using my own archive for longevity\n",
        "# !gdown --id 1EAbsfY7mjnXNa6RAsATj2ImAEqmHTjbE  #&> /dev/null  #NEWER 4.0 MODEL\n",
        "# !7z e RIFE_trained_model_v4.6.zip #&> /dev/null\n",
        "# !mkdir '/content/drive/MyDrive/Practical-RIFE/train_log'  #&> /dev/null\n",
        "# !mv *.py '/content/drive/MyDrive/Practical-RIFE/train_log/' #&> /dev/null\n",
        "# !mv *.pkl '/content/drive/MyDrive/Practical-RIFE/train_log/'  #&> /dev/null\n",
        "# %cd '/content/drive/MyDrive/Practical-RIFE/'\n",
        "# !pip3 install -r requirements.txt #&> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV5Jr-VjpAaK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title INSTALL ANIMATION KIT DEPENDENCIES\n",
        "# Install basicsr - https://github.com/xinntao/BasicSR\n",
        "# We use BasicSR for both training and inference\n",
        "%cd '/content/drive/MyDrive/Real-ESRGAN'\n",
        "!pip install basicsr\n",
        "# facexlib and gfpgan are for face enhancement\n",
        "!pip install facexlib\n",
        "!pip install gfpgan\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "%cd '/content/drive/MyDrive/Practical-RIFE/'\n",
        "!pip3 install -r requirements.txt #&> /dev/null\n",
        "!pip install -U torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jkYn-H7b40Ow"
      },
      "outputs": [],
      "source": [
        "      #@markdown #DEFINE PARAMS - AnimationKit AI SAVED TO DRIVE\n",
        "#@markdown >*This cell combines Real-ESRGAN upscaling, RIFE smoothing/interpolation, and h265 compression.*\n",
        "#@markdown ---\n",
        "#@markdown ##Input settings\n",
        "_import_mp4_file = False #@param {type:\"boolean\"}\n",
        "_imported_mp4_file='/content/drive/MyDrive/gangsta.mkv' #@param {type:\"string\"}\n",
        "#@markdown >If you want to process from static images, uncheck `_import_mp4_file`\n",
        "_import_frame_folder='/content/drive/MyDrive/AI/StableDiffusion/2022-11/wellerman' #@param {type:\"string\"}\n",
        "#@markdown Note: *`_import_frame_folder` is for importing individual frames from your projects. Will be ignored if `_import_mp4_file` is checked.*\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "#@markdown ---\n",
        "#@markdown ##Output settings\n",
        "_output_folder = '/content/drive/MyDrive/AI/AnimationKit/videos/' #@param {type:\"string\"}\n",
        "_output_filename = 'wellerman60fps.mp4' #@param{type:\"string\"}\n",
        "_target_frames2video_fps=12#@param {type:\"integer\"}\n",
        "_target_fps=60#@param {type:\"integer\"}\n",
        "_target_length_seconds=152#@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "_upscale_model_name='realesr-general-x4v3' #@param ['realesr-general-x4v3', 'RealESRGAN_x4plus','RealESRGAN_x4plus_anime_6B','RealESRGAN_x2plus'] {type:\"string\"}\n",
        "_constant_quality=21#@param {type:\"slider\", min:20, max:50, step:1}\n",
        "_face_enhance_gfpgan=False #@param{type:\"boolean\"}\n",
        "_skip_static_frames = False #deprecated\n",
        "# keep_mp4_audio = False #@param {type: \"boolean\"}\n",
        "#@markdown Default `_constant_quality` is `30`. Higher values = lower filesize, lower quality\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "#@markdown ---\n",
        "#@markdown ##Performance\n",
        "#input_path='/content/drive/MyDrive/pytti_test/videos/zelda4.mp4' #@param {type:\"string\"}\n",
        "_target_scale_RIFE='0.5'#@param ['0.25','0.5','1.0','2.0']{type:\"string\"}\n",
        "_half_precision_realesrgan=False #@param{type:\"boolean\"}\n",
        "#length_multiplier=3#@param {type:\"integer\"}\n",
        "#@markdown *These options can speed up processing at the costs of quality.*\n",
        "#@markdown If you're seeing weird warping in your outputs, try increasing or decreasing `_target_scale_RIFE`.\n",
        "#@markdown \n",
        "#---------------------------------------------------------------#\n",
        "\n",
        "\n",
        "#compress_path='/content/drive/MyDrive/pytti_test/videos/zelda4_16X_180fps.mp4' #@param {type:\"string\"}\n",
        "#outputStr = '_tblend2.mp4' #@param {type:\"string\"}\n",
        "enable_tblend = False #deprecated\n",
        "#deflicker_on = False #@param {type:\"boolean\"}\n",
        "#deflicker_avg_frames=76#@param {type:\"slider\", min:2, max:129, step:1}\n",
        "#mpdecimate_on = False #@param {type:\"boolean\"}\n",
        "#minterpolate_on = False #@param {type:\"boolean\"}\n",
        "#minterpolate_fps=60#@param {type:\"integer\"}\n",
        "#tblend_on = False #@param {type:\"boolean\"}\n",
        "#tmix_on = True #@param {type:\"boolean\"}\n",
        "tblend_framestep_value = \"2\"  #deprecated\n",
        "##@markdown Set `deflicker_avg_frames` filter size in frames. FFmpeg's default is 5. I haven't tested too much but I would try 100.\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "#@markdown ---\n",
        "#@markdown ##Master Overrides\n",
        "#@markdown If you want to skip certain processes, this is the master toggle. All related settings above will be ignored, so no need to change them.\n",
        "#skip_cleanup = True #@param{type:\"boolean\"}\n",
        "_skip_upscaling = False #@param{type:\"boolean\"}\n",
        "_skip_RIFEsmoothing = False #@param{type:\"boolean\"}\n",
        "##@markdown `skip_cleanup` will be automatically enabled if you pick either of these options.\n",
        "#---------------------------------------------------------------#\n",
        "skip_cleanup = False\n",
        "if _skip_upscaling:\n",
        "  skip_cleanup = True\n",
        "if _skip_RIFEsmoothing:\n",
        "  skip_cleanup = True\n",
        "\n",
        "###################################################################\n",
        "#Conditional passing of flags\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "# check if the message ends with .mp4\n",
        "contains_extension = (_output_filename.endswith('.mp4'))\n",
        "if not contains_extension:\n",
        "  _output_filename = _output_filename + '.mp4'\n",
        "output_fullpathname = _output_folder + _output_filename\n",
        "\n",
        "contains_slash = (_output_folder.endswith('/'))\n",
        "if not contains_slash:\n",
        "  _output_folder = _output_folder + '/'\n",
        "#---------------------------------------------------------------#\n",
        "\n",
        "if enable_tblend: #DEPRECATED\n",
        "  visual_effects = '-vf tblend=all_mode=average,framestep=' + tblend_framestep_value\n",
        "else:\n",
        "  visual_effects = ''\n",
        "#---------------------------------------------------------------#\n",
        "\n",
        "added_params = \"\"\n",
        "if _half_precision_realesrgan:\n",
        "  added_params = added_params + \" --half\"\n",
        "if _face_enhance_gfpgan: \n",
        "  added_params = added_params + \" --face_enhance\"\n",
        "\n",
        "if _skip_static_frames: #DEPCRECATED\n",
        "  _target_scale_RIFE = _target_scale_RIFE + ' --skip'\n",
        "\n",
        "%cd /content/\n",
        "#cleanup\n",
        "if not skip_cleanup:\n",
        "  print(\"\\n Parameters Defined, Cleaning up from last run...\\n\")\n",
        "  !rm -rf \"/content/Real-ESRGAN/results\"\n",
        "  !rm -rf '/content/frames_storage/init_frame_storage'\n",
        "  !rm -rf '/content/frames_storage/upscaled_frame_storage'\n",
        "\n",
        "#########################################################################\n",
        "#P3 h265 compression\n",
        "# print(\"\\n ------------------------------------\\n\")\n",
        "# print(\"\\n NOTICE: Beginning h265 compression phase...\\n\")\n",
        "# %cd /content/\n",
        "# Dir_make(_output_folder)\n",
        "\n",
        "#---File overwrite protection---\n",
        "# overwrite_protection = File_check(output_fullpathname)\n",
        "# if overwrite_protection:  #add datetime to end of file\n",
        "#   from datetime import datetime\n",
        "#   current_time = datetime.now().strftime('%y%m%d-%H%M%S_%f')\n",
        "#   output_fullpathname = output_fullpathname + '_' + current_time + '.mp4'\n",
        "#   print(\"NOTICE: Overwrite protection has renamed your output file as \",output_fullpathname,\" \\n\")\n",
        "#---end--------------------\n",
        "\n",
        "# if _skip_RIFEsmoothing:  \n",
        "#   !ffmpeg -i '/content/drive/MyDrive/frames2video.mp4' $visual_effects -c:v libx264 -rc vbr -cq 21 -pix_fmt yuv420p -b:v 0 $output_fullpathname -loglevel trace\n",
        "# else:\n",
        "#   !ffmpeg -i '/content/drive/MyDrive/RIFE_frames2video.mp4' $visual_effects -c:v libx264 -rc vbr -cq 21 -pix_fmt yuv420p -b:v 0 $output_fullpathname -loglevel trace\n",
        "\n",
        "# print(\"\\n ------------------------------------\\n\")\n",
        "\n",
        "# print(\"\\n End of h265 compression phase.\\n\")\n",
        "# file_verified = File_check(output_fullpathname)\n",
        "# if file_verified:\n",
        "#   print(\"\\n NOTICE: Finished! Your final file is saved as \",output_fullpathname)\n",
        "# else:\n",
        "#   print (\"\\n ERROR: Cannot verify that your file completed processing! Check /content/ for mp4 files to see what part of the process went wrong.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9W1_RtpDy5S2"
      },
      "outputs": [],
      "source": [
        "#@title COPY YOUR ANIMATION FRAMES TO TEMP STORAGE TO BE UPSCALED\n",
        "\n",
        "###############################################################\n",
        "#P1 REAL-ESRGAN UPSCALING\n",
        "\n",
        "print(\"\\n ------------------------------------\\n\")\n",
        "print(\"\\n Beginning Real-ESRGAN Upscaling phase...\\n\")\n",
        "\n",
        "if _import_mp4_file:\n",
        "  from pathlib import Path\n",
        "  #---splitframes------------------------------------------------\n",
        "  print(\"\\n Starting splitFrames... \\n\")\n",
        "  File_check(_imported_mp4_file)\n",
        "  Dir_make('/content/drive/MyDrive/frames_storage/init_frame_storage')\n",
        "  !python3 /content/drive/MyDrive/ffprogress/main.py -y -r 1 -i $_imported_mp4_file -r 1 '/content/drive/MyDrive/frames_storage/init_frame_storage'/frame%05d.png\n",
        "  print(\"\\n Completed splitFrames... \\n\")\n",
        "  #---end------------------------------------------------\n",
        "\n",
        "print(\"\\n Beginning sortFrames... \")\n",
        "if not _import_mp4_file:\n",
        "  Dir_check(_import_frame_folder)\n",
        "  %cd $_import_frame_folder\n",
        "Dir_make('/content/drive/MyDrive/frames_storage/init_frame_storage')\n",
        "\n",
        "#---sortframes------------------------------------------------\n",
        "print(\"\\n Copying frames to \"+'/content/drive/MyDrive/frames_storage/init_frame_storage'+\" for processing...\\n\")\n",
        "!find -maxdepth 1 -name '*.png' -print0 | xargs -0 cp -t '/content/drive/MyDrive/frames_storage/init_frame_storage'\n",
        "%cd '/content/drive/MyDrive/frames_storage/init_frame_storage'\n",
        "!find . -type f -name \"*.png\" -execdir bash -c 'mv \"$0\" \"${0##*_}\"' {} \\;  #removes anything not numbered (junk files) from new dir\n",
        "!rename 's/\\d+/sprintf(\"%05d\",$&)/e' *  #adds padding to numbers\n",
        "print(\"\\n Finished copying frames to \"+'/content/drive/MyDrive/frames_storage/init_frame_storage'+\".\\n\")\n",
        "print(\"Completed sortFrames... \\n\")\n",
        "#---end-------------------------------------------------\n",
        "\n",
        "# %cd /content/\n",
        "\n",
        "# #---runUpscale------------------------------------------------\n",
        "# if _skip_upscaling:\n",
        "#   print(\"NOTICE: _skip_upscaling is checked. Skipping Real-ESRGAN upscaling...\\n\")\n",
        "# else:\n",
        "#   Dir_check('/content/drive/MyDrive/frames_storage/init_frame_storage')\n",
        "#   Dir_make('/content/drive/MyDrive/frames_storage/upscaled_frame_storage')\n",
        "#   %cd '/content/drive/MyDrive/Real-ESRGAN/'\n",
        "#   !python3 /content/drive/MyDrive/Real-ESRGAN/inference_realesrgan.py --model_name $_upscale_model_name --outscale 5 -dn 1 --fp32 --input '/content/drive/MyDrive/frames_storage/init_frame_storage' --output '/content/drive/MyDrive/frames_storage/upscaled_frame_storage'$added_params\n",
        "#---end------------------------------------------------\n",
        "\n",
        "#---frames2video---------------------------------------------\n",
        "# print(\"\\n NOTICE: Running frames2video \\n\")\n",
        "# Dir_check('/content/drive/MyDrive/frames_storage/upscaled_frame_storage')\n",
        "# %cd '/content/drive/MyDrive/frames_storage/upscaled_frame_storage'\n",
        "# print(\"\\n Creating wip_file from frames... \\n\")\n",
        "# !ffmpeg -framerate $_target_frames2video_fps -pattern_type glob -i '*.png' -y '/content/drive/MyDrive/frames2video.mp4' -loglevel trace  \n",
        "# #this marks the creation of wip_file\n",
        "\n",
        "# print(\"\\n NOTICE: Finished running frames2video \\n\")\n",
        "# print(\"End of upscaling phase.\\n\")\n",
        "#---end------------------------------------------------\n",
        "\n",
        "#END OF UPSCALING PHASE P1\n",
        "#END OF UPSCALING PHASE\n",
        "\n",
        "###############################################################################\n",
        "###############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NAcj1VjsxJ2Y"
      },
      "outputs": [],
      "source": [
        "#@title USE THIS CELL TO MOVE IMAGES FROM INIT FRAME STORAGE MANUALLY TO RESUME FROM WHERE YOU LEFT OFF IF THE UPSCALE PHASE STOPPED\n",
        "\n",
        "input_directory = \"specify your directory here\" # @param {type: 'string'}\n",
        "output_directory = \"specify your directory here\" # @param {type: 'string'}\n",
        "\n",
        "#@markdown Manually identify which frames you need moved. Then input into the string below.\n",
        "frames_to_be_moved = \"00000..00010\" # @param {type: 'string'}\n",
        "#@markdown string format must be `00000..00000`, respecting the two `..` between the frame names\n",
        "%cd $input directory\n",
        "!bash -c 'mv {$frames_to_be_moved}.png $output_directory'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ROf39jOAblpZ"
      },
      "outputs": [],
      "source": [
        "#@title RUN REAL-ESRGAN UPSCALE PHASE\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "#---runUpscale------------------------------------------------\n",
        "if _skip_upscaling:\n",
        "  print(\"NOTICE: _skip_upscaling is checked. Skipping Real-ESRGAN upscaling...\\n\")\n",
        "else:\n",
        "  Dir_check('/content/drive/MyDrive/frames_storage/init_frame_storage')\n",
        "  Dir_make('/content/drive/MyDrive/frames_storage/upscaled_frame_storage')\n",
        "  %cd '/content/drive/MyDrive/Real-ESRGAN/'\n",
        "  !python3 /content/drive/MyDrive/Real-ESRGAN/inference_realesrgan.py --model_name $_upscale_model_name --outscale 5 -dn 1 --fp32 --gpu-id 0 --input '/content/drive/MyDrive/frames_storage/init_frame_storage' --output '/content/drive/MyDrive/frames_storage/upscaled_frame_storage'$added_params\n",
        "#---end------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RUN REAL-ESRGAN VIDEO UPSCALING\n",
        "!pip install --user ffmpeg-python\n",
        "%cd '/content/drive/MyDrive/Real-ESRGAN/'\n",
        "!python3 /content/drive/MyDrive/Real-ESRGAN/inference_realesrgan_video.py --model_name realesr-general-x4v3 --outscale 5 -dn 1 --fp32 --input '/content/drive/MyDrive/AI/StableDiffusion/2022-11/dark_cyberpunk/dark_cyberpunk.mp4' --fps 60 --output '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BuNwcv9xuCDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JatCucdKzCO4"
      },
      "outputs": [],
      "source": [
        "# %cd '/content'\n",
        "# !git clone https://github.com/anieshav/ffprogress.git\n",
        "#%cd '/content/drive/MyDrive/ffprogress'\n",
        "#@title PATH TO COMPILE FRAMES TO VIDEO\n",
        "\n",
        "input_path = '/content/drive/MyDrive/frames_storage/upscaled_frame_storage' # @param {type: 'string'}\n",
        "#@markdown THE INPUT FOLDER WITH YOUR FRAMES\n",
        "\n",
        "raw_vid = '/content/drive/MyDrive/temp.mp4' # @param {type: 'string'}\n",
        "#@markdown THIS PARAM SAVES THE FRAMES TO VIDEO AND IS THE INPUT FOR COMPRESSED VID\n",
        "\n",
        "compressed_vid = '/content/drive/MyDrive/wellerman.mp4' # @param {type: 'string'}\n",
        "#@markdown THIS IS THE FILE NAME FOR YOUR COMPRESSED VID\n",
        "\n",
        "%cd $input_path\n",
        "\n",
        "!python3 /content/drive/MyDrive/ffprogress/main.py -framerate 12 -pattern_type glob -i '*.png' -y $raw_vid\n",
        "\n",
        "%cd '/content'\n",
        "!python3 /content/drive/MyDrive/ffprogress/main.py -i $raw_vid -c:v libx264 -rc vbr -cq 21 -pix_fmt yuv420p -b:v 0 -y $compressed_vid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tDwGGvX6zFIO"
      },
      "outputs": [],
      "source": [
        "#@title RUN RIFE-INTERPOLATION\n",
        "\n",
        "#P2 RIFE MOTION SMOOTHING\n",
        "#P2 RIFE MOTION SMOOTHING\n",
        "\n",
        "compressed_vid = '/content/drive/MyDrive/wellerman.mp4' # @param {type: 'string'}\n",
        "#@markdown THIS IS THE FILE NAME FOR YOUR COMPRESSED VID\n",
        "\n",
        "output_RIFE = '/content/drive/MyDrive/wellerman_RIFE.mp4' # @param {type: 'string'}\n",
        "#@markdown INPUT YOUR OUTPUT NAME FOR THE INTERPOLATED VIDEO\n",
        "\n",
        "print(\"\\n ------------------------------------\\n\")\n",
        "print(\"\\n Beginning RIFE motion smoothing phase... \\n\")\n",
        "\n",
        "%cd /content/drive/MyDrive/Practical-RIFE/\n",
        "\n",
        "#----------------------------\n",
        "if _import_mp4_file:\n",
        "  measured_fps = AnKit.detect_fps(compressed_vid)\n",
        "  print(\"\\n NOTICE: Detected average FPS of \",_imported_mp4_file,\" is \",measured_fps)\n",
        "  measured_duration = AnKit.detect_duration(_imported_mp4_file)\n",
        "else: \n",
        "  measured_fps = AnKit.detect_fps(compressed_vid)\n",
        "  print(\"\\n NOTICE: Detected average FPS of \",{compressed_vid},\" is \",measured_fps)\n",
        "  measured_duration = AnKit.detect_duration(compressed_vid)\n",
        "\n",
        "print(\"\\n NOTICE: Detected duration INTEGER (in seconds) is \",measured_duration)\n",
        "\n",
        "if measured_duration < 1: #failsafe\n",
        "  print(\"\\n NOTICE: Your input appears to be less than one second... \\n\")\n",
        "  measured_duration = 1\n",
        "\n",
        "exp_value = AnKit.exp_calc(measured_duration,_target_length_seconds)\n",
        "\n",
        "\n",
        "print(\"\\n NOTICE: Target duration currently rounds to the closest --exp RIFE can handle. \\n\")\n",
        "\n",
        "if (exp_value < 0.5):\n",
        "  _skip_RIFEsmoothing = True\n",
        "  print(\"\\n NOTICE: Your _target_fps doesn't necessitate RIFE motion smoothing. Skipping RIFE...\\n\")\n",
        "\n",
        "if _skip_RIFEsmoothing:\n",
        "  print(\"\\n NOTICE: Skipping RIFE motion smoothing...\\n\")\n",
        "else:\n",
        "  #---RUN RIFE------------------------------------\n",
        "  print(\"\\n NOTICE: Running RIFE... \\n\")\n",
        "  %cd /content/drive/MyDrive/Practical-RIFE/\n",
        "  !python3 /content/drive/MyDrive/Practical-RIFE/inference_video.py --fps=$_target_fps --exp=$exp_value  --video=$compressed_vid --scale=$_target_scale_RIFE --output=$output_RIFE\n",
        "  #--exp=$exp_value\n",
        "  #---END--------------------------------------\n",
        "#!ffmpeg -y -i $input $visual_effects -c:v hevc_nvenc -rc vbr -cq $_constant_quality -qmin $_constant_quality -qmax $_constant_quality -b:v 0 $output_fullpathname\n",
        "#END OF MOTION SMOOTHING PHASE\n",
        "print(\"\\n End of RIFE interpolation phase.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZzA7ibeSD5A1"
      },
      "outputs": [],
      "source": [
        "# %cd '/content'\n",
        "# !git clone https://github.com/anieshav/ffprogress.git\n",
        "#%cd '/content/drive/MyDrive/ffprogress'\n",
        "#@title PATH TO COMPRESS YOUR RIFE VIDEO TO COMPRESSED VIDEO, IF NECESSARY\n",
        "\n",
        "#input_path = '/content/drive/MyDrive/frames_storage/upscaled_frame_storage' # @param {type: 'string'}\n",
        "#@markdown THE INPUT FOLDER WITH YOUR FRAMES\n",
        "\n",
        "raw_vid = '/content/drive/MyDrive/gangsta_RIFE.mkv' # @param {type: 'string'}\n",
        "#@markdown THIS PARAM SAVES THE FRAMES TO VIDEO AND IS THE INPUT FOR COMPRESSED VID\n",
        "\n",
        "compressed_vid = '/content/drive/MyDrive/gangsta_RIFE.mp4' # @param {type: 'string'}\n",
        "#@markdown THIS IS THE FILE NAME FOR YOUR COMPRESSED VID\n",
        "\n",
        "%cd '/content'\n",
        "!python3 /content/drive/MyDrive/ffprogress/main.py -i $raw_vid -c:v libx264 -rc vbr -cq 21 -pix_fmt yuv420p -b:v 0 -y $compressed_vid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16oOlkttT98d"
      },
      "source": [
        "# DISCONNECT RUNTIME HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvFKnvlKbN4Y",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vne-az6HUPvP"
      },
      "source": [
        "# AnimationKit AI saved to Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3pCq61SvlHjn"
      },
      "outputs": [],
      "source": [
        "#@markdown # AnimationKit AI saved to Content\n",
        "#@markdown >*This cell combines Real-ESRGAN upscaling, RIFE smoothing/interpolation, and h265 compression.*\n",
        "#@markdown ---\n",
        "#@markdown ##Input settings\n",
        "_import_mp4_file = True #@param {type:\"boolean\"}\n",
        "_imported_mp4_file='/content/drive/MyDrive/AI/VideoKilledTheRadioStar/godzilla/godzilla1.mp4' #@param {type:\"string\"}\n",
        "#@markdown >If you want to process from static images, uncheck `_import_mp4_file`\n",
        "_import_frame_folder='/content/drive/MyDrive/AI/StableDiffusion/2022-10/thecube' #@param {type:\"string\"}\n",
        "#@markdown Note: *`_import_frame_folder` is for importing individual frames from your projects. Will be ignored if `_import_mp4_file` is checked.*\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "#@markdown ---\n",
        "#@markdown ##Output settings\n",
        "_output_folder = '/content/drive/MyDrive/AI/AnimationKit/videos/' #@param {type:\"string\"}\n",
        "_output_filename = 'thecube60fps.mp4' #@param{type:\"string\"}\n",
        "_target_fps=60#@param {type:\"integer\"}\n",
        "_target_length_seconds=180#@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "_upscale_model_name='realesr-general-x4v3' #@param ['realesr-general-x4v3', 'RealESRGAN_x4plus','RealESRGAN_x4plus_anime_6B','RealESRGAN_x2plus'] {type:\"string\"}\n",
        "_constant_quality=21#@param {type:\"slider\", min:20, max:50, step:1}\n",
        "_face_enhance_gfpgan=False #@param{type:\"boolean\"}\n",
        "_skip_static_frames = False #deprecated\n",
        "# keep_mp4_audio = False #@param {type: \"boolean\"}\n",
        "#@markdown Default `_constant_quality` is `30`. Higher values = lower filesize, lower quality\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "#@markdown ---\n",
        "#@markdown ##Performance\n",
        "#input_path='/content/drive/MyDrive/pytti_test/videos/zelda4.mp4' #@param {type:\"string\"}\n",
        "_target_scale_RIFE='1.0'#@param ['0.25','0.5','1.0','2.0']{type:\"string\"}\n",
        "_half_precision_realesrgan=False #@param{type:\"boolean\"}\n",
        "#length_multiplier=3#@param {type:\"integer\"}\n",
        "#@markdown *These options can speed up processing at the costs of quality.*\n",
        "#@markdown If you're seeing weird warping in your outputs, try increasing or decreasing `_target_scale_RIFE`.\n",
        "#@markdown \n",
        "#---------------------------------------------------------------#\n",
        "\n",
        "\n",
        "#compress_path='/content/drive/MyDrive/pytti_test/videos/zelda4_16X_180fps.mp4' #@param {type:\"string\"}\n",
        "#outputStr = '_tblend2.mp4' #@param {type:\"string\"}\n",
        "enable_tblend = False #deprecated\n",
        "#deflicker_on = False #@param {type:\"boolean\"}\n",
        "#deflicker_avg_frames=76#@param {type:\"slider\", min:2, max:129, step:1}\n",
        "#mpdecimate_on = False #@param {type:\"boolean\"}\n",
        "#minterpolate_on = False #@param {type:\"boolean\"}\n",
        "#minterpolate_fps=60#@param {type:\"integer\"}\n",
        "#tblend_on = False #@param {type:\"boolean\"}\n",
        "#tmix_on = True #@param {type:\"boolean\"}\n",
        "tblend_framestep_value = \"2\"  #deprecated\n",
        "##@markdown Set `deflicker_avg_frames` filter size in frames. FFmpeg's default is 5. I haven't tested too much but I would try 100.\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "#@markdown ---\n",
        "#@markdown ##Master Overrides\n",
        "#@markdown If you want to skip certain processes, this is the master toggle. All related settings above will be ignored, so no need to change them.\n",
        "#skip_cleanup = True #@param{type:\"boolean\"}\n",
        "_skip_upscaling = False #@param{type:\"boolean\"}\n",
        "_skip_RIFEsmoothing = False #@param{type:\"boolean\"}\n",
        "##@markdown `skip_cleanup` will be automatically enabled if you pick either of these options.\n",
        "#---------------------------------------------------------------#\n",
        "skip_cleanup = False\n",
        "if _skip_upscaling:\n",
        "  skip_cleanup = True\n",
        "if _skip_RIFEsmoothing:\n",
        "  skip_cleanup = True\n",
        "\n",
        "###################################################################\n",
        "#Conditional passing of flags\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "# check if the message ends with .mp4\n",
        "contains_extension = (_output_filename.endswith('.mp4'))\n",
        "if not contains_extension:\n",
        "  _output_filename = _output_filename + '.mp4'\n",
        "output_fullpathname = _output_folder + _output_filename\n",
        "\n",
        "contains_slash = (_output_folder.endswith('/'))\n",
        "if not contains_slash:\n",
        "  _output_folder = _output_folder + '/'\n",
        "#---------------------------------------------------------------#\n",
        "\n",
        "if enable_tblend: #DEPRECATED\n",
        "  visual_effects = '-vf tblend=all_mode=average,framestep=' + tblend_framestep_value\n",
        "else:\n",
        "  visual_effects = ''\n",
        "#---------------------------------------------------------------#\n",
        "\n",
        "added_params = \"\"\n",
        "if _half_precision_realesrgan:\n",
        "  added_params = added_params + \" --half\"\n",
        "if _face_enhance_gfpgan: \n",
        "  added_params = added_params + \" --face_enhance\"\n",
        "\n",
        "if _skip_static_frames: #DEPCRECATED\n",
        "  _target_scale_RIFE = _target_scale_RIFE + ' --skip'\n",
        "\n",
        "%cd /content/\n",
        "#cleanup\n",
        "if not skip_cleanup:\n",
        "  print(\"\\n Cleaning up from last run...\\n\")\n",
        "  !rm -rf \"/content/Real-ESRGAN/results\"\n",
        "  !rm -rf '/content/frames_storage/init_frame_storage'\n",
        "  !rm -rf '/content/frames_storage/upscaled_frame_storage'\n",
        "\n",
        "###############################################################\n",
        "#P1 REAL-ESRGAN UPSCALING\n",
        "\n",
        "print(\"\\n ------------------------------------\\n\")\n",
        "print(\"\\n Beginning Real-ESRGAN Upscaling phase...\\n\")\n",
        "\n",
        "if _import_mp4_file:\n",
        "  from pathlib import Path\n",
        "  #---splitframes------------------------------------------------\n",
        "  print(\"\\n Starting splitFrames... \\n\")\n",
        "  File_check(_imported_mp4_file)\n",
        "  Dir_make('/content/frames_storage/init_frame_storage')\n",
        "  !ffmpeg -y -r 1 -i $_imported_mp4_file -r 1 '/content/frames_storage/init_frame_storage'/frame%05d.png\n",
        "  print(\"\\n Completed splitFrames... \\n\")\n",
        "  #---end------------------------------------------------\n",
        "\n",
        "print(\"\\n Beginning sortFrames... \")\n",
        "if not _import_mp4_file:\n",
        "  Dir_check(_import_frame_folder)\n",
        "  %cd $_import_frame_folder\n",
        "Dir_make('/content/frames_storage/init_frame_storage')\n",
        "\n",
        "#---sortframes------------------------------------------------\n",
        "print(\"\\n Copying frames to \"+'/content/frames_storage/init_frame_storage'+\" for processing...\\n\")\n",
        "!find -maxdepth 1 -name '*.png' -print0 | xargs -0 cp -t '/content/frames_storage/init_frame_storage'\n",
        "%cd '/content/frames_storage/init_frame_storage'\n",
        "!find . -type f -name \"*.png\" -execdir bash -c 'mv \"$0\" \"${0##*_}\"' {} \\;  #removes anything not numbered (junk files) from new dir\n",
        "!rename 's/\\d+/sprintf(\"%05d\",$&)/e' *  #adds padding to numbers\n",
        "print(\"\\n Finished copying frames to \"+'/content/frames_storage/init_frame_storage'+\".\\n\")\n",
        "print(\"Completed sortFrames... \\n\")\n",
        "#---end-------------------------------------------------\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "#---runUpscale------------------------------------------------\n",
        "if _skip_upscaling:\n",
        "  print(\"NOTICE: _skip_upscaling is checked. Skipping Real-ESRGAN upscaling...\\n\")\n",
        "else:\n",
        "  Dir_check('/content/frames_storage/init_frame_storage')\n",
        "  Dir_make('/content/frames_storage/upscaled_frame_storage')\n",
        "  %cd '/content/Real-ESRGAN/'\n",
        "  !python inference_realesrgan.py --model_name $_upscale_model_name --input '/content/frames_storage/init_frame_storage' --output '/content/frames_storage/upscaled_frame_storage'$added_params\n",
        "#---end------------------------------------------------\n",
        "\n",
        "#---frames2video---------------------------------------------\n",
        "print(\"\\n NOTICE: Running frames2video \\n\")\n",
        "Dir_check('/content/frames_storage/upscaled_frame_storage')\n",
        "%cd '/content/frames_storage/upscaled_frame_storage'\n",
        "print(\"\\n Creating wip_file from frames... \\n\")\n",
        "!ffmpeg -framerate $_target_fps -pattern_type glob -i '*.png' -y '/content/frames2video.mp4'  \n",
        "#this marks the creation of wip_file\n",
        "\n",
        "print(\"\\n NOTICE: Finished running frames2video \\n\")\n",
        "print(\"End of upscaling phase.\\n\")\n",
        "#---end------------------------------------------------\n",
        "\n",
        "#END OF UPSCALING PHASE P1\n",
        "#END OF UPSCALING PHASE\n",
        "\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "\n",
        "#P2 RIFE MOTION SMOOTHING\n",
        "#P2 RIFE MOTION SMOOTHING\n",
        "\n",
        "\n",
        "print(\"\\n ------------------------------------\\n\")\n",
        "print(\"\\n Beginning RIFE motion smoothing phase... \\n\")\n",
        "\n",
        "%cd /content/Practical-RIFE/\n",
        "\n",
        "#----------------------------\n",
        "if _import_mp4_file:\n",
        "  measured_fps = AnKit.detect_fps(_imported_mp4_file)\n",
        "  print(\"\\n NOTICE: Detected average FPS of \",_imported_mp4_file,\" is \",measured_fps)\n",
        "  measured_duration = AnKit.detect_duration(_imported_mp4_file)\n",
        "else: \n",
        "  measured_fps = AnKit.detect_fps('/content/frames2video.mp4')\n",
        "  print(\"\\n NOTICE: Detected average FPS of \",\"/content/frames2video.mp4\",\" is \",measured_fps)\n",
        "  measured_duration = AnKit.detect_duration('/content/frames2video.mp4')\n",
        "\n",
        "print(\"\\n NOTICE: Detected duration INTEGER (in seconds) is \",measured_duration)\n",
        "\n",
        "if measured_duration < 1: #failsafe\n",
        "  print(\"\\n NOTICE: Your input appears to be less than one second... \\n\")\n",
        "  measured_duration = 1\n",
        "\n",
        "exp_value = AnKit.exp_calc(measured_duration,_target_length_seconds)\n",
        "\n",
        "\n",
        "#print(\"\\n NOTICE: Target duration currently rounds to the closest --exp RIFE can handle. \\n\")\n",
        "\n",
        "if (exp_value < 0.5):\n",
        "  _skip_RIFEsmoothing = True\n",
        "  print(\"\\n NOTICE: Your _target_fps doesn't necessitate RIFE motion smoothing. Skipping RIFE...\\n\")\n",
        "\n",
        "if _skip_RIFEsmoothing:\n",
        "  print(\"\\n NOTICE: Skipping RIFE motion smoothing...\\n\")\n",
        "else:\n",
        "  #---RUN RIFE------------------------------------\n",
        "  print(\"\\n NOTICE: Running RIFE... \\n\")\n",
        "  %cd /content/Practical-RIFE\n",
        "  !python3 /content/Practical-RIFE/inference_video.py --fps=$_target_fps --exp=$exp_value --video='/content/frames2video.mp4' --scale=$_target_scale_RIFE --output='/content/RIFE_frames2video.mp4'\n",
        "  \n",
        "  #---END--------------------------------------\n",
        "#!ffmpeg -y -i $input $visual_effects -c:v hevc_nvenc -rc vbr -cq $_constant_quality -qmin $_constant_quality -qmax $_constant_quality -b:v 0 $output_fullpathname\n",
        "#END OF MOTION SMOOTHING PHASE\n",
        "print(\"\\n End of RIFE interpolation phase.\\n\")\n",
        "\n",
        "#########################################################################\n",
        "#P3 h265 compression\n",
        "print(\"\\n ------------------------------------\\n\")\n",
        "print(\"\\n NOTICE: Beginning h265 compression phase...\\n\")\n",
        "%cd /content/\n",
        "Dir_make(_output_folder)\n",
        "\n",
        "#---File overwrite protection---\n",
        "overwrite_protection = File_check(output_fullpathname)\n",
        "if overwrite_protection:  #add datetime to end of file\n",
        "  from datetime import datetime\n",
        "  current_time = datetime.now().strftime('%y%m%d-%H%M%S_%f')\n",
        "  output_fullpathname = output_fullpathname + '_' + current_time + '.mp4'\n",
        "  print(\"NOTICE: Overwrite protection has renamed your output file as \",output_fullpathname,\" \\n\")\n",
        "#---end--------------------\n",
        "\n",
        "# if _skip_RIFEsmoothing:  \n",
        "#   !ffmpeg -i '/content/frames2video.mp4' $visual_effects -c:v libx264 -rc vbr -cq 21 -pix_fmt yuv420p -b:v 0 $output_fullpathname\n",
        "# else:\n",
        "#   !ffmpeg -i '/content/RIFE_frames2video.mp4' $visual_effects -c:v libx264 -rc vbr -cq 21 -pix_fmt yuv420p -b:v 0 $output_fullpathname\n",
        "\n",
        "# print(\"\\n End of h265 compression phase.\\n\")\n",
        "# file_verified = File_check(output_fullpathname)\n",
        "# if file_verified:\n",
        "#   print(\"\\n NOTICE: Finished! Your final file is saved as \",output_fullpathname)\n",
        "# else:\n",
        "#   print (\"\\n ERROR: Cannot verify that your file completed processing! Check /content/ for mp4 files to see what part of the process went wrong.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg0BjqbpmqeM"
      },
      "source": [
        "# **ADD CAPTIONS TO YOUR VIDEO!** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IhW_rFN0tqLe"
      },
      "outputs": [],
      "source": [
        "# @title ## Analyze Video frame count\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from queue import Queue, Empty\n",
        "from subprocess import Popen, PIPE\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "video = '/content/drive/MyDrive/wellerman.mp4' # @param {type: 'string'}\n",
        "#output_filename = '/content/drive/MyDrive/rapgod_4K'\n",
        "\n",
        "videoCapture = cv2.VideoCapture(video)\n",
        "fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
        "tot_frame = videoCapture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "frames = tot_frame\n",
        "videoCapture.release()\n",
        "\n",
        "print(tot_frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mNOaAO7IosGi"
      },
      "outputs": [],
      "source": [
        "# @title ## Create Subtitle File for Video\n",
        "\n",
        "import os \n",
        "\n",
        "# src = '/content/drive/MyDrive/AI/VideoKilledTheRadioStar/venom/whispers/large.vtt'\n",
        "# !cp $src '/content/drive/MyDrive/AI/VideoKilledTheRadioStar/venom/whispers/large1.vtt' \n",
        "# dst = '/content/drive/MyDrive/AI/VideoKilledTheRadioStar/venom/whispers/large.srt'\n",
        "workspace = OmegaConf.load('config.yaml')\n",
        "root = Path(workspace.project_root)\n",
        "storyboard_fname = root / 'storyboard.yaml'\n",
        "storyboard = OmegaConf.load(storyboard_fname)\n",
        "\n",
        "source_whisper = storyboard.params.whisper.transcriptions.large\n",
        "save_source_whisper = '/content/drive/MyDrive/AI/VideoKilledTheRadioStar/emmett/whispers/large.vtt' # @param {type: 'string'}   \n",
        "#@markdown This saves the original whisper file.. Make sure you keep the `.vtt` extension.\n",
        "\n",
        "\n",
        "\n",
        "new_destination = '/content/drive/MyDrive/AI/VideoKilledTheRadioStar/emmett/whispers/large.srt' # @param {type: 'string'}\n",
        "\n",
        "#@markdown Change the name of your ouput file accordingly. Make sure you keep the `.srt` extension.\n",
        "\n",
        "os.rename(save_source_whisper, new_destination)\n",
        "print(new_destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FfmEqtkDo7UV"
      },
      "outputs": [],
      "source": [
        "# @title ## Create CAPTIONED Video!!!\n",
        "\n",
        "invid_forcaptions = '/content/drive/MyDrive/healingjourney.mp4' # @param {type: 'string'}\n",
        "outvid_forcaptions = '/content/drive/MyDrive/healingjourney.mkv' # @param {type: 'string'}\n",
        "\n",
        "\n",
        "!ffmpeg -i $invid_forcaptions -vf subtitles=$new_destination:force_style='Fontname=Humor-Sans' -v trace $outvid_forcaptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K8A5aU0J6Pgn"
      },
      "outputs": [],
      "source": [
        "#@title Add Audio to your video\n",
        "\n",
        "#@markdown This input is how slow you want the video in factor.\n",
        "\n",
        "invid_audio = '/content/drive/MyDrive/healingjourney.mkv' # @param {type: 'string'}\n",
        "add_audio = '/content/drive/MyDrive/AI/VideoKilledTheRadioStar/emmett/audio.mp3' # @param {type: 'string'}\n",
        "outvid_audio = '/content/drive/MyDrive/emmett_with_music.mkv' # @param {type: 'string'}\n",
        "\n",
        "\n",
        "!ffmpeg -i $invid_audio -i $add_audio -map 0 -map 1:a -c:v copy -y -v trace $outvid_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRQRdgm6yluU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# %cd '/content'\n",
        "# !git clone https://github.com/anieshav/ffprogress.git\n",
        "#%cd '/content/drive/MyDrive/ffprogress'\n",
        "#@title PATH TO COMPILE FRAMES TO VIDEO\n",
        "input_path = '/content/drive/MyDrive/AI/StableDiffusion/2022-11/emmett' # @param {type: 'string'}\n",
        "raw_vid = '/content/drive/MyDrive/test.mkv' # @param {type: 'string'}\n",
        "#@markdown THIS PARAM SAVES THE FRAMES TO VIDEO AND IS THE INPUT FOR COMPRESSED VID\n",
        "compressed_vid = '/content/drive/MyDrive/testing.mkv' # @param {type: 'string'}\n",
        "#@markdown THIS IS THE FILE NAME FOR YOUR COMPRESSED VID\n",
        "\n",
        "%cd $input_path\n",
        "\n",
        "!python3 /content/drive/MyDrive/ffprogress/main.py -framerate 12 -pattern_type glob -i '*.png' -y $raw_vid\n",
        "\n",
        "%cd '/content'\n",
        "!python3 /content/drive/MyDrive/ffprogress/main.py -i $raw_vid -c:v libx264 -rc vbr -cq 21 -pix_fmt yuv420p -b:v 0 -y $compressed_vid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eofFt6bbzGz1"
      },
      "outputs": [],
      "source": [
        "#@markdown Slow Your Video Speed\n",
        "\n",
        "vid_speed = '0.8' # @param {type: 'string'}\n",
        "#@markdown This input is how slow you want the video in factor.\n",
        "\n",
        "invid_slowed = '/content/drive/MyDrive/DNA_4K.mp4' # @param {type: 'string'}\n",
        "outvid_slowed = '/content/drive/MyDrive/final_product_captions.mp4' # @param {type: 'string'}\n",
        "\n",
        "\n",
        "!python3 /content/drive/MyDrive/ffprogress/main.py -i $invid_slowed -vf setpts=$vid_speed*PTS -y -v trace $outvid_slowed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MqcAZDvJ6Jjh"
      },
      "outputs": [],
      "source": [
        "#@markdown Slow Your Video Speed\n",
        "\n",
        "vid_speed = '1.3' # @param {type: 'string'}\n",
        "#@markdown This input is how slow you want the video in factor.\n",
        "\n",
        "invid_slowed = '/content/drive/MyDrive/aenema_RIFE.mp4' # @param {type: 'string'}\n",
        "outvid_slowed = '/content/drive/MyDrive/aenema_slowed_1.mp4' # @param {type: 'string'}\n",
        "\n",
        "\n",
        "!python3 /content/drive/MyDrive/ffprogress/main.py -i $invid_slowed -vf setpts=$vid_speed*PTS -y -v trace $outvid_slowed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CONVERT MP4 TO MKV\n",
        "\n",
        "vid_to_convert = '/content/drive/MyDrive/wellerman.mp4' # @param {type: 'string'}\n",
        "converted_vid = '/content/drive/MyDrive/wellerman.mkv' # @param {type: 'string'}\n",
        "\n",
        "!python3 /content/drive/MyDrive/ffprogress/main.py -i $vid_to_convert -vcodec copy $converted_vid"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FXDhg6RzRFLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za124iWvdMsZ"
      },
      "source": [
        "# **DeepVoice3: Single-speaker text-to-speech demo**\n",
        "\n",
        "In this notebook, you can try DeepVoice3-based single-speaker text-to-speech (en) using a model trained on [LJSpeech dataset](https://keithito.com/LJ-Speech-Dataset/). The notebook is supposed to be executed on [Google colab](https://colab.research.google.com) so you don't have to setup your machines locally.\n",
        "\n",
        "**Estimated time to complete**: 5 miniutes.\n",
        "\n",
        "- Code: https://github.com/r9y9/deepvoice3_pytorch\n",
        "- Audio samples: https://r9y9.github.io/deepvoice3_pytorch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml6wOhwqhGiI"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjindPTItq75"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhN0gocoPJWz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!git clone https://github.com/r9y9/deepvoice3_pytorch \n",
        "%cd '/content/deepvoice3_pytorch'\n",
        "!pip install -e \".[bin]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yJ90ESZiT_S"
      },
      "source": [
        "## Synthesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUyhiJg03dj6"
      },
      "source": [
        "### Setup hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6VFmDe-ideo",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "%pylab inline\n",
        "! pip install -q librosa nltk\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "# need this for English text processing frontend\n",
        "import nltk\n",
        "! python -m nltk.downloader cmudict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l1Gd2SStt0E"
      },
      "source": [
        "### Download a pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Zwjr4UjNn_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "preset = \"20180505_deepvoice3_ljspeech.json\"\n",
        "checkpoint_path = \"20180505_deepvoice3_checkpoint_step000640000.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45Wrp8INj6Xu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import os\n",
        "from os.path import exists, join, expanduser\n",
        "\n",
        "if not exists(preset):\n",
        "  !curl -O -L \"https://www.dropbox.com/s/0ck82unm0bo0rxd/20180505_deepvoice3_ljspeech.json\"\n",
        "if not exists(checkpoint_path):\n",
        "  !curl -O -L \"https://www.dropbox.com/s/5ucl9remrwy5oeg/20180505_deepvoice3_checkpoint_step000640000.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9sLuYgcnbZb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import hparams\n",
        "import json\n",
        "\n",
        "\n",
        "# Load parameters from preset\n",
        "with open(preset) as f:\n",
        "  hparams.hparams.parse_json(f.read())\n",
        "  \n",
        "# Inject frontend text processor\n",
        "import synthesis\n",
        "import train\n",
        "\n",
        "from deepvoice3_pytorch import frontend\n",
        "\n",
        "synthesis._frontend = getattr(frontend, \"en\")\n",
        "train._frontend =  getattr(frontend, \"en\")\n",
        "\n",
        "# alises\n",
        "fs = hparams.hparams.sample_rate\n",
        "hop_length = hparams.hparams.hop_size\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4NOldY83wG1"
      },
      "source": [
        "### Define utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcO5EKq7SBhz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#speaker_id:\n",
        "# (ID, AGE, GENDER, ACCENTS, REGION)\n",
        "\n",
        "# 225, 23, F, English, Southern, England \n",
        "# 226, 22, M, English, Surrey\n",
        "# 227, 38, M, English, Cumbria\n",
        "# 228, 22, F, English, Southern England\n",
        "# 229, 23, F, English, Southern England\n",
        "# 230, 22, F, English, Stockton-on-tees\n",
        "# 231, 23, F, English, Southern England\n",
        "# 232, 23, M, English, Southern England\n",
        "# 233, 23, F, English, Staffordshire\n",
        "# 234, 22, F, Scottish, West Dumfries\n",
        "# 236, 23, F, English, Manchester\n",
        "# 237, 22, M, Scottish, Fife"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRbelGLjiSfA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "def tts(model, text, p=0, speaker_id=None, fast=True, figures=True):\n",
        "  from synthesis import tts as _tts\n",
        "  waveform, alignment, spectrogram, mel = _tts(model, text, p, speaker_id, fast)\n",
        "  if figures:\n",
        "      visualize(alignment, spectrogram)\n",
        "  IPython.display.display(Audio(waveform, rate=fs))\n",
        "  \n",
        "def visualize(alignment, spectrogram):\n",
        "  label_fontsize = 16\n",
        "  figure(figsize=(16,16))\n",
        "\n",
        "  subplot(2,1,1)\n",
        "  imshow(alignment.T, aspect=\"auto\", origin=\"lower\", interpolation=None)\n",
        "  xlabel(\"Decoder timestamp\", fontsize=label_fontsize)\n",
        "  ylabel(\"Encoder timestamp\", fontsize=label_fontsize)\n",
        "  colorbar()\n",
        "\n",
        "  subplot(2,1,2)\n",
        "  librosa.display.specshow(spectrogram.T, sr=fs, \n",
        "                           hop_length=hop_length, x_axis=\"time\", y_axis=\"linear\")\n",
        "  xlabel(\"Time\", fontsize=label_fontsize)\n",
        "  ylabel(\"Hz\", fontsize=label_fontsize)\n",
        "  tight_layout()\n",
        "  colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2jmbSD430Ws"
      },
      "source": [
        "### Load the model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr8pgqtYhvav",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from train import build_model\n",
        "from train import restore_parts, load_checkpoint\n",
        "\n",
        "model = build_model()\n",
        "model = load_checkpoint(checkpoint_path, model, None, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOJ3miW63ywA"
      },
      "source": [
        "### Generate speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GR1XRy-ykbz_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Try your favorite senteneces:)\n",
        "texts = [\n",
        "    \"Scientists at the CERN laboratory say they have discovered a new particle.\",\n",
        "    \"There's a way to measure the acute emotional intelligence that has never gone out of style.\",\n",
        "    \"President Trump met with other leaders at the Group of 20 conference.\",\n",
        "    \"The Senate's bill to repeal and replace the Affordable Care Act is now imperiled.\",\n",
        "    \"Generative adversarial network or variational auto-encoder.\",\n",
        "    \"The buses aren't the problem, they actually provide a solution.\",\n",
        "    \"peter piper picked a peck of pickled peppers how many peppers did peter piper pick.\",\n",
        "    \"Some have accepted this as a miracle without any physical explanation.\",\n",
        "]\n",
        "\n",
        "for idx, text in enumerate(texts):\n",
        "  print(idx, text)\n",
        "  tts(model, text, figures=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nirMEf2J5Roy",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# With attention plot\n",
        "text = \"Generative adversarial network or variational auto-encoder.\"\n",
        "tts(model, text, figures=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArQspYbs5Aoo"
      },
      "source": [
        "For details, please visit https://github.com/r9y9/deepvoice3_pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az25TPUDjT2l"
      },
      "source": [
        "# **(OPTIONAL) FILM Interpolation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "i4lk6X4JfVr7"
      },
      "outputs": [],
      "source": [
        "#@markdown ##prep #1\n",
        "#@markdown ###clone repo\n",
        "!git clone https://github.com/vsewall/frame-interpolation frame_interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sBT-p97WfVr8"
      },
      "outputs": [],
      "source": [
        "#@markdown ##prep #2\n",
        "#@markdown ###you will see the restart button after execution. press it or go `Runtime > Restart runtime`\n",
        "#@markdown ###and after restarting **RUN THIS CELL AGAIN**\n",
        "!pip install tensorflow-datasets==4.4.0 tensorflow-addons==0.15.0 absl-py==0.12.0 gin-config==0.5.0 parameterized==0.8.1 mediapy==1.0.3 scikit-image==0.19.1 apache-beam==2.34.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nc2Gf7_JfVr8"
      },
      "outputs": [],
      "source": [
        "#@markdown ##prep #3\n",
        "#@markdown ###download pretrained models\n",
        "\n",
        "!pip install --upgrade gdown\n",
        "\n",
        "!gdown --id 1C1YwOo293_yrgSS8tAyFbbVcMeXxzftE\n",
        "!unzip \"/content/drive/MyDrive/pretrained_models-20220214T214839Z-001.zip\" -d \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title INSTALL REQUIREMENTS IF YOU CLONED INTO YOUR DRIVE\n",
        "\n",
        "%cd '/content/drive/MyDrive/frame_interpolation'\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gyCqyEYTsMuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FILM INFERENCE  { form-width: \"300px\" }\n",
        "\n",
        "#@markdown ###copy path to the sequence folder and paste it below\n",
        "%cd /content/drive/MyDrive/\n",
        "folder = '/content/drive/MyDrive/AI/StableDiffusion/2022-11/dark_cyberpunk' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ###the higher the next value, the longer the final video\n",
        "#@markdown ###1 ≈ 2x, 2 ≈ 4x, 3 ≈ 8x etc.\n",
        "\n",
        "times = 4 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "fps = 60 #@param {type:\"slider\", min:1, max:120, step:1}\n",
        "\n",
        "!python -m frame_interpolation.eval.interpolator_cli \\\n",
        "     --pattern $folder \\\n",
        "     --fps $fps \\\n",
        "     --model_path /content/drive/MyDrive/pretrained_models/film_net/Style/saved_model \\\n",
        "     --times_to_interpolate $times \\\n",
        "     --output_video\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Qq4SG7pto28I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dH1ktSYsci4v"
      },
      "outputs": [],
      "source": [
        "#@title  { form-width: \"300px\" }\n",
        "\n",
        "#@title  { form-width: \"300px\" }\n",
        "#@markdown # AI Manifestation Kit-->RUN THIS CELL FOR ALL-IN-ONE SEQUENCE\n",
        "#@markdown >*This cell combines Real-ESRGAN upscaling, RIFE smoothing/interpolation, and h265 compression.*\n",
        "#---------------------------------------------------------------#\n",
        "#@markdown ##FILM Interpolation\n",
        "\n",
        "#@markdown ###copy path to the sequence folder and paste it below\n",
        "%cd /content/\n",
        "folder = '/content/drive/MyDrive/AI/StableDiffusion/2022-10/dragons' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ###the higher the next value, the longer the final video\n",
        "#@markdown ###1 ≈ 2x, 2 ≈ 4x, 3 ≈ 8x etc.\n",
        "\n",
        "times = 1 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "fps = 29 #@param {type:\"slider\", min:1, max:120, step:1}\n",
        "\n",
        "!python -m frame_interpolation.eval.interpolator_cli \\\n",
        "     --pattern $folder \\\n",
        "     --fps $fps \\\n",
        "     --model_path /content/pretrained_models/film_net/Style/saved_model \\\n",
        "     --times_to_interpolate $times \\\n",
        "     --output_video\n",
        "\n",
        "#@markdown # AnimationKit AI\n",
        "#@markdown >*This cell combines Real-ESRGAN upscaling, RIFE smoothing/interpolation, and h265 compression.*\n",
        "#@markdown ---\n",
        "#@markdown ##Input settings\n",
        "_import_mp4_file = True #@param {type:\"boolean\"}\n",
        "_imported_mp4_file='/content/drive/MyDrive/AI/StableDiffusion/2022-10/dragons/interpolated.mp4' #@param {type:\"string\"}\n",
        "#@markdown >If you want to process from static images, uncheck `_import_mp4_file`\n",
        "_import_frame_folder='/content/drive/MyDrive/pytti_test/images_out/zelda3/' #@param {type:\"string\"}\n",
        "#@markdown Note: *`_import_frame_folder` is for importing individual frames from your projects. Will be ignored if `_import_mp4_file` is checked.*\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "#@markdown ---\n",
        "#@markdown ##Output settings\n",
        "_output_folder = '/content/drive/MyDrive/AI/AnimationKit/videos/' #@param {type:\"string\"}\n",
        "_output_filename = 'dragons60fps.mp4' #@param{type:\"string\"}\n",
        "_target_fps=60#@param {type:\"integer\"}\n",
        "_target_length_seconds=140#@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "_upscale_model_name='RealESRGAN_x4plus_anime_6B' #@param ['RealESRGAN_x4plus','RealESRGAN_x4plus_anime_6B','RealESRGAN_x2plus'] {type:\"string\"}\n",
        "_constant_quality=21#@param {type:\"slider\", min:20, max:50, step:1}\n",
        "_face_enhance_gfpgan=False #@param{type:\"boolean\"}\n",
        "_skip_static_frames = False #deprecated\n",
        "# keep_mp4_audio = False #@param {type: \"boolean\"}\n",
        "#@markdown Default `_constant_quality` is `30`. Higher values = lower filesize, lower quality\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "#@markdown ---\n",
        "#@markdown ##Performance\n",
        "#input_path='/content/drive/MyDrive/pytti_test/videos/zelda4.mp4' #@param {type:\"string\"}\n",
        "_target_scale_RIFE='1.0'#@param ['0.25','0.5','1.0','2.0']{type:\"string\"}\n",
        "_half_precision_realesrgan=False #@param{type:\"boolean\"}\n",
        "#length_multiplier=3#@param {type:\"integer\"}\n",
        "#@markdown *These options can speed up processing at the costs of quality.*\n",
        "#@markdown If you're seeing weird warping in your outputs, try increasing or decreasing `_target_scale_RIFE`.\n",
        "#@markdown \n",
        "#---------------------------------------------------------------#\n",
        "\n",
        "\n",
        "#compress_path='/content/drive/MyDrive/pytti_test/videos/zelda4_16X_180fps.mp4' #@param {type:\"string\"}\n",
        "#outputStr = '_tblend2.mp4' #@param {type:\"string\"}\n",
        "enable_tblend = False #deprecated\n",
        "#deflicker_on = False #@param {type:\"boolean\"}\n",
        "#deflicker_avg_frames=76#@param {type:\"slider\", min:2, max:129, step:1}\n",
        "#mpdecimate_on = False #@param {type:\"boolean\"}\n",
        "#minterpolate_on = False #@param {type:\"boolean\"}\n",
        "#minterpolate_fps=60#@param {type:\"integer\"}\n",
        "#tblend_on = False #@param {type:\"boolean\"}\n",
        "#tmix_on = True #@param {type:\"boolean\"}\n",
        "tblend_framestep_value = \"2\"  #deprecated\n",
        "##@markdown Set `deflicker_avg_frames` filter size in frames. FFmpeg's default is 5. I haven't tested too much but I would try 100.\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "#@markdown ---\n",
        "#@markdown ##Master Overrides\n",
        "#@markdown If you want to skip certain processes, this is the master toggle. All related settings above will be ignored, so no need to change them.\n",
        "#skip_cleanup = True #@param{type:\"boolean\"}\n",
        "_skip_upscaling = False #@param{type:\"boolean\"}\n",
        "_skip_RIFEsmoothing = True #@param{type:\"boolean\"}\n",
        "##@markdown `skip_cleanup` will be automatically enabled if you pick either of these options.\n",
        "#---------------------------------------------------------------#\n",
        "skip_cleanup = False\n",
        "if _skip_upscaling:\n",
        "  skip_cleanup = True\n",
        "if _skip_RIFEsmoothing:\n",
        "  skip_cleanup = True\n",
        "\n",
        "###################################################################\n",
        "#Conditional passing of flags\n",
        "\n",
        "#---------------------------------------------------------------#\n",
        "# check if the message ends with .mp4\n",
        "contains_extension = (_output_filename.endswith('.mp4'))\n",
        "if not contains_extension:\n",
        "  _output_filename = _output_filename + '.mp4'\n",
        "output_fullpathname = _output_folder + _output_filename\n",
        "\n",
        "contains_slash = (_output_folder.endswith('/'))\n",
        "if not contains_slash:\n",
        "  _output_folder = _output_folder + '/'\n",
        "#---------------------------------------------------------------#\n",
        "\n",
        "if enable_tblend: #DEPRECATED\n",
        "  visual_effects = '-vf tblend=all_mode=average,framestep=' + tblend_framestep_value\n",
        "else:\n",
        "  visual_effects = ''\n",
        "#---------------------------------------------------------------#\n",
        "\n",
        "added_params = \"\"\n",
        "if _half_precision_realesrgan:\n",
        "  added_params = added_params + \" --half\"\n",
        "if _face_enhance_gfpgan: \n",
        "  added_params = added_params + \" --face_enhance\"\n",
        "\n",
        "if _skip_static_frames: #DEPCRECATED\n",
        "  _target_scale_RIFE = _target_scale_RIFE + ' --skip'\n",
        "\n",
        "%cd /content/\n",
        "#cleanup\n",
        "if not skip_cleanup:\n",
        "  print(\"\\n Cleaning up from last run...\\n\")\n",
        "  !rm -rf \"/content/Real-ESRGAN/results\"\n",
        "  !rm -rf '/content/frames_storage/init_frame_storage'\n",
        "  !rm -rf '/content/frames_storage/upscaled_frame_storage'\n",
        "\n",
        "###############################################################\n",
        "#P1 REAL-ESRGAN UPSCALING\n",
        "\n",
        "print(\"\\n ------------------------------------\\n\")\n",
        "print(\"\\n Beginning Real-ESRGAN Upscaling phase...\\n\")\n",
        "\n",
        "if _import_mp4_file:\n",
        "  from pathlib import Path\n",
        "  #---splitframes------------------------------------------------\n",
        "  print(\"\\n Starting splitFrames... \\n\")\n",
        "  File_check(_imported_mp4_file)\n",
        "  Dir_make('/content/frames_storage/init_frame_storage')\n",
        "  !ffmpeg -y -r 1 -i $_imported_mp4_file -r 1 '/content/frames_storage/init_frame_storage'/frame%05d.png\n",
        "  print(\"\\n Completed splitFrames... \\n\")\n",
        "  #---end------------------------------------------------\n",
        "\n",
        "print(\"\\n Beginning sortFrames... \")\n",
        "if not _import_mp4_file:\n",
        "  Dir_check(_import_frame_folder)\n",
        "  %cd $_import_frame_folder\n",
        "Dir_make('/content/frames_storage/init_frame_storage')\n",
        "\n",
        "#---sortframes------------------------------------------------\n",
        "print(\"\\n Copying frames to \"+'/content/frames_storage/init_frame_storage'+\" for processing...\\n\")\n",
        "!find -maxdepth 1 -name '*.png' -print0 | xargs -0 cp -t '/content/frames_storage/init_frame_storage'\n",
        "%cd '/content/frames_storage/init_frame_storage'\n",
        "!find . -type f -name \"*.png\" -execdir bash -c 'mv \"$0\" \"${0##*_}\"' {} \\;  #removes anything not numbered (junk files) from new dir\n",
        "!rename 's/\\d+/sprintf(\"%05d\",$&)/e' *  #adds padding to numbers\n",
        "print(\"\\n Finished copying frames to \"+'/content/frames_storage/init_frame_storage'+\".\\n\")\n",
        "print(\"Completed sortFrames... \\n\")\n",
        "#---end-------------------------------------------------\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "#---runUpscale------------------------------------------------\n",
        "if _skip_upscaling:\n",
        "  print(\"NOTICE: _skip_upscaling is checked. Skipping Real-ESRGAN upscaling...\\n\")\n",
        "else:\n",
        "  Dir_check('/content/frames_storage/init_frame_storage')\n",
        "  Dir_make('/content/frames_storage/upscaled_frame_storage')\n",
        "  %cd '/content/Real-ESRGAN/'\n",
        "  !python inference_realesrgan.py --model_name $_upscale_model_name --input '/content/frames_storage/init_frame_storage' --output '/content/frames_storage/upscaled_frame_storage'$added_params\n",
        "#---end------------------------------------------------\n",
        "\n",
        "#---frames2video---------------------------------------------\n",
        "print(\"\\n NOTICE: Running frames2video \\n\")\n",
        "Dir_check('/content/frames_storage/upscaled_frame_storage')\n",
        "%cd '/content/frames_storage/upscaled_frame_storage'\n",
        "print(\"\\n Creating wip_file from frames... \\n\")\n",
        "!ffmpeg -framerate $_target_fps -pattern_type glob -i '*.png' -y '/content/frames2video.mp4'  \n",
        "#this marks the creation of wip_file\n",
        "\n",
        "print(\"\\n NOTICE: Finished running frames2video \\n\")\n",
        "print(\"End of upscaling phase.\\n\")\n",
        "#---end------------------------------------------------\n",
        "\n",
        "#END OF UPSCALING PHASE P1\n",
        "#END OF UPSCALING PHASE\n",
        "\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "\n",
        "#P2 RIFE MOTION SMOOTHING\n",
        "#P2 RIFE MOTION SMOOTHING\n",
        "\n",
        "\n",
        "print(\"\\n ------------------------------------\\n\")\n",
        "print(\"\\n Beginning RIFE motion smoothing phase... \\n\")\n",
        "\n",
        "%cd /content/Practical-RIFE/\n",
        "\n",
        "#----------------------------\n",
        "if _import_mp4_file:\n",
        "  measured_fps = AnKit.detect_fps(_imported_mp4_file)\n",
        "  print(\"\\n NOTICE: Detected average FPS of \",_imported_mp4_file,\" is \",measured_fps)\n",
        "  measured_duration = AnKit.detect_duration(_imported_mp4_file)\n",
        "else: \n",
        "  measured_fps = AnKit.detect_fps('/content/frames2video.mp4')\n",
        "  print(\"\\n NOTICE: Detected average FPS of \",\"/content/frames2video.mp4\",\" is \",measured_fps)\n",
        "  measured_duration = AnKit.detect_duration('/content/frames2video.mp4')\n",
        "\n",
        "print(\"\\n NOTICE: Detected duration INTEGER (in seconds) is \",measured_duration)\n",
        "\n",
        "if measured_duration < 1: #failsafe\n",
        "  print(\"\\n NOTICE: Your input appears to be less than one second... \\n\")\n",
        "  measured_duration = 1\n",
        "\n",
        "exp_value = AnKit.exp_calc(measured_duration,_target_length_seconds)\n",
        "\n",
        "\n",
        "#print(\"\\n NOTICE: Target duration currently rounds to the closest --exp RIFE can handle. \\n\")\n",
        "\n",
        "if (exp_value < 0.5):\n",
        "  _skip_RIFEsmoothing = True\n",
        "  print(\"\\n NOTICE: Your _target_fps doesn't necessitate RIFE motion smoothing. Skipping RIFE...\\n\")\n",
        "\n",
        "if _skip_RIFEsmoothing:\n",
        "  print(\"\\n NOTICE: Skipping RIFE motion smoothing...\\n\")\n",
        "  \n",
        "  #---END--------------------------------------\n",
        "#!ffmpeg -y -i $input $visual_effects -c:v hevc_nvenc -rc vbr -cq $_constant_quality -qmin $_constant_quality -qmax $_constant_quality -b:v 0 $output_fullpathname\n",
        "#END OF MOTION SMOOTHING PHASE\n",
        "print(\"\\n End of RIFE interpolation phase.\\n\")\n",
        "\n",
        "#########################################################################\n",
        "#P3 h265 compression\n",
        "print(\"\\n ------------------------------------\\n\")\n",
        "print(\"\\n NOTICE: Beginning h265 compression phase...\\n\")\n",
        "%cd /content/\n",
        "Dir_make(_output_folder)\n",
        "\n",
        "#---File overwrite protection---\n",
        "overwrite_protection = File_check(output_fullpathname)\n",
        "if overwrite_protection:  #add datetime to end of file\n",
        "  from datetime import datetime\n",
        "  current_time = datetime.now().strftime('%y%m%d-%H%M%S_%f')\n",
        "  output_fullpathname = output_fullpathname + '_' + current_time + '.mp4'\n",
        "  print(\"NOTICE: Overwrite protection has renamed your output file as \",output_fullpathname,\" \\n\")\n",
        "#---end--------------------\n",
        "\n",
        "if _skip_RIFEsmoothing:  \n",
        "  !ffmpeg -i '/content/frames2video.mp4' $visual_effects -c:v libx264 -rc vbr -cq 21 -pix_fmt yuv420p -b:v 0 $output_fullpathname\n",
        "\n",
        "print(\"\\n End of h265 compression phase.\\n\")\n",
        "file_verified = File_check(output_fullpathname)\n",
        "if file_verified:\n",
        "  print(\"\\n NOTICE: Finished! Your final file is saved as \",output_fullpathname)\n",
        "else:\n",
        "  print (\"\\n ERROR: Cannot verify that your file completed processing! Check /content/ for mp4 files to see what part of the process went wrong.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYbcutcI_Jxx"
      },
      "source": [
        "# AnimationPreview by [@pharmapsychotic](https://twitter.com/pharmapsychotic) \n",
        "\n",
        "This notebook lets you preview camera motion animations for [Disco Diffusion](https://colab.research.google.com/github/alembics/disco-diffusion/blob/main/Disco_Diffusion.ipynb), [2D Animation enabled JAX](https://colab.research.google.com/drive/1nmtcbQsE8sTjfLJ1u3Y4d6vi9ZTAvQph?usp=sharing), and [Deforum Stable Diffusion](https://colab.research.google.com/github/deforum/stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb)\n",
        "\n",
        "Get a preview of what your camera transforms will look like in a couple minutes instead of hours waiting on a full Disco animation to render. \n",
        "\n",
        "For help creating your key frames check out:\n",
        "* [Keyframe string generator for AI animation notebooks](https://www.chigozie.co.uk/keyframe-string-generator/) by [chigozienri](https://twitter.com/chigozienri)\n",
        "* [Audio keyframe generator](https://www.chigozie.co.uk/audio-keyframe-generator/) by [chigozienri](https://twitter.com/chigozienri)\n",
        "* [Wiggle 5.1](https://colab.research.google.com/github/zippy731/wiggle/blob/main/Wiggle_Standalone_5_1.ipynb) random camera animation notebook by [zippy731](https://twitter.com/zippy731)\n",
        "* For convenience a version of Wiggle 5.1 that you can quickly copy/paste generated key frames is included below!\n",
        "\n",
        "<br>\n",
        "\n",
        "2022/08/31:\n",
        "* Updated to latest Wiggle 5.1 with looping!\n",
        "\n",
        "2022/08/25:\n",
        "* Added new generator using Perlin noise\n",
        "* Plot the random values and Perlin noise values\n",
        "\n",
        "2022/08/16:\n",
        "* Added support for initial image\n",
        "* Added parameters to control the preview (how much darkening per frame and rect frame interval)\n",
        "* Optimizations\n",
        "\n",
        "<br>\n",
        "\n",
        "If you're looking for more Ai art tools check out my [Ai generative art tools list](https://pharmapsychotic.com/tools.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9lbjK8Cb_Jxy"
      },
      "outputs": [],
      "source": [
        "#@title Check GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LRn2sVX2_Jxz"
      },
      "outputs": [],
      "source": [
        "#@title Install libraries\n",
        "!git clone https://github.com/alembics/disco-diffusion.git\n",
        "!git clone https://github.com/shariqfarooq123/AdaBins.git\n",
        "!git clone https://github.com/isl-org/MiDaS.git\n",
        "!git clone https://github.com/MSFTserver/pytorch3d-lite.git\n",
        "!pip install perlin_noise timm tqdm\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "sys.path.insert(0, os.path.join(os.getcwd(), 'disco-diffusion'))\n",
        "sys.path.append(os.path.join(os.getcwd(), 'pytorch3d-lite'))\n",
        "sys.path.append(os.path.join(os.getcwd(), 'AdaBins'))\n",
        "sys.path.append(os.path.join(os.getcwd(), 'MiDaS'))\n",
        "\n",
        "model_path = '.'\n",
        "\n",
        "def wget(url, outputdir):\n",
        "    res = subprocess.run(['wget', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "if not os.path.exists(os.path.join(model_path, 'dpt_large-midas-2f21e586.pt')):\n",
        "    wget(\"https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\", model_path)\n",
        "if not os.path.exists('MiDaS/midas_utils.py'):\n",
        "    shutil.move('MiDaS/utils.py', 'MiDaS/midas_utils.py')\n",
        "if not os.path.exists('./pretrained/AdaBins_nyu.pt'):\n",
        "    os.makedirs('./pretrained', exist_ok=True)\n",
        "    wget(\"https://cloudflare-ipfs.com/ipfs/Qmd2mMnDLWePKmgfS8m6ntAg4nhV5VkUyAydYBp8cWWeB7/AdaBins_nyu.pt\", './pretrained')\n",
        "\n",
        "\n",
        "import cv2\n",
        "import io\n",
        "import ipywidgets as widgets\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import requests\n",
        "import torch\n",
        "from base64 import b64encode\n",
        "from IPython import display\n",
        "from ipywidgets import Layout, Output, Text\n",
        "from perlin_noise import PerlinNoise\n",
        "from PIL import Image, ImageDraw, ImageOps\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "import disco_xform_utils as dxf\n",
        "import py3d_tools as p3dT\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K5SDg-Ml_Jx1"
      },
      "outputs": [],
      "source": [
        "#@title Setup\n",
        "\n",
        "def fetch(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        r = requests.get(url_or_path)\n",
        "        r.raise_for_status()\n",
        "        fd = io.BytesIO()\n",
        "        fd.write(r.content)\n",
        "        fd.seek(0)\n",
        "        return fd\n",
        "    return open(url_or_path, 'rb')\n",
        "\n",
        "def parse_key_frames(string, prompt_parser=None):\n",
        "    import re\n",
        "    pattern = r'((?P<frame>[0-9]+):[\\s]*[\\(](?P<param>[\\S\\s]*?)[\\)])'\n",
        "    frames = dict()\n",
        "    for match_object in re.finditer(pattern, string):\n",
        "        frame = int(match_object.groupdict()['frame'])\n",
        "        param = match_object.groupdict()['param']\n",
        "        if prompt_parser:\n",
        "            frames[frame] = prompt_parser(param)\n",
        "        else:\n",
        "            frames[frame] = param\n",
        "\n",
        "    if frames == {} and len(string) != 0:\n",
        "        raise RuntimeError('Key Frame string not correctly formatted')\n",
        "    return frames\n",
        "\n",
        "def get_inbetweens(key_frames, integer=False):\n",
        "    key_frame_series = pd.Series([np.nan for a in range(max_frames)])\n",
        "\n",
        "    for i, value in key_frames.items():\n",
        "        key_frame_series[i] = value\n",
        "    key_frame_series = key_frame_series.astype(float)\n",
        "    \n",
        "    interp_method = interp_spline\n",
        "\n",
        "    if interp_method == 'Cubic' and len(key_frames.items()) <=3:\n",
        "      interp_method = 'Quadratic'\n",
        "    \n",
        "    if interp_method == 'Quadratic' and len(key_frames.items()) <= 2:\n",
        "      interp_method = 'Linear'\n",
        "      \n",
        "    \n",
        "    key_frame_series[0] = key_frame_series[key_frame_series.first_valid_index()]\n",
        "    key_frame_series[max_frames-1] = key_frame_series[key_frame_series.last_valid_index()]\n",
        "    # key_frame_series = key_frame_series.interpolate(method=intrp_method,order=1, limit_direction='both')\n",
        "    key_frame_series = key_frame_series.interpolate(method=interp_method.lower(),limit_direction='both')\n",
        "    if integer:\n",
        "        return key_frame_series.astype(int)\n",
        "    return key_frame_series\n",
        "\n",
        "TRANSLATION_SCALE = 1.0/200.0\n",
        "\n",
        "def do_3d_step(img_filepath, frame_num, midas_model, midas_transform):\n",
        "    translation_x = translation_x_series[frame_num]\n",
        "    translation_y = translation_y_series[frame_num]\n",
        "    translation_z = translation_z_series[frame_num]\n",
        "    rotation_3d_x = rotation_3d_x_series[frame_num]\n",
        "    rotation_3d_y = rotation_3d_y_series[frame_num]\n",
        "    rotation_3d_z = rotation_3d_z_series[frame_num]\n",
        "    translate_xyz = [-translation_x*TRANSLATION_SCALE, translation_y*TRANSLATION_SCALE, -translation_z*TRANSLATION_SCALE]\n",
        "    rotate_xyz_degrees = [rotation_3d_x, rotation_3d_y, rotation_3d_z]\n",
        "    rotate_xyz = [math.radians(rotate_xyz_degrees[0]), math.radians(rotate_xyz_degrees[1]), math.radians(rotate_xyz_degrees[2])]\n",
        "    rot_mat = p3dT.euler_angles_to_matrix(torch.tensor(rotate_xyz, device=device), \"XYZ\").unsqueeze(0)\n",
        "    next_step_pil = transform_image_3d(img_filepath, midas_model, midas_transform, device,\n",
        "                                            rot_mat, translate_xyz, near_plane, far_plane,\n",
        "                                            fov, padding_mode=padding_mode,\n",
        "                                            sampling_mode=sampling_mode, midas_weight=midas_weight)\n",
        "    return next_step_pil\n",
        "\n",
        "\n",
        "# Load MiDaS model\n",
        "from midas.dpt_depth import DPTDepthModel\n",
        "from midas.midas_net import MidasNet\n",
        "from midas.midas_net_custom import MidasNet_small\n",
        "from midas.transforms import Resize, NormalizeImage, PrepareForNet\n",
        "\n",
        "# Initialize MiDaS depth model.\n",
        "# It remains resident in VRAM and likely takes around 2GB VRAM.\n",
        "# You could instead initialize it for each frame (and free it after each frame) to save VRAM.. but initializing it is slow.\n",
        "default_models = {\n",
        "    #\"midas_v21_small\": f\"{model_path}/model-small-70d6b9c8.pt\",\n",
        "    #\"midas_v21\": f\"{model_path}/midas_v21-f6b98070.pt\",\n",
        "    \"dpt_large\": f\"{model_path}/dpt_large-midas-2f21e586.pt\",\n",
        "    #\"dpt_hybrid\": f\"{model_path}/dpt_hybrid-midas-501f0c75.pt\",\n",
        "    #\"dpt_hybrid_nyu\": f\"{model_path}/dpt_hybrid_nyu-2ce69ec7.pt\",\n",
        "}\n",
        "\n",
        "def init_midas_depth_model(midas_model_type=\"dpt_large\", optimize=True):\n",
        "    midas_model = None\n",
        "    net_w = None\n",
        "    net_h = None\n",
        "    resize_mode = None\n",
        "    normalization = None\n",
        "\n",
        "    print(f\"Initializing MiDaS '{midas_model_type}' depth model...\")\n",
        "    # load network\n",
        "    midas_model_path = default_models[midas_model_type]\n",
        "\n",
        "    if midas_model_type == \"dpt_large\": # DPT-Large\n",
        "        midas_model = DPTDepthModel(\n",
        "            path=midas_model_path,\n",
        "            backbone=\"vitl16_384\",\n",
        "            non_negative=True,\n",
        "        )\n",
        "        net_w, net_h = 384, 384\n",
        "        resize_mode = \"minimal\"\n",
        "        normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    elif midas_model_type == \"dpt_hybrid\": #DPT-Hybrid\n",
        "        midas_model = DPTDepthModel(\n",
        "            path=midas_model_path,\n",
        "            backbone=\"vitb_rn50_384\",\n",
        "            non_negative=True,\n",
        "        )\n",
        "        net_w, net_h = 384, 384\n",
        "        resize_mode=\"minimal\"\n",
        "        normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    elif midas_model_type == \"dpt_hybrid_nyu\": #DPT-Hybrid-NYU\n",
        "        midas_model = DPTDepthModel(\n",
        "            path=midas_model_path,\n",
        "            backbone=\"vitb_rn50_384\",\n",
        "            non_negative=True,\n",
        "        )\n",
        "        net_w, net_h = 384, 384\n",
        "        resize_mode=\"minimal\"\n",
        "        normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    elif midas_model_type == \"midas_v21\":\n",
        "        midas_model = MidasNet(midas_model_path, non_negative=True)\n",
        "        net_w, net_h = 384, 384\n",
        "        resize_mode=\"upper_bound\"\n",
        "        normalization = NormalizeImage(\n",
        "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "    elif midas_model_type == \"midas_v21_small\":\n",
        "        midas_model = MidasNet_small(midas_model_path, features=64, backbone=\"efficientnet_lite3\", exportable=True, non_negative=True, blocks={'expand': True})\n",
        "        net_w, net_h = 256, 256\n",
        "        resize_mode=\"upper_bound\"\n",
        "        normalization = NormalizeImage(\n",
        "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "    else:\n",
        "        print(f\"midas_model_type '{midas_model_type}' not implemented\")\n",
        "        assert False\n",
        "\n",
        "    midas_transform = T.Compose(\n",
        "        [\n",
        "            Resize(\n",
        "                net_w,\n",
        "                net_h,\n",
        "                resize_target=None,\n",
        "                keep_aspect_ratio=True,\n",
        "                ensure_multiple_of=32,\n",
        "                resize_method=resize_mode,\n",
        "                image_interpolation_method=cv2.INTER_CUBIC,\n",
        "            ),\n",
        "            normalization,\n",
        "            PrepareForNet(),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    midas_model.eval()\n",
        "    \n",
        "    if optimize==True:\n",
        "        if device == torch.device(\"cuda\"):\n",
        "            midas_model = midas_model.to(memory_format=torch.channels_last)  \n",
        "            midas_model = midas_model.half()\n",
        "\n",
        "    midas_model.to(device)\n",
        "\n",
        "    print(f\"MiDaS '{midas_model_type}' depth model initialized.\")\n",
        "    return midas_model, midas_transform, net_w, net_h, resize_mode, normalization\n",
        "\n",
        "\n",
        "# ======== modified disco_xform_utils ========\n",
        "import torch, torchvision\n",
        "import py3d_tools as p3d\n",
        "import midas_utils\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import sys, math\n",
        "\n",
        "try:\n",
        "    from infer import InferenceHelper\n",
        "except:\n",
        "    print(\"disco_xform_utils.py failed to import InferenceHelper. Please ensure that AdaBins directory is in the path (i.e. via sys.path.append('./AdaBins') or other means).\")\n",
        "    sys.exit()\n",
        "\n",
        "MAX_ADABINS_AREA = 530000\n",
        "MIN_ADABINS_AREA = 448*448\n",
        "\n",
        "@torch.no_grad()\n",
        "def transform_image_3d(img_filepath, midas_model, midas_transform, device, rot_mat=torch.eye(3).unsqueeze(0), translate=(0.,0.,-0.04), near=2000, far=20000, fov_deg=60, padding_mode='border', sampling_mode='bicubic', midas_weight = 0.3,spherical=False):\n",
        "    img_pil = to_pil_image(img_filepath)\n",
        "    w, h = img_pil.size\n",
        "    image_tensor = torchvision.transforms.functional.to_tensor(img_pil).to(device)\n",
        "\n",
        "    use_adabins = midas_weight < 1.0 and use_depth_warping\n",
        "\n",
        "    if use_adabins:\n",
        "        # AdaBins\n",
        "        \"\"\"\n",
        "        predictions using nyu dataset\n",
        "        \"\"\"\n",
        "        #print(\"Running AdaBins depth estimation implementation...\")\n",
        "        infer_helper = InferenceHelper(dataset='nyu', device=device)\n",
        "\n",
        "        image_pil_area = w*h\n",
        "        if image_pil_area > MAX_ADABINS_AREA:\n",
        "            scale = math.sqrt(MAX_ADABINS_AREA) / math.sqrt(image_pil_area)\n",
        "            depth_input = img_pil.resize((int(w*scale), int(h*scale)), Image.LANCZOS) # LANCZOS is supposed to be good for downsampling.\n",
        "        elif image_pil_area < MIN_ADABINS_AREA:\n",
        "            scale = math.sqrt(MIN_ADABINS_AREA) / math.sqrt(image_pil_area)\n",
        "            depth_input = img_pil.resize((int(w*scale), int(h*scale)), Image.BICUBIC)\n",
        "        else:\n",
        "            depth_input = img_pil\n",
        "        try:\n",
        "            _, adabins_depth = infer_helper.predict_pil(depth_input)\n",
        "            if image_pil_area != MAX_ADABINS_AREA:\n",
        "                adabins_depth = torchvision.transforms.functional.resize(torch.from_numpy(adabins_depth), image_tensor.shape[-2:], interpolation=torchvision.transforms.functional.InterpolationMode.BICUBIC).squeeze().to(device)\n",
        "            else:\n",
        "                adabins_depth = torch.from_numpy(adabins_depth).squeeze().to(device)\n",
        "            adabins_depth_np = adabins_depth.cpu().numpy()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # MiDaS\n",
        "\n",
        "    # MiDaS depth estimation implementation\n",
        "    if midas_model and use_depth_warping:\n",
        "        if not isinstance(img_filepath, str):\n",
        "            to_pil_image(img_filepath).save('midas_input.png')\n",
        "            img_filepath = 'midas_input.png'\n",
        "        img_midas = midas_utils.read_image(img_filepath)\n",
        "        img_midas_input = midas_transform({\"image\": img_midas})[\"image\"]\n",
        "        midas_optimize = True\n",
        "\n",
        "        #print(\"Running MiDaS depth estimation implementation...\")\n",
        "        sample = torch.from_numpy(img_midas_input).float().to(device).unsqueeze(0)\n",
        "        if midas_optimize==True and device == torch.device(\"cuda\"):\n",
        "            sample = sample.to(memory_format=torch.channels_last)  \n",
        "            sample = sample.half()\n",
        "        prediction_torch = midas_model.forward(sample)\n",
        "        prediction_torch = torch.nn.functional.interpolate(\n",
        "                prediction_torch.unsqueeze(1),\n",
        "                size=img_midas.shape[:2],\n",
        "                mode=\"bicubic\",\n",
        "                align_corners=False,\n",
        "            ).squeeze()\n",
        "    else:\n",
        "        prediction_torch = torch.zeros((1, h, w), device=device) \n",
        "    prediction_np = prediction_torch.clone().cpu().numpy()\n",
        "\n",
        "    #print(\"Finished depth estimation.\")\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # MiDaS makes the near values greater, and the far values lesser. Let's reverse that and try to align with AdaBins a bit better.\n",
        "    prediction_np = np.subtract(50.0, prediction_np)\n",
        "    prediction_np = prediction_np / 19.0\n",
        "\n",
        "    if use_adabins:\n",
        "        adabins_weight = 1.0 - midas_weight\n",
        "        depth_map = prediction_np*midas_weight + adabins_depth_np*adabins_weight\n",
        "    else:\n",
        "        depth_map = prediction_np\n",
        "\n",
        "    depth_map = np.expand_dims(depth_map, axis=0)\n",
        "    depth_tensor = torch.from_numpy(depth_map).squeeze().to(device)\n",
        "\n",
        "    pixel_aspect = 1.0 # really.. the aspect of an individual pixel! (so usually 1.0)\n",
        "    persp_cam_old = p3d.FoVPerspectiveCameras(near, far, pixel_aspect, fov=fov_deg, degrees=True, device=device)\n",
        "    persp_cam_new = p3d.FoVPerspectiveCameras(near, far, pixel_aspect, fov=fov_deg, degrees=True, R=rot_mat, T=torch.tensor([translate]), device=device)\n",
        "\n",
        "    # range of [-1,1] is important to torch grid_sample's padding handling\n",
        "    y,x = torch.meshgrid(torch.linspace(-1.,1.,h,dtype=torch.float32,device=device),torch.linspace(-1.,1.,w,dtype=torch.float32,device=device))\n",
        "    z = torch.as_tensor(depth_tensor, dtype=torch.float32, device=device)\n",
        "    xyz_old_world = torch.stack((x.flatten(), y.flatten(), z.flatten()), dim=1)\n",
        "\n",
        "    # Transform the points using pytorch3d. With current functionality, this is overkill and prevents it from working on Windows.\n",
        "    # If you want it to run on Windows (without pytorch3d), then the transforms (and/or perspective if that's separate) can be done pretty easily without it.\n",
        "    xyz_old_cam_xy = persp_cam_old.get_full_projection_transform().transform_points(xyz_old_world)[:,0:2]\n",
        "    xyz_new_cam_xy = persp_cam_new.get_full_projection_transform().transform_points(xyz_old_world)[:,0:2]\n",
        "\n",
        "    offset_xy = xyz_new_cam_xy - xyz_old_cam_xy\n",
        "    # affine_grid theta param expects a batch of 2D mats. Each is 2x3 to do rotation+translation.\n",
        "    identity_2d_batch = torch.tensor([[1.,0.,0.],[0.,1.,0.]], device=device).unsqueeze(0)\n",
        "    # coords_2d will have shape (N,H,W,2).. which is also what grid_sample needs.\n",
        "    coords_2d = torch.nn.functional.affine_grid(identity_2d_batch, [1,1,h,w], align_corners=False)\n",
        "    offset_coords_2d = coords_2d - torch.reshape(offset_xy, (h,w,2)).unsqueeze(0)\n",
        "\n",
        "    if spherical:\n",
        "        spherical_grid = get_spherical_projection(h, w, torch.tensor([0,0], device=device), -0.4,device=device)#align_corners=False\n",
        "        stage_image = torch.nn.functional.grid_sample(image_tensor.add(1/512 - 0.0001).unsqueeze(0), offset_coords_2d, mode=sampling_mode, padding_mode=padding_mode, align_corners=True)\n",
        "        new_image = torch.nn.functional.grid_sample(stage_image, spherical_grid,align_corners=True) #, mode=sampling_mode, padding_mode=padding_mode, align_corners=False)\n",
        "    else:\n",
        "        new_image = torch.nn.functional.grid_sample(image_tensor.add(1/512 - 0.0001).unsqueeze(0), offset_coords_2d, mode=sampling_mode, padding_mode=padding_mode, align_corners=False)\n",
        "\n",
        "    img_pil = torchvision.transforms.ToPILImage()(new_image.squeeze().clamp(0,1.))\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return img_pil\n",
        "\n",
        "def get_spherical_projection(H, W, center, magnitude,device):  \n",
        "    xx, yy = torch.linspace(-1, 1, W,dtype=torch.float32,device=device), torch.linspace(-1, 1, H,dtype=torch.float32,device=device)  \n",
        "    gridy, gridx  = torch.meshgrid(yy, xx)\n",
        "    grid = torch.stack([gridx, gridy], dim=-1)  \n",
        "    d = center - grid\n",
        "    d_sum = torch.sqrt((d**2).sum(axis=-1))\n",
        "    grid += d * d_sum.unsqueeze(-1) * magnitude \n",
        "    return grid.unsqueeze(0)\n",
        "\n",
        "\n",
        "# ======== preview rendering ========\n",
        "\n",
        "def draw_preview(img, preview_darken, scale):\n",
        "    img1 = ImageDraw.Draw(img, \"RGBA\")\n",
        "    img1.rectangle([(0,0),(img.width,img.height)], fill=(0,0,0,int(preview_darken*255)))\n",
        "    if scale > 0:\n",
        "        rw = img.width * scale\n",
        "        rh = img.height * scale\n",
        "        x, y = (img.width-rw)/2, (img.height-rh)/2\n",
        "        shape = [(x, y), (x+rw, y+rh)]\n",
        "        img1.rectangle(shape, outline=\"white\", width=2)\n",
        "\n",
        "def to_cv2_image(img):\n",
        "    if isinstance(img, np.ndarray):\n",
        "        return img\n",
        "    if isinstance(img, str):\n",
        "        return cv2.imread(img)\n",
        "    if isinstance(img, Image.Image):\n",
        "        return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "    assert(0)\n",
        "    return img        \n",
        "\n",
        "def to_pil_image(img):\n",
        "    if isinstance(img, Image.Image):\n",
        "        return img\n",
        "    if isinstance(img, str):\n",
        "        return Image.open(fetch(init_image)).convert('RGB')\n",
        "    if isinstance(img, np.ndarray):        \n",
        "        return Image.fromarray(cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "    assert(0)\n",
        "    return img\n",
        "\n",
        "def do_it():\n",
        "    global init_image\n",
        "    prev_frame = None\n",
        "    prev_frame_scaled = None\n",
        "    old_frame_scaled = None\n",
        "\n",
        "    if (animation_mode == \"3D\") and use_depth_warping:\n",
        "        midas_model, midas_transform, midas_net_w, midas_net_h, midas_resize_mode, midas_normalization = init_midas_depth_model(midas_depth_model)\n",
        "    else:\n",
        "        midas_model = None\n",
        "        midas_transform = None\n",
        "\n",
        "    for frame_num in tqdm(range(0, max_frames)):\n",
        "        frame_filename = f'frame_{frame_num:04d}.png'\n",
        "        if use_depth_warping:\n",
        "            display.clear_output(wait=True)\n",
        "            print(f\"Rendering frame {frame_num+1} of {max_frames}\")\n",
        "\n",
        "        if animation_mode == \"2D\":\n",
        "            angle = angle_series[frame_num]\n",
        "            zoom = zoom_series[frame_num]\n",
        "            translation_x = translation_x_series[frame_num]\n",
        "            translation_y = translation_y_series[frame_num]\n",
        "            if frame_num > 0:\n",
        "                img_0 = to_cv2_image(prev_frame)\n",
        "                center = (1*img_0.shape[1]//2, 1*img_0.shape[0]//2)\n",
        "                trans_mat = np.float32([[1, 0, translation_x], [0, 1, translation_y]])\n",
        "                rot_mat = cv2.getRotationMatrix2D( center, angle, zoom )\n",
        "                trans_mat = np.vstack([trans_mat, [0,0,1]])\n",
        "                rot_mat = np.vstack([rot_mat, [0,0,1]])\n",
        "                transformation_matrix = np.matmul(rot_mat, trans_mat)\n",
        "                img_0 = cv2.warpPerspective(\n",
        "                    img_0,\n",
        "                    transformation_matrix,\n",
        "                    (img_0.shape[1], img_0.shape[0]),\n",
        "                    borderMode=cv2.BORDER_WRAP\n",
        "                )\n",
        "                prev_frame_scaled = img_0\n",
        "                init_image = prev_frame_scaled\n",
        "        elif animation_mode == \"3D\":\n",
        "            if frame_num > 0:\n",
        "                img_filepath = prev_frame\n",
        "                next_step_pil = do_3d_step(img_filepath, frame_num, midas_model, midas_transform)                \n",
        "                prev_frame_scaled = next_step_pil\n",
        "\n",
        "                ### Turbo mode - skip some diffusions, use 3d morph for clarity and to save time\n",
        "                if turbo_mode:\n",
        "                    if frame_num == turbo_preroll: #start tracking oldframe\n",
        "                        old_frame_scaled = next_step_pil #stash for later blending          \n",
        "                    elif frame_num > turbo_preroll:\n",
        "                        #set up 2 warped image sequences, old & new, to blend toward new diff image\n",
        "                        old_frame = do_3d_step(old_frame_scaled, frame_num, midas_model, midas_transform)\n",
        "                        old_frame_scaled = old_frame #old_frame.save('oldFrameScaled.png')                        \n",
        "                        if frame_num % int(turbo_steps) != 0: \n",
        "                            #print('turbo skip this frame: skipping clip diffusion steps')\n",
        "                            blend_factor = ((frame_num % int(turbo_steps))+1)/int(turbo_steps)\n",
        "                            #print('turbo skip this frame: skipping clip diffusion steps and saving blended frame')\n",
        "                            newWarpedImg = prev_frame_scaled\n",
        "                            oldWarpedImg = old_frame_scaled\n",
        "                            blendedImage = cv2.addWeighted(to_cv2_image(newWarpedImg), blend_factor, to_cv2_image(oldWarpedImg),1-blend_factor, 0.0)\n",
        "                            cv2.imwrite(frame_filename, blendedImage)\n",
        "                            prev_frame = next_step_pil # save it also as prev_frame to feed next iteration\n",
        "                            continue\n",
        "                        else:\n",
        "                            #if not a skip frame, will run diffusion and need to blend.\n",
        "                            oldWarpedImg = prev_frame_scaled\n",
        "                            old_frame_scaled = oldWarpedImg #swap in for blending later \n",
        "                            #print('clip/diff this frame - generate clip diff image')\n",
        "\n",
        "                init_image = prev_frame_scaled\n",
        "\n",
        "        if init_image is None or init_image == '':\n",
        "            init = Image.new(\"RGB\", (width_height[0], width_height[1]))\n",
        "        elif isinstance(init_image, str):\n",
        "            init = Image.open(fetch(init_image)).convert('RGB').resize((width_height[0], width_height[1]))\n",
        "        else:\n",
        "            init = to_pil_image(init_image)\n",
        "        image = init\n",
        "\n",
        "        draw_preview(image, preview_darken, 0.25 if frame_num % int(preview_rect_frame_delta) == 0 else 0)\n",
        "\n",
        "        prev_frame = image\n",
        "        if animation_mode == \"2D\":\n",
        "            image.save(frame_filename)\n",
        "        elif animation_mode == \"3D\":\n",
        "            if turbo_mode and frame_num > 0:\n",
        "                # Mix new image with prevFrameScaled\n",
        "                blend_factor = (1)/int(turbo_steps)\n",
        "                newFrame = prev_frame\n",
        "                prev_frame_warped = prev_frame_scaled\n",
        "                blendedImage = cv2.addWeighted(to_cv2_image(newFrame), blend_factor, to_cv2_image(prev_frame_warped), (1-blend_factor), 0.0)\n",
        "                cv2.imwrite(frame_filename, blendedImage)\n",
        "            else:\n",
        "                image.save(frame_filename)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    print(\"Creating preview video...\")\n",
        "\n",
        "    # make video\n",
        "    FPS = 24\n",
        "    cmd = [\n",
        "        'ffmpeg',\n",
        "        '-y',\n",
        "        '-vcodec', 'png',\n",
        "        '-r', str(video_fps),\n",
        "        '-start_number', str(0),\n",
        "        '-i', f'frame_%04d.png',\n",
        "        '-frames:v', str(max_frames),\n",
        "        '-c:v', 'libx264',\n",
        "        '-vf',\n",
        "        f'fps={video_fps}',\n",
        "        '-pix_fmt', 'yuv420p',\n",
        "        '-crf', '17',\n",
        "        '-preset', 'veryfast',\n",
        "        'anim_preview.mp4'\n",
        "    ]\n",
        "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    stdout, stderr = process.communicate()\n",
        "    if process.returncode != 0:\n",
        "        print(stderr)\n",
        "        raise RuntimeError(stderr)\n",
        "\n",
        "    # delete the frame images\n",
        "    for frame_num in range(0, max_frames):\n",
        "        frame_filename = f'frame_{frame_num:04d}.png'\n",
        "        os.remove(frame_filename)\n",
        "\n",
        "    display.clear_output(wait=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0WUG_Bc_Jx4"
      },
      "source": [
        "# Animation preview rendering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RT4KbU09_Jx5"
      },
      "outputs": [],
      "source": [
        "#@title Animation preview\n",
        "width_height = [640, 512] #@param{type: 'raw'}\n",
        "video_fps = 24 #@param {type:\"number\"}\n",
        "animation_mode = '3D' #@param ['2D', '3D'] {type:'string'}\n",
        "init_image = \"/content/drive/MyDrive/bokinator/ZT-D40900B-10PN675.png\" #@param{type: 'string'}\n",
        "preview_darken = 0.05 #@param{type: 'number'}\n",
        "preview_rect_frame_delta = 5#@param{type: 'number'}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown #### Camera key frames\n",
        "max_frames = 4470#@param {type:\"number\"}\n",
        "interp_spline = 'Linear' #Do not change, currently will not look good. param ['Linear','Quadratic','Cubic']{type:\"string\"}\n",
        "angle = \"0:(0)\"#@param {type:\"string\"}\n",
        "zoom = \"0:(1.05)\"#@param {type:\"string\"}\n",
        "translation_x = \"0:(0)\"#@param {type:\"string\"}\n",
        "translation_y = \"0:(0)\"#@param {type:\"string\"}\n",
        "translation_z = \"0: (0.675), 1: (0.675), 2: (0.675), 3: (0.675), 4: (0.675), 5: (0.675), 6: (0.675), 7: (0.675), 8: (0.675), 9: (0.675), 10: (0.675), 11: (0.675), 12: (0.675), 13: (0.675), 14: (0.675), 15: (0.675), 16: (0.675), 17: (0.675), 18: (0.675), 19: (0.675), 20: (0.675), 21: (0.675), 22: (0.675), 23: (0.675), 24: (0.675), 25: (0.675), 26: (0.675), 27: (0.675), 28: (0.675), 29: (0.675), 30: (0.675), 31: (0.675), 32: (0.675), 33: (0.675), 34: (0.675), 35: (0.675), 36: (0.675), 37: (0.675), 38: (0.675), 39: (0.675), 40: (0.675), 41: (0.675), 42: (0.675), 43: (0.675), 44: (0.675), 45: (0.675), 46: (0.675), 47: (0.675), 48: (0.675), 49: (0.675), 50: (0.675), 51: (0.675), 52: (0.675), 53: (0.675), 54: (0.675), 55: (0.675), 56: (0.675), 57: (0.675), 58: (0.675), 59: (0.675), 60: (0.675), 61: (0.675), 62: (0.675), 63: (0.675), 64: (0.675), 65: (0.675), 66: (0.675), 67: (0.675), 68: (0.675), 69: (0.675), 70: (0.675), 71: (0.675), 72: (0.675), 73: (0.675), 74: (0.675), 75: (0.675), 76: (0.675), 77: (0.675), 78: (0.675), 79: (0.675), 80: (0.675), 81: (0.675), 82: (0.675), 83: (0.675), 84: (0.675), 85: (0.675), 86: (0.675), 87: (0.675), 88: (0.675), 89: (0.675), 90: (0.675), 91: (0.675), 92: (0.675), 93: (0.675), 94: (0.675), 95: (0.675), 96: (0.675), 97: (0.675), 98: (0.675), 99: (0.675), 100: (0.675), 101: (0.675), 102: (0.675), 103: (0.675), 104: (0.675), 105: (0.675), 106: (0.675), 107: (0.675), 108: (0.675), 109: (0.675), 110: (0.675), 111: (0.675), 112: (0.675), 113: (0.675), 114: (0.675), 115: (0.675), 116: (0.675), 117: (0.675), 118: (0.675), 119: (1.01), 120: (1.01), 121: (1.01), 122: (1.01), 123: (0.875), 124: (0.875), 125: (45), 126: (1.09), 127: (0.875), 128: (1.27), 129: (1.24), 130: (1.42), 131: (1.04), 132: (1.20), 133: (1.25), 134: (1.07), 135: (1.03), 136: (1.01), 137: (1.01), 138: (1.01), 139: (1.01), 140: (1.01), 141: (0.875), 142: (1.29), 143: (1.41), 144: (1.18), 145: (1.01), 146: (45), 147: (1.03), 148: (0.675), 149: (0.875), 150: (1.01), 151: (0.675), 152: (1.01), 153: (1.04), 154: (30), 155: (30), 156: (30), 157: (45), 158: (0.875), 159: (1.03), 160: (1.03), 161: (1.01), 162: (0.875), 163: (1.01), 164: (0.675), 165: (0.675), 166: (0.875), 167: (1.03), 168: (0.875), 169: (0.875), 170: (1.08), 171: (1.10), 172: (1.15), 173: (1.69), 174: (1.37), 175: (1.29), 176: (45), 177: (1.09), 178: (1.11), 179: (1.35), 180: (1.15), 181: (30), 182: (0.875), 183: (30), 184: (1.04), 185: (0.675), 186: (0.675), 187: (0.675), 188: (0.675), 189: (0.675), 190: (0.675), 191: (1.01), 192: (0.675), 193: (1.01), 194: (1.01), 195: (0.875), 196: (1.01), 197: (30), 198: (1.56), 199: (1.29), 200: (1.30), 201: (1.30), 202: (1.03), 203: (0.875), 204: (1.01), 205: (0.675), 206: (1.01), 207: (0.675), 208: (1.01), 209: (0.675), 210: (0.675), 211: (0.675), 212: (0.675), 213: (0.675), 214: (0.675), 215: (0.675), 216: (1.01), 217: (1.01), 218: (1.01), 219: (0.675), 220: (0.875), 221: (30), 222: (1.04), 223: (1.03), 224: (1.07), 225: (1.04), 226: (1.04), 227: (1.24), 228: (1.31), 229: (1.51), 230: (45), 231: (1.23), 232: (1.14), 233: (1.11), 234: (0.875), 235: (0.875), 236: (1.01), 237: (1.01), 238: (1.01), 239: (0.675), 240: (0.675), 241: (0.875), 242: (1.04), 243: (1.10), 244: (1.01), 245: (1.04), 246: (0.675), 247: (1.01), 248: (1.03), 249: (0.675), 250: (1.01), 251: (1.01), 252: (1.07), 253: (45), 254: (1.03), 255: (0.875), 256: (0.875), 257: (0.875), 258: (1.03), 259: (0.875), 260: (1.01), 261: (1.01), 262: (0.675), 263: (0.675), 264: (0.675), 265: (1.03), 266: (1.01), 267: (1.01), 268: (1.03), 269: (1.08), 270: (1.03), 271: (1.14), 272: (1.46), 273: (1.27), 274: (1.28), 275: (0.875), 276: (1.16), 277: (1.10), 278: (1.15), 279: (30), 280: (0.875), 281: (0.875), 282: (0.875), 283: (1.04), 284: (0.675), 285: (0.675), 286: (0.675), 287: (0.675), 288: (0.675), 289: (1.01), 290: (0.875), 291: (0.675), 292: (1.01), 293: (0.875), 294: (0.875), 295: (1.01), 296: (1.09), 297: (1.61), 298: (1.23), 299: (1.29), 300: (1.16), 301: (30), 302: (0.875), 303: (0.675), 304: (0.675), 305: (1.01), 306: (1.01), 307: (1.01), 308: (0.675), 309: (0.675), 310: (0.675), 311: (0.675), 312: (0.675), 313: (0.675), 314: (0.675), 315: (1.01), 316: (1.01), 317: (1.01), 318: (0.875), 319: (1.03), 320: (1.07), 321: (1.03), 322: (30), 323: (1.08), 324: (1.04), 325: (1.10), 326: (1.16), 327: (1.41), 328: (1.19), 329: (1.04), 330: (1.41), 331: (1.21), 332: (45), 333: (1.04), 334: (0.875), 335: (1.01), 336: (1.01), 337: (1.03), 338: (1.01), 339: (1.08), 340: (1.60), 341: (1.23), 342: (30), 343: (1.03), 344: (1.07), 345: (1.01), 346: (1.01), 347: (0.875), 348: (0.675), 349: (0.675), 350: (0.875), 351: (30), 352: (30), 353: (45), 354: (1.07), 355: (30), 356: (1.03), 357: (1.04), 358: (1.03), 359: (0.875), 360: (0.875), 361: (0.675), 362: (0.675), 363: (0.675), 364: (1.08), 365: (0.875), 366: (0.875), 367: (45), 368: (1.14), 369: (1.11), 370: (1.33), 371: (1.79), 372: (1.23), 373: (1.15), 374: (45), 375: (1.09), 376: (1.25), 377: (1.25), 378: (1.08), 379: (1.03), 380: (1.03), 381: (30), 382: (1.01), 383: (0.675), 384: (0.675), 385: (0.675), 386: (0.675), 387: (0.675), 388: (0.675), 389: (0.675), 390: (0.675), 391: (1.01), 392: (0.875), 393: (0.875), 394: (0.875), 395: (1.18), 396: (1.56), 397: (1.27), 398: (1.29), 399: (1.07), 400: (1.04), 401: (1.01), 402: (0.675), 403: (1.01), 404: (0.675), 405: (1.01), 406: (0.675), 407: (0.675), 408: (0.675), 409: (0.675), 410: (0.675), 411: (0.675), 412: (0.675), 413: (0.875), 414: (1.01), 415: (0.875), 416: (1.04), 417: (1.03), 418: (1.04), 419: (45), 420: (1.03), 421: (30), 422: (1.08), 423: (1.04), 424: (1.14), 425: (1.18), 426: (1.47), 427: (1.08), 428: (1.13), 429: (1.40), 430: (1.15), 431: (1.04), 432: (1.03), 433: (1.03), 434: (30), 435: (1.03), 436: (1.04), 437: (0.875), 438: (1.20), 439: (1.60), 440: (1.18), 441: (1.03), 442: (1.03), 443: (45), 444: (0.675), 445: (0.875), 446: (0.875), 447: (0.675), 448: (1.01), 449: (1.03), 450: (45), 451: (1.04), 452: (45), 453: (1.08), 454: (1.04), 455: (1.04), 456: (1.04), 457: (0.875), 458: (0.875), 459: (0.875), 460: (0.675), 461: (0.675), 462: (1.01), 463: (1.04), 464: (0.875), 465: (1.03), 466: (1.11), 467: (1.15), 468: (1.13), 469: (1.50), 470: (1.55), 471: (1.29), 472: (1.10), 473: (1.07), 474: (1.07), 475: (1.30), 476: (1.19), 477: (30), 478: (1.03), 479: (30), 480: (30), 481: (1.01), 482: (0.675), 483: (0.675), 484: (0.675), 485: (0.675), 486: (0.675), 487: (0.675), 488: (0.675), 489: (1.01), 490: (1.01), 491: (1.01), 492: (0.875), 493: (1.03), 494: (1.35), 495: (1.32), 496: (1.27), 497: (1.37), 498: (1.04), 499: (1.03), 500: (1.01), 501: (0.675), 502: (1.01), 503: (1.01), 504: (0.875), 505: (0.675), 506: (1.01), 507: (0.675), 508: (0.675), 509: (0.675), 510: (0.675), 511: (0.675), 512: (0.875), 513: (1.01), 514: (0.875), 515: (30), 516: (1.04), 517: (30), 518: (30), 519: (1.03), 520: (1.07), 521: (1.09), 522: (0.875), 523: (1.25), 524: (1.27), 525: (1.40), 526: (1.04), 527: (1.22), 528: (1.23), 529: (1.15), 530: (30), 531: (1.03), 532: (0.875), 533: (1.04), 534: (1.03), 535: (0.875), 536: (1.04), 537: (1.37), 538: (1.37), 539: (1.19), 540: (1.01), 541: (1.07), 542: (1.03), 543: (0.675), 544: (0.875), 545: (1.01), 546: (0.675), 547: (1.01), 548: (30), 549: (30), 550: (1.04), 551: (45), 552: (1.08), 553: (1.04), 554: (1.04), 555: (1.03), 556: (1.01), 557: (0.875), 558: (1.01), 559: (0.675), 560: (0.675), 561: (1.01), 562: (1.03), 563: (0.875), 564: (0.875), 565: (1.16), 566: (1.13), 567: (1.18), 568: (1.73), 569: (1.36), 570: (1.20), 571: (1.04), 572: (45), 573: (30), 574: (1.28), 575: (1.11), 576: (1.04), 577: (0.875), 578: (30), 579: (1.03), 580: (0.675), 581: (0.675), 582: (0.675), 583: (0.675), 584: (0.675), 585: (0.675), 586: (1.01), 587: (0.675), 588: (1.01), 589: (1.01), 590: (0.875), 591: (1.01), 592: (45), 593: (1.50), 594: (1.32), 595: (1.31), 596: (1.28), 597: (1.03), 598: (0.875), 599: (1.01), 600: (0.675), 601: (1.01), 602: (0.675), 603: (1.01), 604: (0.675), 605: (0.675), 606: (0.675), 607: (0.675), 608: (0.675), 609: (0.675), 610: (0.675), 611: (1.01), 612: (1.03), 613: (1.03), 614: (1.04), 615: (30), 616: (45), 617: (1.04), 618: (1.04), 619: (1.07), 620: (30), 621: (1.04), 622: (1.21), 623: (1.33), 624: (1.28), 625: (1.03), 626: (1.31), 627: (1.17), 628: (1.14), 629: (1.04), 630: (1.03), 631: (0.875), 632: (1.03), 633: (1.03), 634: (1.01), 635: (1.08), 636: (1.57), 637: (1.24), 638: (1.12), 639: (1.01), 640: (1.07), 641: (1.01), 642: (1.01), 643: (0.875), 644: (0.675), 645: (0.675), 646: (0.875), 647: (30), 648: (45), 649: (30), 650: (45), 651: (30), 652: (1.04), 653: (1.03), 654: (1.04), 655: (0.875), 656: (0.875), 657: (1.01), 658: (0.675), 659: (0.675), 660: (1.04), 661: (1.04), 662: (0.875), 663: (1.04), 664: (1.13), 665: (1.08), 666: (1.22), 667: (1.92), 668: (1.26), 669: (1.22), 670: (30), 671: (1.10), 672: (1.17), 673: (1.28), 674: (1.10), 675: (1.04), 676: (1.03), 677: (1.04), 678: (0.875), 679: (0.675), 680: (0.675), 681: (0.675), 682: (0.675), 683: (0.675), 684: (0.675), 685: (1.01), 686: (0.675), 687: (1.01), 688: (0.875), 689: (0.875), 690: (1.01), 691: (1.09), 692: (1.49), 693: (1.23), 694: (1.33), 695: (1.11), 696: (30), 697: (1.01), 698: (0.675), 699: (0.675), 700: (1.01), 701: (0.675), 702: (1.01), 703: (0.675), 704: (0.675), 705: (0.675), 706: (0.675), 707: (0.675), 708: (0.675), 709: (0.675), 710: (1.01), 711: (0.875), 712: (0.875), 713: (1.01), 714: (0.875), 715: (1.03), 716: (1.01), 717: (1.04), 718: (1.07), 719: (1.04), 720: (1.10), 721: (1.16), 722: (1.34), 723: (1.15), 724: (1.04), 725: (1.35), 726: (1.15), 727: (1.04), 728: (1.04), 729: (0.875), 730: (1.01), 731: (1.01), 732: (1.01), 733: (1.01), 734: (1.11), 735: (1.58), 736: (1.22), 737: (1.04), 738: (0.875), 739: (1.07), 740: (1.01), 741: (1.01), 742: (0.875), 743: (0.675), 744: (0.675), 745: (0.875), 746: (30), 747: (45), 748: (45), 749: (1.07), 750: (30), 751: (1.03), 752: (1.04), 753: (1.03), 754: (1.01), 755: (1.01), 756: (0.675), 757: (0.675), 758: (0.675), 759: (45), 760: (0.875), 761: (1.04), 762: (45), 763: (1.15), 764: (1.10), 765: (1.31), 766: (1.80), 767: (1.21), 768: (1.15), 769: (45), 770: (1.08), 771: (1.25), 772: (1.22), 773: (1.08), 774: (1.03), 775: (1.03), 776: (30), 777: (1.01), 778: (0.675), 779: (0.675), 780: (0.675), 781: (0.675), 782: (0.675), 783: (0.675), 784: (0.675), 785: (0.675), 786: (1.01), 787: (0.875), 788: (0.875), 789: (0.875), 790: (1.19), 791: (1.51), 792: (1.28), 793: (1.28), 794: (45), 795: (1.03), 796: (1.01), 797: (0.675), 798: (1.01), 799: (0.675), 800: (0.675), 801: (0.675), 802: (0.675), 803: (0.675), 804: (0.675), 805: (0.675), 806: (0.675), 807: (0.675), 808: (1.01), 809: (1.01), 810: (0.875), 811: (0.875), 812: (0.875), 813: (1.03), 814: (45), 815: (1.03), 816: (30), 817: (1.07), 818: (1.03), 819: (1.14), 820: (1.19), 821: (1.41), 822: (45), 823: (1.12), 824: (1.36), 825: (1.17), 826: (1.04), 827: (1.03), 828: (0.875), 829: (1.03), 830: (0.875), 831: (1.03), 832: (0.875), 833: (1.21), 834: (1.54), 835: (1.20), 836: (0.875), 837: (1.04), 838: (30), 839: (0.675), 840: (0.875), 841: (1.01), 842: (0.675), 843: (1.01), 844: (1.03), 845: (45), 846: (1.04), 847: (45), 848: (1.09), 849: (1.04), 850: (1.04), 851: (1.04), 852: (1.01), 853: (1.01), 854: (1.01), 855: (0.675), 856: (0.675), 857: (1.01), 858: (1.08), 859: (1.03), 860: (0.875), 861: (1.08), 862: (1.17), 863: (1.14), 864: (1.52), 865: (1.54), 866: (1.29), 867: (1.10), 868: (1.08), 869: (1.09), 870: (1.33), 871: (1.19), 872: (45), 873: (0.875), 874: (30), 875: (1.04), 876: (1.01), 877: (0.675), 878: (0.675), 879: (0.675), 880: (0.675), 881: (1.01), 882: (1.01), 883: (0.675), 884: (1.01), 885: (1.01), 886: (1.01), 887: (0.875), 888: (1.03), 889: (1.32), 890: (1.40), 891: (1.28), 892: (1.37), 893: (1.03), 894: (1.03), 895: (1.01), 896: (0.675), 897: (1.01), 898: (0.675), 899: (0.875), 900: (0.675), 901: (1.01), 902: (0.675), 903: (0.675), 904: (0.675), 905: (0.675), 906: (0.675), 907: (1.01), 908: (1.01), 909: (1.01), 910: (1.03), 911: (1.03), 912: (1.04), 913: (30), 914: (1.03), 915: (1.07), 916: (1.09), 917: (1.01), 918: (1.23), 919: (1.30), 920: (1.41), 921: (1.04), 922: (1.24), 923: (1.20), 924: (1.11), 925: (1.04), 926: (0.875), 927: (1.01), 928: (0.875), 929: (0.875), 930: (1.01), 931: (1.03), 932: (1.33), 933: (1.27), 934: (1.21), 935: (1.01), 936: (45), 937: (1.03), 938: (0.675), 939: (0.875), 940: (1.01), 941: (0.675), 942: (1.01), 943: (1.04), 944: (30), 945: (1.04), 946: (45), 947: (1.08), 948: (1.04), 949: (1.03), 950: (1.03), 951: (1.01), 952: (0.875), 953: (1.01), 954: (0.675), 955: (0.675), 956: (1.01), 957: (30), 958: (0.875), 959: (0.875), 960: (1.15), 961: (1.11), 962: (1.15), 963: (1.76), 964: (1.32), 965: (1.26), 966: (45), 967: (1.09), 968: (1.11), 969: (1.34), 970: (1.12), 971: (30), 972: (0.875), 973: (30), 974: (1.03), 975: (1.01), 976: (0.675), 977: (0.675), 978: (0.675), 979: (0.675), 980: (0.675), 981: (0.675), 982: (0.675), 983: (1.01), 984: (1.01), 985: (0.875), 986: (1.01), 987: (45), 988: (1.43), 989: (1.28), 990: (1.29), 991: (1.23), 992: (1.03), 993: (0.875), 994: (0.675), 995: (0.675), 996: (1.01), 997: (0.675), 998: (1.01), 999: (0.675), 1000: (0.675), 1001: (0.675), 1002: (0.675), 1003: (0.675), 1004: (0.675), 1005: (0.675), 1006: (1.01), 1007: (1.01), 1008: (1.01), 1009: (1.03), 1010: (1.04), 1011: (30), 1012: (1.03), 1013: (1.03), 1014: (1.08), 1015: (30), 1016: (30), 1017: (1.20), 1018: (1.36), 1019: (1.31), 1020: (1.03), 1021: (1.37), 1022: (1.20), 1023: (1.13), 1024: (1.04), 1025: (0.875), 1026: (0.875), 1027: (1.03), 1028: (1.03), 1029: (1.01), 1030: (1.07), 1031: (1.57), 1032: (1.25), 1033: (1.10), 1034: (0.875), 1035: (1.07), 1036: (1.01), 1037: (0.675), 1038: (0.875), 1039: (0.675), 1040: (0.675), 1041: (0.875), 1042: (30), 1043: (45), 1044: (30), 1045: (45), 1046: (45), 1047: (1.04), 1048: (1.03), 1049: (1.04), 1050: (1.01), 1051: (1.01), 1052: (0.675), 1053: (0.675), 1054: (0.675), 1055: (0.875), 1056: (0.875), 1057: (1.01), 1058: (1.04), 1059: (1.13), 1060: (1.10), 1061: (1.23), 1062: (2.00), 1063: (1.23), 1064: (1.22), 1065: (30), 1066: (1.10), 1067: (1.17), 1068: (1.35), 1069: (1.10), 1070: (1.04), 1071: (1.03), 1072: (30), 1073: (0.875), 1074: (0.675), 1075: (0.675), 1076: (0.675), 1077: (0.675), 1078: (0.675), 1079: (0.675), 1080: (1.01), 1081: (0.675), 1082: (1.01), 1083: (1.01), 1084: (0.875), 1085: (1.01), 1086: (1.12), 1087: (1.55), 1088: (1.30), 1089: (1.30), 1090: (1.11), 1091: (30), 1092: (0.875), 1093: (0.675), 1094: (0.675), 1095: (1.01), 1096: (0.675), 1097: (1.01), 1098: (0.675), 1099: (0.675), 1100: (0.675), 1101: (0.675), 1102: (0.675), 1103: (0.675), 1104: (0.675), 1105: (0.675), 1106: (0.675), 1107: (0.675), 1108: (0.675), 1109: (0.675), 1110: (0.675), 1111: (0.675), 1112: (0.675), 1113: (0.675), 1114: (0.675), 1115: (0.675), 1116: (0.675), 1117: (0.675), 1118: (0.675), 1119: (0.675), 1120: (0.675), 1121: (0.675), 1122: (0.675), 1123: (0.675), 1124: (0.675), 1125: (0.675), 1126: (0.675), 1127: (0.675), 1128: (0.675), 1129: (0.675), 1130: (0.675), 1131: (0.675), 1132: (0.675), 1133: (0.675), 1134: (0.675), 1135: (0.675), 1136: (0.675), 1137: (0.675), 1138: (0.675), 1139: (0.675), 1140: (0.675), 1141: (0.675), 1142: (0.675), 1143: (0.675), 1144: (0.675), 1145: (0.675), 1146: (0.675), 1147: (0.675), 1148: (0.675), 1149: (0.675), 1150: (0.675), 1151: (0.675), 1152: (0.675), 1153: (0.675), 1154: (0.675), 1155: (0.675), 1156: (0.675), 1157: (0.675), 1158: (0.675), 1159: (0.675), 1160: (0.675), 1161: (0.675), 1162: (0.675), 1163: (0.675), 1164: (0.675), 1165: (0.675), 1166: (0.675), 1167: (0.675), 1168: (0.675), 1169: (0.675), 1170: (0.675), 1171: (0.675), 1172: (0.675), 1173: (0.675), 1174: (0.675), 1175: (0.675), 1176: (0.675), 1177: (0.675), 1178: (0.675), 1179: (0.675), 1180: (0.675), 1181: (0.675), 1182: (0.675), 1183: (0.675), 1184: (0.675), 1185: (0.675), 1186: (0.675), 1187: (0.675), 1188: (0.675), 1189: (0.675), 1190: (0.675), 1191: (0.675), 1192: (0.675), 1193: (0.675), 1194: (0.675), 1195: (0.675), 1196: (0.675), 1197: (0.675), 1198: (0.675), 1199: (0.675), 1200: (0.675), 1201: (0.675), 1202: (0.675), 1203: (0.675), 1204: (0.675), 1205: (0.675), 1206: (0.675), 1207: (0.675), 1208: (0.675), 1209: (0.675), 1210: (0.675), 1211: (0.675), 1212: (0.675), 1213: (0.675), 1214: (0.675), 1215: (0.675), 1216: (0.675), 1217: (0.675), 1218: (0.675), 1219: (0.675), 1220: (0.675), 1221: (0.675), 1222: (0.675), 1223: (0.675), 1224: (0.675), 1225: (0.675), 1226: (0.675), 1227: (0.675), 1228: (0.675), 1229: (0.675), 1230: (0.675), 1231: (0.675), 1232: (0.675), 1233: (0.675), 1234: (0.675), 1235: (0.675), 1236: (0.675), 1237: (0.675), 1238: (0.675), 1239: (0.675), 1240: (0.675), 1241: (0.675), 1242: (0.675), 1243: (0.675), 1244: (0.675), 1245: (0.675), 1246: (0.675), 1247: (0.675), 1248: (0.675), 1249: (0.675), 1250: (0.675), 1251: (0.675), 1252: (0.675), 1253: (0.675), 1254: (0.675), 1255: (1.01), 1256: (30), 1257: (1.08), 1258: (1.04), 1259: (30), 1260: (45), 1261: (1.04), 1262: (1.03), 1263: (1.03), 1264: (1.01), 1265: (0.675), 1266: (0.675), 1267: (0.675), 1268: (0.675), 1269: (0.675), 1270: (0.675), 1271: (0.675), 1272: (0.675), 1273: (0.675), 1274: (0.675), 1275: (0.675), 1276: (0.675), 1277: (0.875), 1278: (45), 1279: (1.35), 1280: (1.60), 1281: (1.45), 1282: (0.875), 1283: (0.875), 1284: (0.675), 1285: (0.675), 1286: (0.675), 1287: (45), 1288: (1.23), 1289: (1.52), 1290: (1.04), 1291: (45), 1292: (0.675), 1293: (0.675), 1294: (0.675), 1295: (0.875), 1296: (1.13), 1297: (1.40), 1298: (1.03), 1299: (0.675), 1300: (0.675), 1301: (0.675), 1302: (0.675), 1303: (0.675), 1304: (1.04), 1305: (1.08), 1306: (1.68), 1307: (45), 1308: (1.04), 1309: (1.03), 1310: (1.01), 1311: (0.675), 1312: (0.675), 1313: (0.675), 1314: (0.675), 1315: (0.675), 1316: (0.675), 1317: (0.675), 1318: (0.675), 1319: (0.675), 1320: (0.675), 1321: (0.675), 1322: (0.675), 1323: (0.675), 1324: (0.675), 1325: (0.675), 1326: (0.675), 1327: (0.675), 1328: (1.03), 1329: (1.61), 1330: (1.36), 1331: (1.20), 1332: (1.22), 1333: (1.40), 1334: (1.16), 1335: (1.24), 1336: (1.33), 1337: (1.63), 1338: (1.56), 1339: (1.25), 1340: (1.79), 1341: (1.34), 1342: (1.36), 1343: (0.875), 1344: (1.17), 1345: (1.34), 1346: (1.03), 1347: (1.09), 1348: (1.24), 1349: (1.10), 1350: (0.675), 1351: (1.04), 1352: (30), 1353: (0.675), 1354: (0.875), 1355: (45), 1356: (1.09), 1357: (1.04), 1358: (45), 1359: (45), 1360: (1.03), 1361: (0.875), 1362: (30), 1363: (0.675), 1364: (0.675), 1365: (0.675), 1366: (0.675), 1367: (0.675), 1368: (0.675), 1369: (0.675), 1370: (0.675), 1371: (0.675), 1372: (0.675), 1373: (0.675), 1374: (0.675), 1375: (1.01), 1376: (30), 1377: (1.12), 1378: (1.41), 1379: (1.56), 1380: (1.23), 1381: (0.875), 1382: (1.01), 1383: (0.675), 1384: (0.675), 1385: (0.675), 1386: (1.07), 1387: (1.39), 1388: (1.40), 1389: (1.04), 1390: (1.04), 1391: (0.675), 1392: (0.675), 1393: (0.675), 1394: (45), 1395: (1.21), 1396: (1.31), 1397: (1.01), 1398: (0.675), 1399: (0.675), 1400: (0.675), 1401: (0.675), 1402: (0.675), 1403: (0.675), 1404: (1.10), 1405: (1.54), 1406: (1.03), 1407: (1.04), 1408: (1.03), 1409: (0.675), 1410: (0.675), 1411: (0.675), 1412: (0.675), 1413: (0.675), 1414: (0.675), 1415: (0.675), 1416: (0.675), 1417: (0.675), 1418: (0.675), 1419: (0.675), 1420: (0.675), 1421: (0.675), 1422: (0.675), 1423: (0.675), 1424: (0.675), 1425: (0.675), 1426: (0.675), 1427: (1.13), 1428: (1.51), 1429: (1.39), 1430: (1.16), 1431: (1.27), 1432: (1.34), 1433: (1.16), 1434: (1.31), 1435: (1.29), 1436: (1.78), 1437: (1.41), 1438: (1.29), 1439: (1.74), 1440: (1.43), 1441: (1.25), 1442: (0.875), 1443: (1.27), 1444: (1.24), 1445: (0.875), 1446: (1.16), 1447: (1.24), 1448: (1.04), 1449: (0.675), 1450: (1.10), 1451: (1.04), 1452: (1.01), 1453: (30), 1454: (1.07), 1455: (1.07), 1456: (1.04), 1457: (45), 1458: (1.07), 1459: (1.03), 1460: (1.03), 1461: (0.875), 1462: (0.675), 1463: (0.675), 1464: (0.675), 1465: (0.675), 1466: (0.675), 1467: (0.675), 1468: (0.675), 1469: (0.675), 1470: (0.675), 1471: (0.675), 1472: (0.675), 1473: (1.01), 1474: (0.875), 1475: (1.03), 1476: (1.16), 1477: (1.48), 1478: (1.60), 1479: (1.10), 1480: (1.03), 1481: (0.675), 1482: (0.675), 1483: (0.675), 1484: (0.675), 1485: (1.11), 1486: (1.45), 1487: (1.21), 1488: (1.04), 1489: (0.875), 1490: (0.675), 1491: (0.675), 1492: (0.675), 1493: (1.07), 1494: (1.31), 1495: (1.17), 1496: (1.01), 1497: (0.675), 1498: (0.675), 1499: (0.675), 1500: (0.675), 1501: (1.03), 1502: (1.01), 1503: (1.41), 1504: (1.36), 1505: (1.03), 1506: (1.04), 1507: (0.875), 1508: (0.675), 1509: (0.675), 1510: (0.675), 1511: (0.675), 1512: (0.675), 1513: (0.675), 1514: (0.675), 1515: (0.675), 1516: (0.675), 1517: (0.675), 1518: (0.675), 1519: (0.675), 1520: (0.675), 1521: (0.675), 1522: (0.675), 1523: (0.675), 1524: (0.675), 1525: (0.675), 1526: (1.19), 1527: (1.58), 1528: (1.34), 1529: (1.13), 1530: (1.36), 1531: (1.32), 1532: (1.16), 1533: (1.34), 1534: (1.33), 1535: (1.81), 1536: (1.32), 1537: (1.47), 1538: (1.54), 1539: (1.43), 1540: (1.12), 1541: (1.03), 1542: (1.34), 1543: (1.14), 1544: (0.875), 1545: (1.25), 1546: (1.21), 1547: (1.01), 1548: (0.675), 1549: (1.15), 1550: (0.675), 1551: (0.675), 1552: (1.11), 1553: (1.07), 1554: (1.04), 1555: (1.01), 1556: (0.875), 1557: (1.04), 1558: (45), 1559: (0.875), 1560: (1.01), 1561: (0.675), 1562: (0.675), 1563: (0.675), 1564: (0.675), 1565: (0.675), 1566: (0.675), 1567: (0.675), 1568: (0.675), 1569: (0.675), 1570: (0.675), 1571: (0.675), 1572: (0.875), 1573: (1.08), 1574: (1.04), 1575: (1.38), 1576: (1.48), 1577: (1.68), 1578: (1.04), 1579: (1.03), 1580: (0.675), 1581: (0.675), 1582: (0.675), 1583: (1.03), 1584: (30), 1585: (1.61), 1586: (1.19), 1587: (1.10), 1588: (1.01), 1589: (0.675), 1590: (0.675), 1591: (1.04), 1592: (1.21), 1593: (1.28), 1594: (30), 1595: (0.675), 1596: (0.675), 1597: (0.675), 1598: (0.675), 1599: (0.675), 1600: (1.03), 1601: (1.01), 1602: (1.33), 1603: (1.18), 1604: (0.875), 1605: (30), 1606: (0.875), 1607: (1.01), 1608: (1.01), 1609: (0.675), 1610: (0.675), 1611: (0.675), 1612: (0.675), 1613: (0.675), 1614: (0.675), 1615: (0.675), 1616: (0.675), 1617: (0.675), 1618: (0.675), 1619: (0.675), 1620: (0.675), 1621: (0.675), 1622: (0.675), 1623: (0.675), 1624: (0.875), 1625: (1.27), 1626: (1.38), 1627: (1.25), 1628: (1.19), 1629: (1.48), 1630: (1.16), 1631: (1.17), 1632: (1.35), 1633: (1.50), 1634: (1.72), 1635: (1.25), 1636: (1.73), 1637: (1.44), 1638: (1.47), 1639: (30), 1640: (1.08), 1641: (1.44), 1642: (1.10), 1643: (1.04), 1644: (1.21), 1645: (1.18), 1646: (0.675), 1647: (1.01), 1648: (1.14), 1649: (0.675), 1650: (1.01), 1651: (1.08), 1652: (1.08), 1653: (30), 1654: (1.04), 1655: (1.07), 1656: (1.04), 1657: (1.03), 1658: (1.03), 1659: (0.675), 1660: (0.675), 1661: (0.675), 1662: (0.675), 1663: (0.675), 1664: (0.675), 1665: (0.675), 1666: (0.675), 1667: (0.675), 1668: (0.675), 1669: (0.675), 1670: (0.675), 1671: (0.875), 1672: (45), 1673: (1.07), 1674: (1.32), 1675: (1.58), 1676: (1.43), 1677: (0.875), 1678: (0.875), 1679: (0.675), 1680: (0.675), 1681: (0.675), 1682: (1.07), 1683: (1.25), 1684: (1.48), 1685: (1.04), 1686: (45), 1687: (0.675), 1688: (0.675), 1689: (0.675), 1690: (0.875), 1691: (1.15), 1692: (1.40), 1693: (0.875), 1694: (0.675), 1695: (0.675), 1696: (0.675), 1697: (0.675), 1698: (0.675), 1699: (1.01), 1700: (1.07), 1701: (1.64), 1702: (1.07), 1703: (1.04), 1704: (1.03), 1705: (1.01), 1706: (0.675), 1707: (0.675), 1708: (0.675), 1709: (0.675), 1710: (0.675), 1711: (0.675), 1712: (0.675), 1713: (0.675), 1714: (0.675), 1715: (0.675), 1716: (0.675), 1717: (0.675), 1718: (0.675), 1719: (0.675), 1720: (0.675), 1721: (0.675), 1722: (0.675), 1723: (1.04), 1724: (1.54), 1725: (1.37), 1726: (1.21), 1727: (1.22), 1728: (1.38), 1729: (1.16), 1730: (1.27), 1731: (1.30), 1732: (1.67), 1733: (1.56), 1734: (1.26), 1735: (1.81), 1736: (1.37), 1737: (1.35), 1738: (0.875), 1739: (1.18), 1740: (1.32), 1741: (1.03), 1742: (1.10), 1743: (1.25), 1744: (1.10), 1745: (0.675), 1746: (30), 1747: (1.04), 1748: (0.675), 1749: (0.875), 1750: (1.04), 1751: (45), 1752: (1.01), 1753: (0.875), 1754: (0.875), 1755: (1.04), 1756: (0.875), 1757: (45), 1758: (0.675), 1759: (0.675), 1760: (0.675), 1761: (0.675), 1762: (0.675), 1763: (0.675), 1764: (0.675), 1765: (0.675), 1766: (0.675), 1767: (0.675), 1768: (0.675), 1769: (1.01), 1770: (1.03), 1771: (1.07), 1772: (1.10), 1773: (1.37), 1774: (1.61), 1775: (1.27), 1776: (0.875), 1777: (1.01), 1778: (0.675), 1779: (0.675), 1780: (0.675), 1781: (1.04), 1782: (1.22), 1783: (1.64), 1784: (45), 1785: (30), 1786: (0.675), 1787: (0.675), 1788: (0.675), 1789: (1.16), 1790: (1.21), 1791: (1.22), 1792: (1.01), 1793: (0.675), 1794: (0.675), 1795: (0.675), 1796: (0.675), 1797: (0.875), 1798: (1.01), 1799: (1.15), 1800: (1.48), 1801: (1.04), 1802: (1.04), 1803: (1.03), 1804: (1.01), 1805: (1.01), 1806: (0.675), 1807: (0.675), 1808: (0.675), 1809: (0.675), 1810: (0.675), 1811: (0.675), 1812: (0.675), 1813: (0.675), 1814: (0.675), 1815: (0.675), 1816: (0.675), 1817: (0.675), 1818: (0.675), 1819: (0.675), 1820: (0.675), 1821: (0.675), 1822: (1.13), 1823: (1.50), 1824: (1.41), 1825: (1.17), 1826: (1.27), 1827: (1.36), 1828: (1.11), 1829: (1.36), 1830: (1.27), 1831: (1.74), 1832: (1.41), 1833: (1.28), 1834: (1.87), 1835: (1.45), 1836: (1.31), 1837: (1.01), 1838: (1.32), 1839: (1.27), 1840: (1.03), 1841: (1.13), 1842: (1.30), 1843: (1.03), 1844: (0.675), 1845: (1.09), 1846: (1.01), 1847: (0.675), 1848: (1.07), 1849: (45), 1850: (1.08), 1851: (1.04), 1852: (30), 1853: (45), 1854: (1.03), 1855: (1.03), 1856: (0.875), 1857: (0.675), 1858: (0.675), 1859: (0.675), 1860: (0.675), 1861: (0.675), 1862: (0.675), 1863: (0.675), 1864: (0.675), 1865: (0.675), 1866: (0.675), 1867: (0.675), 1868: (0.675), 1869: (1.03), 1870: (30), 1871: (1.20), 1872: (1.58), 1873: (1.57), 1874: (1.09), 1875: (1.04), 1876: (0.675), 1877: (0.675), 1878: (0.675), 1879: (1.01), 1880: (1.11), 1881: (1.47), 1882: (1.20), 1883: (1.04), 1884: (0.875), 1885: (0.675), 1886: (0.675), 1887: (0.675), 1888: (1.08), 1889: (1.32), 1890: (1.16), 1891: (1.01), 1892: (0.675), 1893: (0.675), 1894: (0.675), 1895: (0.675), 1896: (1.04), 1897: (1.01), 1898: (1.45), 1899: (1.37), 1900: (0.875), 1901: (1.04), 1902: (0.875), 1903: (0.675), 1904: (0.675), 1905: (0.675), 1906: (0.675), 1907: (0.675), 1908: (0.675), 1909: (0.675), 1910: (0.675), 1911: (0.675), 1912: (0.675), 1913: (0.675), 1914: (0.675), 1915: (0.675), 1916: (0.675), 1917: (0.675), 1918: (0.675), 1919: (0.675), 1920: (0.675), 1921: (1.20), 1922: (1.56), 1923: (1.32), 1924: (1.14), 1925: (1.39), 1926: (1.32), 1927: (1.15), 1928: (1.31), 1929: (1.35), 1930: (1.83), 1931: (1.31), 1932: (1.51), 1933: (1.57), 1934: (1.40), 1935: (1.11), 1936: (1.04), 1937: (1.38), 1938: (1.14), 1939: (0.875), 1940: (1.25), 1941: (1.20), 1942: (1.01), 1943: (0.675), 1944: (1.15), 1945: (0.675), 1946: (0.675), 1947: (1.09), 1948: (30), 1949: (1.04), 1950: (1.01), 1951: (0.875), 1952: (1.04), 1953: (30), 1954: (0.875), 1955: (1.01), 1956: (0.675), 1957: (0.675), 1958: (0.675), 1959: (0.675), 1960: (0.675), 1961: (0.675), 1962: (0.675), 1963: (0.675), 1964: (0.675), 1965: (0.675), 1966: (0.675), 1967: (0.875), 1968: (30), 1969: (1.04), 1970: (1.35), 1971: (1.47), 1972: (1.66), 1973: (1.03), 1974: (1.03), 1975: (0.675), 1976: (0.675), 1977: (0.675), 1978: (1.03), 1979: (45), 1980: (1.62), 1981: (1.17), 1982: (1.10), 1983: (1.01), 1984: (0.675), 1985: (0.675), 1986: (1.04), 1987: (1.21), 1988: (1.27), 1989: (30), 1990: (1.01), 1991: (0.675), 1992: (0.675), 1993: (0.675), 1994: (0.675), 1995: (1.04), 1996: (1.01), 1997: (1.30), 1998: (1.14), 1999: (0.875), 2000: (1.04), 2001: (0.875), 2002: (1.01), 2003: (1.01), 2004: (0.675), 2005: (0.675), 2006: (0.675), 2007: (0.675), 2008: (0.675), 2009: (0.675), 2010: (0.675), 2011: (0.675), 2012: (0.675), 2013: (0.675), 2014: (0.675), 2015: (0.675), 2016: (0.675), 2017: (0.675), 2018: (0.675), 2019: (1.03), 2020: (1.32), 2021: (1.34), 2022: (1.27), 2023: (1.19), 2024: (1.46), 2025: (1.14), 2026: (1.18), 2027: (1.35), 2028: (1.52), 2029: (1.74), 2030: (1.25), 2031: (1.75), 2032: (1.42), 2033: (1.50), 2034: (1.04), 2035: (1.09), 2036: (1.45), 2037: (1.09), 2038: (30), 2039: (1.20), 2040: (1.19), 2041: (0.675), 2042: (0.875), 2043: (1.11), 2044: (0.675), 2045: (1.01), 2046: (1.09), 2047: (1.07), 2048: (30), 2049: (1.04), 2050: (1.08), 2051: (1.04), 2052: (1.04), 2053: (1.03), 2054: (0.675), 2055: (0.675), 2056: (0.675), 2057: (0.675), 2058: (0.675), 2059: (0.675), 2060: (0.675), 2061: (0.675), 2062: (0.675), 2063: (0.675), 2064: (0.675), 2065: (0.675), 2066: (1.01), 2067: (30), 2068: (1.08), 2069: (1.36), 2070: (1.56), 2071: (1.39), 2072: (0.875), 2073: (0.875), 2074: (0.675), 2075: (0.675), 2076: (0.675), 2077: (1.07), 2078: (1.27), 2079: (1.48), 2080: (1.04), 2081: (45), 2082: (0.675), 2083: (0.675), 2084: (0.675), 2085: (1.03), 2086: (1.15), 2087: (1.41), 2088: (0.875), 2089: (0.675), 2090: (0.675), 2091: (0.675), 2092: (0.675), 2093: (0.675), 2094: (1.01), 2095: (1.10), 2096: (1.57), 2097: (45), 2098: (1.04), 2099: (1.03), 2100: (0.675), 2101: (0.675), 2102: (0.675), 2103: (0.675), 2104: (0.675), 2105: (0.675), 2106: (0.675), 2107: (0.675), 2108: (0.675), 2109: (0.675), 2110: (0.675), 2111: (0.675), 2112: (0.675), 2113: (0.675), 2114: (0.675), 2115: (0.675), 2116: (0.675), 2117: (0.675), 2118: (30), 2119: (1.53), 2120: (1.40), 2121: (1.20), 2122: (1.23), 2123: (1.37), 2124: (1.16), 2125: (1.27), 2126: (1.28), 2127: (1.72), 2128: (1.54), 2129: (1.26), 2130: (1.70), 2131: (1.44), 2132: (1.35), 2133: (0.875), 2134: (1.19), 2135: (1.30), 2136: (0.875), 2137: (1.10), 2138: (1.26), 2139: (1.09), 2140: (0.675), 2141: (30), 2142: (30), 2143: (0.675), 2144: (1.03), 2145: (30), 2146: (1.08), 2147: (1.04), 2148: (30), 2149: (45), 2150: (1.03), 2151: (1.03), 2152: (1.04), 2153: (0.675), 2154: (0.675), 2155: (0.675), 2156: (0.675), 2157: (0.675), 2158: (0.675), 2159: (0.675), 2160: (0.675), 2161: (0.675), 2162: (0.675), 2163: (0.675), 2164: (0.675), 2165: (1.01), 2166: (1.03), 2167: (1.10), 2168: (1.42), 2169: (1.60), 2170: (1.21), 2171: (0.875), 2172: (1.01), 2173: (0.675), 2174: (0.675), 2175: (0.675), 2176: (1.10), 2177: (1.39), 2178: (1.37), 2179: (1.03), 2180: (1.04), 2181: (0.675), 2182: (0.675), 2183: (0.675), 2184: (30), 2185: (1.23), 2186: (1.30), 2187: (1.01), 2188: (0.675), 2189: (0.675), 2190: (0.675), 2191: (0.675), 2192: (0.675), 2193: (0.675), 2194: (1.25), 2195: (1.62), 2196: (1.03), 2197: (1.04), 2198: (1.03), 2199: (0.675), 2200: (0.675), 2201: (0.675), 2202: (0.675), 2203: (0.675), 2204: (0.675), 2205: (0.675), 2206: (0.675), 2207: (0.675), 2208: (0.675), 2209: (0.675), 2210: (0.675), 2211: (0.675), 2212: (0.675), 2213: (0.675), 2214: (0.675), 2215: (0.675), 2216: (0.675), 2217: (1.11), 2218: (1.61), 2219: (1.41), 2220: (1.14), 2221: (1.30), 2222: (1.37), 2223: (1.16), 2224: (1.31), 2225: (1.28), 2226: (1.83), 2227: (1.40), 2228: (1.32), 2229: (1.68), 2230: (1.44), 2231: (1.20), 2232: (0.875), 2233: (1.26), 2234: (1.24), 2235: (0.875), 2236: (1.19), 2237: (1.24), 2238: (1.03), 2239: (0.675), 2240: (1.11), 2241: (1.01), 2242: (0.675), 2243: (1.04), 2244: (1.04), 2245: (1.07), 2246: (1.04), 2247: (45), 2248: (45), 2249: (1.03), 2250: (1.03), 2251: (0.875), 2252: (0.675), 2253: (0.675), 2254: (0.675), 2255: (0.675), 2256: (0.675), 2257: (0.675), 2258: (0.675), 2259: (0.675), 2260: (0.675), 2261: (0.675), 2262: (0.675), 2263: (0.675), 2264: (1.03), 2265: (1.04), 2266: (1.19), 2267: (1.53), 2268: (1.58), 2269: (1.07), 2270: (1.04), 2271: (0.675), 2272: (0.675), 2273: (0.675), 2274: (1.01), 2275: (1.11), 2276: (1.48), 2277: (1.20), 2278: (1.04), 2279: (0.875), 2280: (0.675), 2281: (0.675), 2282: (0.675), 2283: (1.09), 2284: (1.33), 2285: (1.14), 2286: (0.675), 2287: (0.675), 2288: (0.675), 2289: (0.675), 2290: (0.675), 2291: (1.01), 2292: (1.01), 2293: (1.32), 2294: (1.37), 2295: (0.875), 2296: (1.04), 2297: (0.875), 2298: (0.675), 2299: (0.675), 2300: (0.675), 2301: (0.675), 2302: (0.675), 2303: (0.675), 2304: (0.675), 2305: (0.675), 2306: (0.675), 2307: (0.675), 2308: (0.675), 2309: (0.675), 2310: (0.675), 2311: (0.675), 2312: (0.675), 2313: (0.675), 2314: (0.675), 2315: (0.675), 2316: (1.18), 2317: (1.54), 2318: (1.29), 2319: (1.16), 2320: (1.39), 2321: (1.31), 2322: (1.15), 2323: (1.31), 2324: (1.36), 2325: (1.83), 2326: (1.30), 2327: (1.54), 2328: (1.53), 2329: (1.39), 2330: (1.11), 2331: (1.04), 2332: (1.39), 2333: (1.13), 2334: (0.875), 2335: (1.24), 2336: (1.21), 2337: (1.01), 2338: (0.675), 2339: (1.17), 2340: (1.01), 2341: (0.875), 2342: (1.08), 2343: (1.07), 2344: (30), 2345: (30), 2346: (1.07), 2347: (30), 2348: (1.03), 2349: (0.875), 2350: (1.01), 2351: (0.675), 2352: (0.675), 2353: (0.675), 2354: (0.675), 2355: (0.675), 2356: (0.675), 2357: (0.675), 2358: (0.675), 2359: (0.675), 2360: (0.675), 2361: (0.675), 2362: (45), 2363: (1.04), 2364: (45), 2365: (1.47), 2366: (1.68), 2367: (1.54), 2368: (1.03), 2369: (1.03), 2370: (0.675), 2371: (0.675), 2372: (0.675), 2373: (1.03), 2374: (1.17), 2375: (1.57), 2376: (1.07), 2377: (1.07), 2378: (1.01), 2379: (0.675), 2380: (0.675), 2381: (1.01), 2382: (1.10), 2383: (1.39), 2384: (1.07), 2385: (0.675), 2386: (0.675), 2387: (0.675), 2388: (0.675), 2389: (0.675), 2390: (0.875), 2391: (1.03), 2392: (1.58), 2393: (1.15), 2394: (1.03), 2395: (1.04), 2396: (1.01), 2397: (0.675), 2398: (0.675), 2399: (0.675), 2400: (0.675), 2401: (0.675), 2402: (0.675), 2403: (0.675), 2404: (0.675), 2405: (0.675), 2406: (0.675), 2407: (0.675), 2408: (0.675), 2409: (0.675), 2410: (0.675), 2411: (0.675), 2412: (0.675), 2413: (0.675), 2414: (1.01), 2415: (1.50), 2416: (1.41), 2417: (1.27), 2418: (1.19), 2419: (1.39), 2420: (1.20), 2421: (1.21), 2422: (1.32), 2423: (1.54), 2424: (1.72), 2425: (1.26), 2426: (1.76), 2427: (1.39), 2428: (1.43), 2429: (1.04), 2430: (1.10), 2431: (1.38), 2432: (30), 2433: (30), 2434: (1.24), 2435: (1.16), 2436: (0.675), 2437: (0.875), 2438: (1.17), 2439: (0.675), 2440: (0.675), 2441: (0.675), 2442: (0.675), 2443: (0.675), 2444: (0.675), 2445: (0.675), 2446: (0.675), 2447: (0.675), 2448: (0.675), 2449: (0.675), 2450: (0.675), 2451: (0.675), 2452: (0.675), 2453: (0.675), 2454: (0.675), 2455: (0.675), 2456: (0.675), 2457: (0.675), 2458: (0.675), 2459: (0.675), 2460: (0.675), 2461: (0.675), 2462: (0.675), 2463: (0.675), 2464: (0.675), 2465: (0.675), 2466: (0.675), 2467: (0.675), 2468: (0.675), 2469: (0.675), 2470: (0.675), 2471: (0.675), 2472: (0.675), 2473: (0.675), 2474: (0.675), 2475: (0.675), 2476: (0.675), 2477: (0.675), 2478: (0.675), 2479: (0.675), 2480: (0.675), 2481: (0.675), 2482: (0.675), 2483: (0.675), 2484: (0.675), 2485: (0.675), 2486: (0.675), 2487: (0.675), 2488: (0.675), 2489: (0.675), 2490: (0.675), 2491: (0.675), 2492: (0.675), 2493: (0.675), 2494: (0.675), 2495: (0.675), 2496: (0.675), 2497: (0.675), 2498: (0.675), 2499: (0.675), 2500: (0.675), 2501: (0.675), 2502: (0.675), 2503: (0.675), 2504: (0.675), 2505: (0.675), 2506: (0.675), 2507: (0.675), 2508: (0.675), 2509: (0.675), 2510: (0.675), 2511: (0.675), 2512: (0.675), 2513: (0.675), 2514: (0.675), 2515: (0.675), 2516: (0.675), 2517: (0.675), 2518: (0.675), 2519: (0.675), 2520: (0.675), 2521: (0.675), 2522: (0.675), 2523: (0.675), 2524: (0.675), 2525: (0.675), 2526: (0.675), 2527: (0.675), 2528: (0.675), 2529: (0.675), 2530: (0.675), 2531: (0.675), 2532: (0.675), 2533: (0.675), 2534: (0.675), 2535: (0.675), 2536: (0.675), 2537: (0.675), 2538: (0.675), 2539: (0.675), 2540: (0.675), 2541: (0.675)\"#@param {type:\"string\"}\n",
        "rotation_3d_x = \"0:(0)\"#@param {type:\"string\"}\n",
        "rotation_3d_y = \"0: (0.00), 1: (0.00), 2: (0.00), 3: (0.00), 4: (0.00), 5: (0.00), 6: (0.00), 7: (0.03), 8: (0.02), 9: (0.02), 10: (0.01), 11: (0.01), 12: (0.01), 13: (0.01), 14: (0.01), 15: (0.01), 16: (0.01), 17: (0.01), 18: (0.06), 19: (0.05), 20: (0.04), 21: (0.03), 22: (0.03), 23: (0.03), 24: (0.04), 25: (0.05), 26: (0.04), 27: (0.04), 28: (0.03), 29: (0.03), 30: (0.02), 31: (0.02), 32: (0.02), 33: (0.02), 34: (0.03), 35: (0.04), 36: (0.04), 37: (0.03), 38: (0.03), 39: (0.02), 40: (0.06), 41: (0.04), 42: (0.04), 43: (0.03), 44: (0.02), 45: (0.03), 46: (0.04), 47: (0.03), 48: (0.03), 49: (0.03), 50: (0.04), 51: (0.07), 52: (0.05), 53: (0.04), 54: (0.03), 55: (0.03), 56: (0.03), 57: (0.04), 58: (0.03), 59: (0.03), 60: (0.05), 61: (0.08), 62: (0.07), 63: (0.07), 64: (0.07), 65: (0.05), 66: (0.05), 67: (0.06), 68: (0.07), 69: (0.06), 70: (0.05), 71: (0.04), 72: (0.04), 73: (0.04), 74: (0.04), 75: (0.03), 76: (0.03), 77: (0.05), 78: (0.05), 79: (0.06), 80: (0.05), 81: (0.04), 82: (0.12), 83: (0.14), 84: (0.13), 85: (0.08), 86: (0.05), 87: (0.05), 88: (0.05), 89: (0.05), 90: (0.03), 91: (0.02), 92: (0.03), 93: (0.10), 94: (0.07), 95: (0.06), 96: (0.05), 97: (0.03), 98: (0.03), 99: (0.02), 100: (0.01), 101: (0.01), 102: (0.01), 103: (0.06), 104: (0.09), 105: (0.10), 106: (0.07), 107: (0.07), 108: (0.06), 109: (0.07), 110: (0.06), 111: (0.05), 112: (0.04), 113: (0.03), 114: (0.03), 115: (0.03), 116: (0.02), 117: (0.02), 118: (0.02), 119: (0.03), 120: (0.04), 121: (0.03), 122: (0.02), 123: (0.02), 124: (0.03), 125: (0.05), 126: (0.05), 127: (0.06), 128: (0.09), 129: (0.08), 130: (0.09), 131: (0.08), 132: (0.07), 133: (0.06), 134: (0.06), 135: (0.11), 136: (0.08), 137: (0.07), 138: (0.06), 139: (0.06), 140: (0.04), 141: (0.06), 142: (0.05), 143: (0.04), 144: (0.03), 145: (0.11), 146: (0.11), 147: (0.10), 148: (0.09), 149: (0.08), 150: (0.07), 151: (0.06), 152: (0.05), 153: (0.05), 154: (0.04), 155: (0.04), 156: (0.03), 157: (0.04), 158: (0.03), 159: (0.03), 160: (0.04), 161: (0.06), 162: (0.06), 163: (0.05), 164: (0.04), 165: (0.04), 166: (0.06), 167: (0.11), 168: (0.10), 169: (0.10), 170: (0.09), 171: (0.10), 172: (0.12), 173: (0.12), 174: (0.10), 175: (0.09), 176: (0.10), 177: (0.17), 178: (0.11), 179: (0.12), 180: (0.09), 181: (0.07), 182: (0.05), 183: (0.06), 184: (0.04), 185: (0.06), 186: (0.07), 187: (0.13), 188: (0.09), 189: (0.09), 190: (0.06), 191: (0.06), 192: (0.04), 193: (0.07), 194: (0.06), 195: (0.05), 196: (0.04), 197: (0.04), 198: (0.03), 199: (0.03), 200: (0.03), 201: (0.02), 202: (0.02), 203: (0.05), 204: (0.06), 205: (0.05), 206: (0.05), 207: (0.04), 208: (0.04), 209: (0.11), 210: (0.06), 211: (0.05), 212: (0.04), 213: (0.07), 214: (0.10), 215: (0.09), 216: (0.06), 217: (0.04), 218: (0.04), 219: (0.10), 220: (0.08), 221: (0.07), 222: (0.06), 223: (0.06), 224: (0.05), 225: (0.05), 226: (0.07), 227: (0.05), 228: (0.05), 229: (0.10), 230: (0.10), 231: (0.09), 232: (0.08), 233: (0.07), 234: (0.06), 235: (0.06), 236: (0.06), 237: (0.05), 238: (0.04), 239: (0.05), 240: (0.03), 241: (0.03), 242: (0.04), 243: (0.06), 244: (0.05), 245: (0.06), 246: (0.05), 247: (0.06), 248: (0.06), 249: (0.04), 250: (0.04), 251: (0.10), 252: (0.07), 253: (0.07), 254: (0.06), 255: (0.05), 256: (0.04), 257: (0.06), 258: (0.06), 259: (0.04), 260: (0.03), 261: (0.05), 262: (0.07), 263: (0.05), 264: (0.04), 265: (0.03), 266: (0.03), 267: (0.02), 268: (0.02), 269: (0.02), 270: (0.01), 271: (0.02), 272: (0.12), 273: (0.09), 274: (0.10), 275: (0.11), 276: (0.09), 277: (0.07), 278: (0.06), 279: (0.06), 280: (0.05), 281: (0.05), 282: (0.05), 283: (0.04), 284: (0.05), 285: (0.08), 286: (0.08), 287: (0.09), 288: (0.09), 289: (0.07), 290: (0.08), 291: (0.09), 292: (0.09), 293: (0.08), 294: (0.08), 295: (0.08), 296: (0.08), 297: (0.07), 298: (0.08), 299: (0.08), 300: (0.07), 301: (0.06), 302: (0.06), 303: (0.09), 304: (0.11), 305: (0.06), 306: (0.05), 307: (0.05), 308: (0.04), 309: (0.03), 310: (0.04), 311: (0.03), 312: (0.03), 313: (0.03), 314: (0.14), 315: (0.11), 316: (0.08), 317: (0.08), 318: (0.06), 319: (0.05), 320: (0.05), 321: (0.05), 322: (0.05), 323: (0.04), 324: (0.04), 325: (0.03), 326: (0.03), 327: (0.03), 328: (0.03), 329: (0.03), 330: (0.05), 331: (0.05), 332: (0.06), 333: (0.05), 334: (0.03), 335: (0.06), 336: (0.10), 337: (0.09), 338: (0.08), 339: (0.08), 340: (0.08), 341: (0.08), 342: (0.06), 343: (0.06), 344: (0.04), 345: (0.05), 346: (0.09), 347: (0.07), 348: (0.07), 349: (0.06), 350: (0.05), 351: (0.07), 352: (0.07), 353: (0.07), 354: (0.03), 355: (0.03), 356: (0.11), 357: (0.11), 358: (0.08), 359: (0.12), 360: (0.13), 361: (0.07), 362: (0.12), 363: (0.18), 364: (0.14), 365: (0.08), 366: (0.09), 367: (0.17), 368: (0.13), 369: (0.08), 370: (0.05), 371: (0.04), 372: (0.07), 373: (0.05), 374: (0.04), 375: (0.03), 376: (0.04), 377: (0.07), 378: (0.07), 379: (0.07), 380: (0.06), 381: (0.04), 382: (0.06), 383: (0.11), 384: (0.10), 385: (0.13), 386: (0.07), 387: (0.08), 388: (0.16), 389: (0.16), 390: (0.13), 391: (0.09), 392: (0.07), 393: (0.07), 394: (0.07), 395: (0.09), 396: (0.07), 397: (0.07), 398: (0.12), 399: (0.14), 400: (0.11), 401: (0.12), 402: (0.09), 403: (0.11), 404: (0.15), 405: (0.14), 406: (0.11), 407: (0.08), 408: (0.07), 409: (0.10), 410: (0.12), 411: (0.10), 412: (0.09), 413: (0.09), 414: (0.09), 415: (0.10), 416: (0.09), 417: (0.05), 418: (0.04), 419: (0.05), 420: (0.09), 421: (0.05), 422: (0.04), 423: (0.04), 424: (0.05), 425: (0.04), 426: (0.05), 427: (0.04), 428: (0.04), 429: (0.03), 430: (0.06), 431: (0.10), 432: (0.06), 433: (0.03), 434: (0.03), 435: (0.04), 436: (0.04), 437: (0.02), 438: (0.02), 439: (0.01), 440: (0.03), 441: (0.07), 442: (0.07), 443: (0.06), 444: (0.07), 445: (0.06), 446: (0.12), 447: (0.10), 448: (0.09), 449: (0.07), 450: (0.07), 451: (0.06), 452: (0.05), 453: (0.05), 454: (0.04), 455: (0.05), 456: (0.09), 457: (0.11), 458: (0.08), 459: (0.08), 460: (0.08), 461: (0.05), 462: (0.15), 463: (0.11), 464: (0.07), 465: (0.05), 466: (0.07), 467: (0.07), 468: (0.07), 469: (0.09), 470: (0.06), 471: (0.05), 472: (0.08), 473: (0.07), 474: (0.07), 475: (0.08), 476: (0.07), 477: (0.06), 478: (0.05), 479: (0.04), 480: (0.04), 481: (0.03), 482: (0.04), 483: (0.13), 484: (0.09), 485: (0.08), 486: (0.07), 487: (0.06), 488: (0.05), 489: (0.06), 490: (0.06), 491: (0.05), 492: (0.06), 493: (0.06), 494: (0.07), 495: (0.07), 496: (0.05), 497: (0.05), 498: (0.06), 499: (0.06), 500: (0.08), 501: (0.06), 502: (0.05), 503: (0.04), 504: (0.10), 505: (0.11), 506: (0.08), 507: (0.06), 508: (0.05), 509: (0.06), 510: (0.10), 511: (0.07), 512: (0.05), 513: (0.05), 514: (0.08), 515: (0.20), 516: (0.09), 517: (0.07), 518: (0.06), 519: (0.05), 520: (0.04), 521: (0.05), 522: (0.04), 523: (0.04), 524: (0.04), 525: (0.04), 526: (0.04), 527: (0.03), 528: (0.03), 529: (0.03), 530: (0.02), 531: (0.02), 532: (0.02), 533: (0.02), 534: (0.03), 535: (0.02), 536: (0.02), 537: (0.03), 538: (0.02), 539: (0.03), 540: (0.02), 541: (0.02), 542: (0.02), 543: (0.02), 544: (0.02), 545: (0.01), 546: (0.02), 547: (0.01), 548: (0.01), 549: (0.01), 550: (0.01), 551: (0.02), 552: (0.02), 553: (0.01), 554: (0.01), 555: (0.01), 556: (0.01), 557: (0.01), 558: (0.01), 559: (0.02), 560: (0.02), 561: (0.02), 562: (0.02), 563: (0.02), 564: (0.02), 565: (0.01), 566: (0.02), 567: (0.01), 568: (0.01), 569: (0.02), 570: (0.05), 571: (0.04), 572: (0.04), 573: (0.04), 574: (0.04), 575: (0.03), 576: (0.03), 577: (0.04), 578: (0.05), 579: (0.03), 580: (0.03), 581: (0.05), 582: (0.08), 583: (0.07), 584: (0.10), 585: (0.12), 586: (0.07), 587: (0.04), 588: (0.03), 589: (0.03), 590: (0.04), 591: (0.06), 592: (0.09), 593: (0.04), 594: (0.03), 595: (0.03), 596: (0.03), 597: (0.02), 598: (0.03), 599: (0.05), 600: (0.06), 601: (0.04), 602: (0.03), 603: (0.04), 604: (0.04), 605: (0.04), 606: (0.05), 607: (0.04), 608: (0.04), 609: (0.05), 610: (0.06), 611: (0.09), 612: (0.15), 613: (0.10), 614: (0.07), 615: (0.06), 616: (0.06), 617: (0.03), 618: (0.02), 619: (0.03), 620: (0.04), 621: (0.04), 622: (0.04), 623: (0.04), 624: (0.03), 625: (0.03), 626: (0.05), 627: (0.06), 628: (0.06), 629: (0.04), 630: (0.04), 631: (0.02), 632: (0.03), 633: (0.03), 634: (0.04), 635: (0.03), 636: (0.03), 637: (0.04), 638: (0.05), 639: (0.04), 640: (0.04), 641: (0.05), 642: (0.03), 643: (0.03), 644: (0.01), 645: (0.02), 646: (0.02), 647: (0.01), 648: (0.02), 649: (0.02), 650: (0.02), 651: (0.02), 652: (0.02), 653: (0.02), 654: (0.02), 655: (0.02), 656: (0.03), 657: (0.03), 658: (0.03), 659: (0.04), 660: (0.05), 661: (0.01), 662: (0.01), 663: (0.02), 664: (0.02), 665: (0.03), 666: (0.03), 667: (0.04), 668: (0.04), 669: (0.03), 670: (0.04), 671: (0.07), 672: (0.01), 673: (0.02), 674: (0.03), 675: (0.04), 676: (0.04), 677: (0.06), 678: (0.07), 679: (0.06), 680: (0.06), 681: (0.04), 682: (0.01), 683: (0.06), 684: (0.03), 685: (0.05), 686: (0.04), 687: (0.03), 688: (0.02), 689: (0.01), 690: (0.01), 691: (0.01), 692: (0.02), 693: (0.03), 694: (0.01), 695: (0.02), 696: (0.02), 697: (0.01), 698: (0.02), 699: (0.03), 700: (0.03), 701: (0.03), 702: (0.01), 703: (0.02), 704: (0.01), 705: (0.00), 706: (0.01), 707: (0.00), 708: (0.00), 709: (0.01), 710: (0.01), 711: (0.02), 712: (0.02), 713: (0.02), 714: (0.01), 715: (0.01), 716: (0.01), 717: (0.02), 718: (0.03), 719: (0.04), 720: (0.02), 721: (0.01), 722: (0.02), 723: (0.01), 724: (0.01), 725: (0.00), 726: (0.00), 727: (0.01), 728: (0.01), 729: (0.01), 730: (0.01), 731: (0.01), 732: (0.01), 733: (0.03), 734: (0.02), 735: (0.02), 736: (0.04), 737: (0.04), 738: (0.02), 739: (0.03), 740: (0.03), 741: (0.03), 742: (0.02), 743: (0.03), 744: (0.06), 745: (0.05), 746: (0.03), 747: (0.04), 748: (0.04), 749: (0.03), 750: (0.05), 751: (0.06), 752: (0.06), 753: (0.04), 754: (0.01), 755: (0.02), 756: (0.01), 757: (0.01), 758: (0.01), 759: (0.01), 760: (0.01), 761: (0.02), 762: (0.02), 763: (0.01), 764: (0.01), 765: (0.02), 766: (0.02), 767: (0.01), 768: (0.01), 769: (0.01), 770: (0.01), 771: (0.02), 772: (0.01), 773: (0.01), 774: (0.01), 775: (0.02), 776: (0.01), 777: (0.02), 778: (0.02), 779: (0.04), 780: (0.06), 781: (0.04), 782: (0.02), 783: (0.04), 784: (0.03), 785: (0.04), 786: (0.04), 787: (0.03), 788: (0.02), 789: (0.01), 790: (0.02), 791: (0.01), 792: (0.00), 793: (0.00), 794: (0.00), 795: (0.00), 796: (0.00), 797: (0.01), 798: (0.01), 799: (0.01), 800: (0.01), 801: (0.01), 802: (0.01), 803: (0.02), 804: (0.01), 805: (0.00), 806: (0.00), 807: (0.00), 808: (0.01), 809: (0.00), 810: (0.00), 811: (0.00), 812: (0.00), 813: (0.00), 814: (0.00), 815: (0.00), 816: (0.00), 817: (0.01), 818: (0.00), 819: (0.01), 820: (0.03), 821: (0.03), 822: (0.02), 823: (0.03), 824: (0.02), 825: (0.02), 826: (0.04), 827: (0.04), 828: (0.02), 829: (0.03), 830: (0.01), 831: (0.01), 832: (0.07), 833: (0.15), 834: (0.08), 835: (0.08), 836: (0.22), 837: (0.09), 838: (0.01), 839: (0.01), 840: (0.00), 841: (0.00), 842: (0.01), 843: (0.01), 844: (0.00), 845: (0.00), 846: (0.00), 847: (0.00), 848: (0.00), 849: (0.00), 850: (0.00), 851: (0.00), 852: (0.00), 853: (0.00), 854: (0.00), 855: (0.00), 856: (0.00), 857: (0.00), 858: (0.01), 859: (0.01), 860: (0.01), 861: (0.01), 862: (0.00), 863: (0.00), 864: (0.00), 865: (0.00), 866: (0.00), 867: (0.00), 868: (0.00), 869: (0.00), 870: (0.00), 871: (0.00), 872: (0.00), 873: (0.00), 874: (0.00), 875: (0.00), 876: (0.00), 877: (0.00), 878: (0.00), 879: (0.01), 880: (0.00), 881: (0.01), 882: (0.01), 883: (0.00), 884: (0.00), 885: (0.00), 886: (0.00), 887: (0.01), 888: (0.01), 889: (0.00), 890: (0.00), 891: (0.01), 892: (0.01), 893: (0.01), 894: (0.00), 895: (0.01), 896: (0.01), 897: (0.01), 898: (0.02), 899: (0.01), 900: (0.01), 901: (0.01), 902: (0.01), 903: (0.00), 904: (0.00), 905: (0.00), 906: (0.01), 907: (0.01), 908: (0.01), 909: (0.01), 910: (0.01), 911: (0.01), 912: (0.02), 913: (0.03), 914: (0.03), 915: (0.03), 916: (0.03), 917: (0.03), 918: (0.03), 919: (0.02), 920: (0.01), 921: (0.01), 922: (0.01), 923: (0.01), 924: (0.01), 925: (0.01), 926: (0.01), 927: (0.01), 928: (0.02), 929: (0.03), 930: (0.02), 931: (0.02), 932: (0.01), 933: (0.03), 934: (0.02), 935: (0.01), 936: (0.01), 937: (0.02), 938: (0.02), 939: (0.02), 940: (0.01), 941: (0.01), 942: (0.01), 943: (0.01), 944: (0.02), 945: (0.01), 946: (0.01), 947: (0.01), 948: (0.00), 949: (0.00), 950: (0.00), 951: (0.00), 952: (0.01), 953: (0.01), 954: (0.01), 955: (0.00), 956: (0.00), 957: (0.00), 958: (0.00), 959: (0.00), 960: (0.00), 961: (0.00), 962: (0.00), 963: (0.00), 964: (0.00), 965: (0.00), 966: (0.00), 967: (0.00), 968: (0.00), 969: (0.00), 970: (0.00), 971: (0.00), 972: (0.00), 973: (0.00), 974: (0.00), 975: (0.00), 976: (0.00), 977: (0.00), 978: (0.00), 979: (0.00), 980: (0.00), 981: (0.00), 982: (0.00), 983: (0.00), 984: (0.00), 985: (0.00), 986: (0.00), 987: (0.00), 988: (0.00), 989: (0.00), 990: (0.00), 991: (0.00), 992: (0.00), 993: (0.00), 994: (0.00), 995: (0.00), 996: (0.00), 997: (0.00), 998: (0.00), 999: (0.00), 1000: (0.01), 1001: (0.01), 1002: (0.01), 1003: (0.02), 1004: (0.02), 1005: (0.02), 1006: (0.03), 1007: (0.03), 1008: (0.03), 1009: (0.02), 1010: (0.02), 1011: (0.03), 1012: (0.03), 1013: (0.03), 1014: (0.03), 1015: (0.05), 1016: (0.04), 1017: (0.03), 1018: (0.04), 1019: (0.01), 1020: (0.02), 1021: (0.05), 1022: (0.08), 1023: (0.07), 1024: (0.08), 1025: (0.08), 1026: (0.08), 1027: (0.10), 1028: (0.14), 1029: (0.17), 1030: (0.23), 1031: (0.16), 1032: (0.20), 1033: (0.23), 1034: (0.17), 1035: (0.14), 1036: (0.13), 1037: (0.12), 1038: (0.18), 1039: (0.20), 1040: (0.15), 1041: (0.10), 1042: (0.06), 1043: (0.05), 1044: (0.04), 1045: (0.04), 1046: (0.05), 1047: (0.06), 1048: (0.08), 1049: (0.09), 1050: (0.09), 1051: (0.08), 1052: (0.04), 1053: (0.04), 1054: (0.04), 1055: (0.07), 1056: (0.08), 1057: (0.11), 1058: (0.13), 1059: (0.08), 1060: (0.08), 1061: (0.08), 1062: (0.06), 1063: (0.03), 1064: (0.05), 1065: (0.04), 1066: (0.04), 1067: (0.04), 1068: (0.05), 1069: (0.09), 1070: (0.12), 1071: (0.13), 1072: (0.10), 1073: (0.06), 1074: (0.10), 1075: (0.11), 1076: (0.11), 1077: (0.14), 1078: (0.18), 1079: (0.29), 1080: (0.19), 1081: (0.18), 1082: (0.20), 1083: (0.13), 1084: (0.08), 1085: (0.07), 1086: (0.08), 1087: (0.05), 1088: (0.04), 1089: (0.05), 1090: (0.08), 1091: (0.06), 1092: (0.07), 1093: (0.05), 1094: (0.02), 1095: (0.02), 1096: (0.05), 1097: (0.06), 1098: (0.09), 1099: (0.07), 1100: (0.07), 1101: (0.08), 1102: (0.09), 1103: (0.10), 1104: (0.07), 1105: (0.06), 1106: (0.06), 1107: (0.03), 1108: (0.05), 1109: (0.04), 1110: (0.04), 1111: (0.08), 1112: (0.07), 1113: (0.07), 1114: (0.07), 1115: (0.12), 1116: (0.10), 1117: (0.11), 1118: (0.10), 1119: (0.11), 1120: (0.10), 1121: (0.06), 1122: (0.08), 1123: (0.07), 1124: (0.10), 1125: (0.08), 1126: (0.04), 1127: (0.06), 1128: (0.04), 1129: (0.04), 1130: (0.06), 1131: (0.05), 1132: (0.12), 1133: (0.10), 1134: (0.09), 1135: (0.08), 1136: (0.08), 1137: (0.09), 1138: (0.18), 1139: (0.13), 1140: (0.09), 1141: (0.07), 1142: (0.07), 1143: (0.09), 1144: (0.07), 1145: (0.07), 1146: (0.02), 1147: (0.01), 1148: (0.04), 1149: (0.03), 1150: (0.04), 1151: (0.05), 1152: (0.06), 1153: (0.09), 1154: (0.07), 1155: (0.08), 1156: (0.07), 1157: (0.08), 1158: (0.07), 1159: (0.12), 1160: (0.12), 1161: (0.17), 1162: (0.16), 1163: (0.12), 1164: (0.14), 1165: (0.09), 1166: (0.08), 1167: (0.05), 1168: (0.02), 1169: (0.04), 1170: (0.09), 1171: (0.09), 1172: (0.14), 1173: (0.18), 1174: (0.14), 1175: (0.12), 1176: (0.13), 1177: (0.07), 1178: (0.03), 1179: (0.03), 1180: (0.04), 1181: (0.03), 1182: (0.05), 1183: (0.03), 1184: (0.04), 1185: (0.03), 1186: (0.04), 1187: (0.08), 1188: (0.11), 1189: (0.09), 1190: (0.07), 1191: (0.06), 1192: (0.08), 1193: (0.15), 1194: (0.08), 1195: (0.12), 1196: (0.15), 1197: (0.18), 1198: (0.18), 1199: (0.13), 1200: (0.10), 1201: (0.17), 1202: (0.13), 1203: (0.12), 1204: (0.18), 1205: (0.17), 1206: (0.25), 1207: (0.31), 1208: (0.30), 1209: (0.26), 1210: (0.15), 1211: (0.05), 1212: (0.05), 1213: (0.08), 1214: (0.11), 1215: (0.09), 1216: (0.07), 1217: (0.07), 1218: (0.05), 1219: (0.09), 1220: (0.07), 1221: (0.04), 1222: (0.08), 1223: (0.11), 1224: (0.10), 1225: (0.08), 1226: (0.11), 1227: (0.17), 1228: (0.26), 1229: (0.27), 1230: (0.24), 1231: (0.07), 1232: (0.03), 1233: (0.04), 1234: (0.06), 1235: (0.06), 1236: (0.06), 1237: (0.09), 1238: (0.11), 1239: (0.12), 1240: (0.12), 1241: (0.10), 1242: (0.04), 1243: (0.09), 1244: (0.11), 1245: (0.10), 1246: (0.14), 1247: (0.09), 1248: (0.11), 1249: (0.12), 1250: (0.12), 1251: (0.11), 1252: (0.09), 1253: (0.07), 1254: (0.06), 1255: (0.07), 1256: (0.06), 1257: (0.09), 1258: (0.06), 1259: (0.11), 1260: (0.08), 1261: (0.08), 1262: (0.08), 1263: (0.03), 1264: (0.06), 1265: (0.06), 1266: (0.05), 1267: (0.05), 1268: (0.04), 1269: (0.05), 1270: (0.05), 1271: (0.06), 1272: (0.05), 1273: (0.02), 1274: (0.03), 1275: (0.04), 1276: (0.02), 1277: (0.02), 1278: (0.04), 1279: (0.04), 1280: (0.04), 1281: (0.06), 1282: (0.05), 1283: (0.05), 1284: (0.03), 1285: (0.10), 1286: (0.10), 1287: (0.11), 1288: (0.11), 1289: (0.11), 1290: (0.10), 1291: (0.11), 1292: (0.07), 1293: (0.06), 1294: (0.03), 1295: (0.02), 1296: (0.06), 1297: (0.07), 1298: (0.07), 1299: (0.08), 1300: (0.08), 1301: (0.11), 1302: (0.08), 1303: (0.08), 1304: (0.06), 1305: (0.05), 1306: (0.09), 1307: (0.07), 1308: (0.05), 1309: (0.05), 1310: (0.09), 1311: (0.09), 1312: (0.10), 1313: (0.09), 1314: (0.09), 1315: (0.09), 1316: (0.09), 1317: (0.08), 1318: (0.07), 1319: (0.07), 1320: (0.09), 1321: (0.12), 1322: (0.13), 1323: (0.14), 1324: (0.12), 1325: (0.09), 1326: (0.08), 1327: (0.09), 1328: (0.09), 1329: (0.08), 1330: (0.07), 1331: (0.07), 1332: (0.06), 1333: (0.06), 1334: (0.07), 1335: (0.07), 1336: (0.06), 1337: (0.03), 1338: (0.03), 1339: (0.06), 1340: (0.10), 1341: (0.05), 1342: (0.05), 1343: (0.08), 1344: (0.08), 1345: (0.08), 1346: (0.11), 1347: (0.11), 1348: (0.06), 1349: (0.05), 1350: (0.04), 1351: (0.06), 1352: (0.07), 1353: (0.05), 1354: (0.04), 1355: (0.06), 1356: (0.05), 1357: (0.07), 1358: (0.05), 1359: (0.09), 1360: (0.13), 1361: (0.14), 1362: (0.21), 1363: (0.23), 1364: (0.22), 1365: (0.16), 1366: (0.15), 1367: (0.19), 1368: (0.22), 1369: (0.20), 1370: (0.20), 1371: (0.27), 1372: (0.23), 1373: (0.26), 1374: (0.27), 1375: (0.30), 1376: (0.33), 1377: (0.34), 1378: (0.43), 1379: (0.22), 1380: (0.32), 1381: (0.30), 1382: (0.50), 1383: (0.50), 1384: (0.53), 1385: (0.49), 1386: (0.55), 1387: (0.41), 1388: (0.65), 1389: (0.69), 1390: (0.34), 1391: (0.69), 1392: (0.44), 1393: (0.26), 1394: (0.32), 1395: (0.30), 1396: (0.31), 1397: (0.40), 1398: (0.44), 1399: (0.31), 1400: (0.16), 1401: (0.28), 1402: (0.33), 1403: (0.47), 1404: (0.46), 1405: (0.49), 1406: (0.78), 1407: (0.77), 1408: (0.74), 1409: (0.43), 1410: (0.59), 1411: (0.76), 1412: (0.51), 1413: (0.38), 1414: (0.39), 1415: (0.45), 1416: (0.47), 1417: (0.59), 1418: (0.57), 1419: (0.37), 1420: (0.48), 1421: (0.42), 1422: (0.31), 1423: (0.29), 1424: (0.47), 1425: (0.54), 1426: (0.33), 1427: (0.42), 1428: (0.35), 1429: (0.35), 1430: (0.30), 1431: (0.32), 1432: (0.14), 1433: (0.20), 1434: (0.21), 1435: (0.24), 1436: (0.21), 1437: (0.17), 1438: (0.20), 1439: (0.31), 1440: (0.34), 1441: (0.19), 1442: (0.14), 1443: (0.08), 1444: (0.07), 1445: (0.09), 1446: (0.12), 1447: (0.11), 1448: (0.18), 1449: (0.29), 1450: (0.33), 1451: (0.29), 1452: (0.31), 1453: (0.23), 1454: (0.14), 1455: (0.17), 1456: (0.17), 1457: (0.13), 1458: (0.15), 1459: (0.14), 1460: (0.20), 1461: (0.23), 1462: (0.23), 1463: (0.16), 1464: (0.12), 1465: (0.14), 1466: (0.14), 1467: (0.12), 1468: (0.15), 1469: (0.18), 1470: (0.37), 1471: (0.41), 1472: (0.24), 1473: (0.21), 1474: (0.16), 1475: (0.15), 1476: (0.12), 1477: (0.12), 1478: (0.10), 1479: (0.10), 1480: (0.13), 1481: (0.13), 1482: (0.15), 1483: (0.13), 1484: (0.06), 1485: (0.05), 1486: (0.05), 1487: (0.05), 1488: (0.07), 1489: (0.06), 1490: (0.09), 1491: (0.11), 1492: (0.25), 1493: (0.18), 1494: (0.22), 1495: (0.19), 1496: (0.13), 1497: (0.10), 1498: (0.14), 1499: (0.14), 1500: (0.11), 1501: (0.14), 1502: (0.23), 1503: (0.25), 1504: (0.31), 1505: (0.29), 1506: (0.12), 1507: (0.10), 1508: (0.12), 1509: (0.14), 1510: (0.14), 1511: (0.14), 1512: (0.17), 1513: (0.17), 1514: (0.16), 1515: (0.13), 1516: (0.08), 1517: (0.09), 1518: (0.09), 1519: (0.11), 1520: (0.07), 1521: (0.08), 1522: (0.14), 1523: (0.17), 1524: (0.23), 1525: (0.22), 1526: (0.12), 1527: (0.08), 1528: (0.10), 1529: (0.11), 1530: (0.14), 1531: (0.12), 1532: (0.19), 1533: (0.23), 1534: (0.34), 1535: (0.33), 1536: (0.30), 1537: (0.36), 1538: (0.27), 1539: (0.29), 1540: (0.33), 1541: (0.30), 1542: (0.33), 1543: (0.55), 1544: (0.63), 1545: (0.66), 1546: (0.54), 1547: (0.59), 1548: (0.33), 1549: (0.35), 1550: (0.37), 1551: (0.63), 1552: (0.69), 1553: (0.60), 1554: (0.59), 1555: (0.81), 1556: (0.96), 1557: (1.00), 1558: (0.46), 1559: (0.25), 1560: (0.20), 1561: (0.12), 1562: (0.12), 1563: (0.10), 1564: (0.07), 1565: (0.09), 1566: (0.12), 1567: (0.13), 1568: (0.11), 1569: (0.09), 1570: (0.22), 1571: (0.36), 1572: (0.44), 1573: (0.29), 1574: (0.30), 1575: (0.31), 1576: (0.27), 1577: (0.37), 1578: (0.45), 1579: (0.47), 1580: (0.52), 1581: (0.47), 1582: (0.48), 1583: (0.42), 1584: (0.33), 1585: (0.40), 1586: (0.39), 1587: (0.33), 1588: (0.23), 1589: (0.16), 1590: (0.13), 1591: (0.12), 1592: (0.14), 1593: (0.15), 1594: (0.24), 1595: (0.20), 1596: (0.16), 1597: (0.16), 1598: (0.30), 1599: (0.46), 1600: (0.38), 1601: (0.43), 1602: (0.24), 1603: (0.17), 1604: (0.13), 1605: (0.21), 1606: (0.14), 1607: (0.19), 1608: (0.24), 1609: (0.17), 1610: (0.16), 1611: (0.14), 1612: (0.15), 1613: (0.17), 1614: (0.16), 1615: (0.19), 1616: (0.27), 1617: (0.26), 1618: (0.18), 1619: (0.23), 1620: (0.27), 1621: (0.19), 1622: (0.16), 1623: (0.19), 1624: (0.28), 1625: (0.23), 1626: (0.18), 1627: (0.23), 1628: (0.19), 1629: (0.31), 1630: (0.40), 1631: (0.37), 1632: (0.24), 1633: (0.14), 1634: (0.14), 1635: (0.16), 1636: (0.19), 1637: (0.25), 1638: (0.29), 1639: (0.40), 1640: (0.40), 1641: (0.46), 1642: (0.37), 1643: (0.24), 1644: (0.19), 1645: (0.24), 1646: (0.27), 1647: (0.32), 1648: (0.19), 1649: (0.25), 1650: (0.25), 1651: (0.25), 1652: (0.34), 1653: (0.21), 1654: (0.18), 1655: (0.27), 1656: (0.30), 1657: (0.28), 1658: (0.29), 1659: (0.32), 1660: (0.33), 1661: (0.30), 1662: (0.36), 1663: (0.28), 1664: (0.29), 1665: (0.30), 1666: (0.23), 1667: (0.22), 1668: (0.27), 1669: (0.30), 1670: (0.25), 1671: (0.20), 1672: (0.18), 1673: (0.23), 1674: (0.21), 1675: (0.13), 1676: (0.17), 1677: (0.13), 1678: (0.14), 1679: (0.14), 1680: (0.16), 1681: (0.16), 1682: (0.16), 1683: (0.17), 1684: (0.17), 1685: (0.18), 1686: (0.22), 1687: (0.18), 1688: (0.16), 1689: (0.09), 1690: (0.08), 1691: (0.06), 1692: (0.09), 1693: (0.17), 1694: (0.16), 1695: (0.17), 1696: (0.12), 1697: (0.25), 1698: (0.25), 1699: (0.29), 1700: (0.32), 1701: (0.32), 1702: (0.14), 1703: (0.12), 1704: (0.14), 1705: (0.13), 1706: (0.19), 1707: (0.20), 1708: (0.22), 1709: (0.23), 1710: (0.21), 1711: (0.18), 1712: (0.21), 1713: (0.24), 1714: (0.20), 1715: (0.18), 1716: (0.15), 1717: (0.13), 1718: (0.19), 1719: (0.12), 1720: (0.13), 1721: (0.09), 1722: (0.11), 1723: (0.16), 1724: (0.20), 1725: (0.29), 1726: (0.23), 1727: (0.12), 1728: (0.22), 1729: (0.25), 1730: (0.30), 1731: (0.41), 1732: (0.28), 1733: (0.23), 1734: (0.27), 1735: (0.31), 1736: (0.25), 1737: (0.25), 1738: (0.20), 1739: (0.31), 1740: (0.32), 1741: (0.38), 1742: (0.40), 1743: (0.33), 1744: (0.28), 1745: (0.34), 1746: (0.26), 1747: (0.22), 1748: (0.17), 1749: (0.14), 1750: (0.20), 1751: (0.29), 1752: (0.19), 1753: (0.18), 1754: (0.20), 1755: (0.24), 1756: (0.19), 1757: (0.21), 1758: (0.16), 1759: (0.12), 1760: (0.09), 1761: (0.13), 1762: (0.12), 1763: (0.11), 1764: (0.15), 1765: (0.18), 1766: (0.19), 1767: (0.17), 1768: (0.27), 1769: (0.17), 1770: (0.24), 1771: (0.13), 1772: (0.09), 1773: (0.11), 1774: (0.12), 1775: (0.15), 1776: (0.15), 1777: (0.18), 1778: (0.16), 1779: (0.11), 1780: (0.12), 1781: (0.11), 1782: (0.10), 1783: (0.12), 1784: (0.11), 1785: (0.14), 1786: (0.16), 1787: (0.16), 1788: (0.17), 1789: (0.21), 1790: (0.17), 1791: (0.12), 1792: (0.16), 1793: (0.18), 1794: (0.23), 1795: (0.21), 1796: (0.14), 1797: (0.19), 1798: (0.20), 1799: (0.24), 1800: (0.18), 1801: (0.13), 1802: (0.14), 1803: (0.16), 1804: (0.23), 1805: (0.24), 1806: (0.25), 1807: (0.57), 1808: (0.60), 1809: (0.67), 1810: (0.58), 1811: (0.40), 1812: (0.30), 1813: (0.23), 1814: (0.35), 1815: (0.21), 1816: (0.28), 1817: (0.27), 1818: (0.20), 1819: (0.17), 1820: (0.18), 1821: (0.14), 1822: (0.08), 1823: (0.12), 1824: (0.15), 1825: (0.21), 1826: (0.20), 1827: (0.23), 1828: (0.14), 1829: (0.19), 1830: (0.22), 1831: (0.13), 1832: (0.15), 1833: (0.17), 1834: (0.20), 1835: (0.17), 1836: (0.19), 1837: (0.18), 1838: (0.15), 1839: (0.15), 1840: (0.14), 1841: (0.13), 1842: (0.15), 1843: (0.11), 1844: (0.10), 1845: (0.08), 1846: (0.08), 1847: (0.06), 1848: (0.07), 1849: (0.15), 1850: (0.12), 1851: (0.14), 1852: (0.17), 1853: (0.12), 1854: (0.06), 1855: (0.10), 1856: (0.13), 1857: (0.18), 1858: (0.18), 1859: (0.18), 1860: (0.19), 1861: (0.21), 1862: (0.21), 1863: (0.15), 1864: (0.13), 1865: (0.15), 1866: (0.16), 1867: (0.15), 1868: (0.19), 1869: (0.15), 1870: (0.19), 1871: (0.13), 1872: (0.17), 1873: (0.13), 1874: (0.12), 1875: (0.13), 1876: (0.15), 1877: (0.30), 1878: (0.30), 1879: (0.27), 1880: (0.28), 1881: (0.18), 1882: (0.23), 1883: (0.27), 1884: (0.24), 1885: (0.13), 1886: (0.11), 1887: (0.13), 1888: (0.11), 1889: (0.09), 1890: (0.09), 1891: (0.10), 1892: (0.13), 1893: (0.15), 1894: (0.15), 1895: (0.11), 1896: (0.08), 1897: (0.20), 1898: (0.21), 1899: (0.23), 1900: (0.24), 1901: (0.17), 1902: (0.17), 1903: (0.20), 1904: (0.25), 1905: (0.24), 1906: (0.19), 1907: (0.17), 1908: (0.23), 1909: (0.24), 1910: (0.37), 1911: (0.24), 1912: (0.23), 1913: (0.26), 1914: (0.13), 1915: (0.19), 1916: (0.15), 1917: (0.14), 1918: (0.18), 1919: (0.24), 1920: (0.19), 1921: (0.17), 1922: (0.26), 1923: (0.15), 1924: (0.17), 1925: (0.16), 1926: (0.17), 1927: (0.16), 1928: (0.09), 1929: (0.16), 1930: (0.23), 1931: (0.25), 1932: (0.23), 1933: (0.33), 1934: (0.35), 1935: (0.27), 1936: (0.38), 1937: (0.39), 1938: (0.38), 1939: (0.27), 1940: (0.46), 1941: (0.29), 1942: (0.20), 1943: (0.19), 1944: (0.21), 1945: (0.18), 1946: (0.15), 1947: (0.14), 1948: (0.20), 1949: (0.18), 1950: (0.16), 1951: (0.18), 1952: (0.18), 1953: (0.20), 1954: (0.26), 1955: (0.22), 1956: (0.18), 1957: (0.29), 1958: (0.22), 1959: (0.28), 1960: (0.25), 1961: (0.23), 1962: (0.21), 1963: (0.21), 1964: (0.21), 1965: (0.22), 1966: (0.22), 1967: (0.21), 1968: (0.26), 1969: (0.22), 1970: (0.33), 1971: (0.32), 1972: (0.32), 1973: (0.31), 1974: (0.27), 1975: (0.23), 1976: (0.19), 1977: (0.17), 1978: (0.15), 1979: (0.15), 1980: (0.16), 1981: (0.18), 1982: (0.22), 1983: (0.22), 1984: (0.23), 1985: (0.21), 1986: (0.18), 1987: (0.21), 1988: (0.15), 1989: (0.17), 1990: (0.13), 1991: (0.14), 1992: (0.13), 1993: (0.12), 1994: (0.11), 1995: (0.09), 1996: (0.05), 1997: (0.00), 1998: (0.01), 1999: (0.02), 2000: (0.04), 2001: (0.06), 2002: (0.07), 2003: (0.06), 2004: (0.08), 2005: (0.10), 2006: (0.09), 2007: (0.08), 2008: (0.06), 2009: (0.10), 2010: (0.12), 2011: (0.11), 2012: (0.08), 2013: (0.07), 2014: (0.19), 2015: (0.14), 2016: (0.11), 2017: (0.11), 2018: (0.03), 2019: (0.01), 2020: (0.01), 2021: (0.00), 2022: (0.00), 2023: (0.01), 2024: (0.01), 2025: (0.03), 2026: (0.12), 2027: (0.19), 2028: (0.18), 2029: (0.13), 2030: (0.09), 2031: (0.10), 2032: (0.04), 2033: (0.01), 2034: (0.02), 2035: (0.04), 2036: (0.05), 2037: (0.06), 2038: (0.04), 2039: (0.07), 2040: (0.10), 2041: (0.12), 2042: (0.17), 2043: (0.16), 2044: (0.11), 2045: (0.11), 2046: (0.10), 2047: (0.09), 2048: (0.07), 2049: (0.06), 2050: (0.07), 2051: (0.11), 2052: (0.14), 2053: (0.09), 2054: (0.01), 2055: (0.02), 2056: (0.04), 2057: (0.06), 2058: (0.07), 2059: (0.06), 2060: (0.07), 2061: (0.11), 2062: (0.09), 2063: (0.05), 2064: (0.04), 2065: (0.01), 2066: (0.05), 2067: (0.04), 2068: (0.07), 2069: (0.08), 2070: (0.08), 2071: (0.08), 2072: (0.09), 2073: (0.10), 2074: (0.10), 2075: (0.04), 2076: (0.03), 2077: (0.04), 2078: (0.02), 2079: (0.03), 2080: (0.04), 2081: (0.06), 2082: (0.07), 2083: (0.08), 2084: (0.08), 2085: (0.08), 2086: (0.08), 2087: (0.10), 2088: (0.10), 2089: (0.08), 2090: (0.08), 2091: (0.11), 2092: (0.13), 2093: (0.11), 2094: (0.12), 2095: (0.10), 2096: (0.04), 2097: (0.01), 2098: (0.03), 2099: (0.03), 2100: (0.03), 2101: (0.03), 2102: (0.05), 2103: (0.06), 2104: (0.03), 2105: (0.03), 2106: (0.01), 2107: (0.01), 2108: (0.04), 2109: (0.04), 2110: (0.05), 2111: (0.06), 2112: (0.06), 2113: (0.09), 2114: (0.06), 2115: (0.06), 2116: (0.03), 2117: (0.02), 2118: (0.02), 2119: (0.03), 2120: (0.03), 2121: (0.04), 2122: (0.02), 2123: (0.03), 2124: (0.06), 2125: (0.05), 2126: (0.06), 2127: (0.05), 2128: (0.06), 2129: (0.09), 2130: (0.08), 2131: (0.05), 2132: (0.05), 2133: (0.05), 2134: (0.07), 2135: (0.08), 2136: (0.05), 2137: (0.07), 2138: (0.05), 2139: (0.03), 2140: (0.04), 2141: (0.02), 2142: (0.04), 2143: (0.07), 2144: (0.09), 2145: (0.09), 2146: (0.05), 2147: (0.09), 2148: (0.08), 2149: (0.07), 2150: (0.09), 2151: (0.06), 2152: (0.10), 2153: (0.08), 2154: (0.05), 2155: (0.04), 2156: (0.04), 2157: (0.05), 2158: (0.03), 2159: (0.01), 2160: (0.01), 2161: (0.03), 2162: (0.03), 2163: (0.06), 2164: (0.05), 2165: (0.05), 2166: (0.07), 2167: (0.08), 2168: (0.05), 2169: (0.05), 2170: (0.06), 2171: (0.05), 2172: (0.06), 2173: (0.09), 2174: (0.08), 2175: (0.10), 2176: (0.10), 2177: (0.11), 2178: (0.08), 2179: (0.09), 2180: (0.04), 2181: (0.02), 2182: (0.05), 2183: (0.08), 2184: (0.10), 2185: (0.11), 2186: (0.08), 2187: (0.10), 2188: (0.08), 2189: (0.08), 2190: (0.07), 2191: (0.01), 2192: (0.03), 2193: (0.03), 2194: (0.03), 2195: (0.03), 2196: (0.04), 2197: (0.07), 2198: (0.21), 2199: (0.40), 2200: (0.33), 2201: (0.36), 2202: (0.08), 2203: (0.10), 2204: (0.06), 2205: (0.04), 2206: (0.04), 2207: (0.04), 2208: (0.07), 2209: (0.09), 2210: (0.14), 2211: (0.15), 2212: (0.06), 2213: (0.11), 2214: (0.10), 2215: (0.14), 2216: (0.11), 2217: (0.15), 2218: (0.07), 2219: (0.18), 2220: (0.19), 2221: (0.13), 2222: (0.21), 2223: (0.08), 2224: (0.08), 2225: (0.05), 2226: (0.04), 2227: (0.05), 2228: (0.03), 2229: (0.03), 2230: (0.05), 2231: (0.05), 2232: (0.04), 2233: (0.02), 2234: (0.01), 2235: (0.06), 2236: (0.06), 2237: (0.07), 2238: (0.10), 2239: (0.13), 2240: (0.19), 2241: (0.16), 2242: (0.15), 2243: (0.10), 2244: (0.04), 2245: (0.05), 2246: (0.05), 2247: (0.03), 2248: (0.04), 2249: (0.07), 2250: (0.05), 2251: (0.07), 2252: (0.08), 2253: (0.11), 2254: (0.05), 2255: (0.08), 2256: (0.12), 2257: (0.11), 2258: (0.08), 2259: (0.10), 2260: (0.08), 2261: (0.15), 2262: (0.14), 2263: (0.10), 2264: (0.07), 2265: (0.06), 2266: (0.05), 2267: (0.06), 2268: (0.04), 2269: (0.03), 2270: (0.02), 2271: (0.06), 2272: (0.11), 2273: (0.04), 2274: (0.01), 2275: (0.01), 2276: (0.01), 2277: (0.04), 2278: (0.03), 2279: (0.04), 2280: (0.03), 2281: (0.04), 2282: (0.02), 2283: (0.01), 2284: (0.01), 2285: (0.01), 2286: (0.01), 2287: (0.03), 2288: (0.04), 2289: (0.02), 2290: (0.03), 2291: (0.04), 2292: (0.02), 2293: (0.02), 2294: (0.03), 2295: (0.03), 2296: (0.01), 2297: (0.04), 2298: (0.06), 2299: (0.04), 2300: (0.04), 2301: (0.05), 2302: (0.04), 2303: (0.05), 2304: (0.03), 2305: (0.03), 2306: (0.03), 2307: (0.01), 2308: (0.04), 2309: (0.07), 2310: (0.06), 2311: (0.07), 2312: (0.08), 2313: (0.08), 2314: (0.10), 2315: (0.06), 2316: (0.07), 2317: (0.02), 2318: (0.01), 2319: (0.04), 2320: (0.05), 2321: (0.06), 2322: (0.08), 2323: (0.06), 2324: (0.06), 2325: (0.04), 2326: (0.03), 2327: (0.02), 2328: (0.01), 2329: (0.02), 2330: (0.01), 2331: (0.02), 2332: (0.02), 2333: (0.02), 2334: (0.04), 2335: (0.03), 2336: (0.05), 2337: (0.07), 2338: (0.11), 2339: (0.09), 2340: (0.03), 2341: (0.04), 2342: (0.05), 2343: (0.06), 2344: (0.05), 2345: (0.05), 2346: (0.05), 2347: (0.05), 2348: (0.05), 2349: (0.02), 2350: (0.02), 2351: (0.06), 2352: (0.06), 2353: (0.06), 2354: (0.06), 2355: (0.06), 2356: (0.06), 2357: (0.06), 2358: (0.05), 2359: (0.02), 2360: (0.03), 2361: (0.05), 2362: (0.06), 2363: (0.05), 2364: (0.08), 2365: (0.15), 2366: (0.09), 2367: (0.08), 2368: (0.08), 2369: (0.05), 2370: (0.06), 2371: (0.08), 2372: (0.13), 2373: (0.09), 2374: (0.10), 2375: (0.11), 2376: (0.12), 2377: (0.15), 2378: (0.17), 2379: (0.16), 2380: (0.22), 2381: (0.17), 2382: (0.13), 2383: (0.16), 2384: (0.15), 2385: (0.16), 2386: (0.12), 2387: (0.18), 2388: (0.23), 2389: (0.24), 2390: (0.21), 2391: (0.11), 2392: (0.05), 2393: (0.04), 2394: (0.04), 2395: (0.05), 2396: (0.05), 2397: (0.04), 2398: (0.11), 2399: (0.14), 2400: (0.09), 2401: (0.14), 2402: (0.07), 2403: (0.04), 2404: (0.07), 2405: (0.07), 2406: (0.09), 2407: (0.11), 2408: (0.15), 2409: (0.22), 2410: (0.15), 2411: (0.13), 2412: (0.18), 2413: (0.08), 2414: (0.08), 2415: (0.06), 2416: (0.08), 2417: (0.10), 2418: (0.11), 2419: (0.13), 2420: (0.18), 2421: (0.17), 2422: (0.12), 2423: (0.09), 2424: (0.18), 2425: (0.25), 2426: (0.24), 2427: (0.29), 2428: (0.28), 2429: (0.24), 2430: (0.16), 2431: (0.21), 2432: (0.21), 2433: (0.16), 2434: (0.08), 2435: (0.06), 2436: (0.12), 2437: (0.09), 2438: (0.06), 2439: (0.07), 2440: (0.08), 2441: (0.08), 2442: (0.13), 2443: (0.11), 2444: (0.08), 2445: (0.03), 2446: (0.07), 2447: (0.12), 2448: (0.15), 2449: (0.11), 2450: (0.07), 2451: (0.06), 2452: (0.07), 2453: (0.10), 2454: (0.05), 2455: (0.04), 2456: (0.05), 2457: (0.03), 2458: (0.05), 2459: (0.06), 2460: (0.06), 2461: (0.11), 2462: (0.10), 2463: (0.13), 2464: (0.13), 2465: (0.20), 2466: (0.12), 2467: (0.13), 2468: (0.14), 2469: (0.13), 2470: (0.12), 2471: (0.16), 2472: (0.18), 2473: (0.21), 2474: (0.13), 2475: (0.09), 2476: (0.04), 2477: (0.07), 2478: (0.06), 2479: (0.07), 2480: (0.14), 2481: (0.08), 2482: (0.15), 2483: (0.11), 2484: (0.08), 2485: (0.09), 2486: (0.19), 2487: (0.09), 2488: (0.15), 2489: (0.15), 2490: (0.12), 2491: (0.12), 2492: (0.21), 2493: (0.27), 2494: (0.13), 2495: (0.11), 2496: (0.04), 2497: (0.03), 2498: (0.07), 2499: (0.05), 2500: (0.05), 2501: (0.08), 2502: (0.06), 2503: (0.09), 2504: (0.09), 2505: (0.12), 2506: (0.10), 2507: (0.08), 2508: (0.08), 2509: (0.10), 2510: (0.11), 2511: (0.14), 2512: (0.16), 2513: (0.15), 2514: (0.16), 2515: (0.12), 2516: (0.12), 2517: (0.11), 2518: (0.08), 2519: (0.05), 2520: (0.13), 2521: (0.15), 2522: (0.12), 2523: (0.24), 2524: (0.27), 2525: (0.17), 2526: (0.12), 2527: (0.12), 2528: (0.12), 2529: (0.11), 2530: (0.06), 2531: (0.06), 2532: (0.08), 2533: (0.06), 2534: (0.08), 2535: (0.06), 2536: (0.07), 2537: (0.05), 2538: (0.06), 2539: (0.06), 2540: (0.11), 2541: (0.13), 2542: (0.12), 2543: (0.16), 2544: (0.11), 2545: (0.14), 2546: (0.14), 2547: (0.19), 2548: (0.15), 2549: (0.15), 2550: (0.14), 2551: (0.23), 2552: (0.23), 2553: (0.19), 2554: (0.17), 2555: (0.17), 2556: (0.17), 2557: (0.27), 2558: (0.24), 2559: (0.37), 2560: (0.20), 2561: (0.14), 2562: (0.12), 2563: (0.14), 2564: (0.20), 2565: (0.26), 2566: (0.26), 2567: (0.15), 2568: (0.12), 2569: (0.13), 2570: (0.15), 2571: (0.11), 2572: (0.09), 2573: (0.09), 2574: (0.11), 2575: (0.14), 2576: (0.14), 2577: (0.15), 2578: (0.22), 2579: (0.26), 2580: (0.23), 2581: (0.08), 2582: (0.07), 2583: (0.07), 2584: (0.09), 2585: (0.09), 2586: (0.05), 2587: (0.10), 2588: (0.15), 2589: (0.29), 2590: (0.22), 2591: (0.23), 2592: (0.11), 2593: (0.13), 2594: (0.14), 2595: (0.12), 2596: (0.10), 2597: (0.08), 2598: (0.13), 2599: (0.19), 2600: (0.19), 2601: (0.13), 2602: (0.07), 2603: (0.09), 2604: (0.17), 2605: (0.09), 2606: (0.08), 2607: (0.10), 2608: (0.07), 2609: (0.12), 2610: (0.12), 2611: (0.11), 2612: (0.10), 2613: (0.05), 2614: (0.06), 2615: (0.06), 2616: (0.05), 2617: (0.06), 2618: (0.08), 2619: (0.11), 2620: (0.06), 2621: (0.06), 2622: (0.06), 2623: (0.04), 2624: (0.02), 2625: (0.04), 2626: (0.04), 2627: (0.06), 2628: (0.04), 2629: (0.05), 2630: (0.05), 2631: (0.08), 2632: (0.08), 2633: (0.09), 2634: (0.08), 2635: (0.14), 2636: (0.12), 2637: (0.18), 2638: (0.22), 2639: (0.15), 2640: (0.14), 2641: (0.15), 2642: (0.10), 2643: (0.13), 2644: (0.08), 2645: (0.05), 2646: (0.12), 2647: (0.10), 2648: (0.11), 2649: (0.11), 2650: (0.13), 2651: (0.13), 2652: (0.14), 2653: (0.12), 2654: (0.07), 2655: (0.06), 2656: (0.12), 2657: (0.09), 2658: (0.13), 2659: (0.11), 2660: (0.15), 2661: (0.13), 2662: (0.14), 2663: (0.18), 2664: (0.21), 2665: (0.18), 2666: (0.14), 2667: (0.08), 2668: (0.06), 2669: (0.07), 2670: (0.15), 2671: (0.18), 2672: (0.20), 2673: (0.17), 2674: (0.15), 2675: (0.13), 2676: (0.12), 2677: (0.08), 2678: (0.05), 2679: (0.06), 2680: (0.06), 2681: (0.05), 2682: (0.06), 2683: (0.07), 2684: (0.13), 2685: (0.12), 2686: (0.08), 2687: (0.03), 2688: (0.02), 2689: (0.05), 2690: (0.09), 2691: (0.05), 2692: (0.04), 2693: (0.07), 2694: (0.07), 2695: (0.07), 2696: (0.12), 2697: (0.11), 2698: (0.06), 2699: (0.07), 2700: (0.05), 2701: (0.06), 2702: (0.07), 2703: (0.10), 2704: (0.09), 2705: (0.08), 2706: (0.08), 2707: (0.10), 2708: (0.08), 2709: (0.11), 2710: (0.23), 2711: (0.19), 2712: (0.29), 2713: (0.36), 2714: (0.38), 2715: (0.20), 2716: (0.18), 2717: (0.34), 2718: (0.45), 2719: (0.38), 2720: (0.40), 2721: (0.49), 2722: (0.47), 2723: (0.40), 2724: (0.59), 2725: (0.62), 2726: (0.45), 2727: (0.48), 2728: (0.53), 2729: (0.57), 2730: (0.52), 2731: (0.51), 2732: (0.82), 2733: (0.75), 2734: (0.40), 2735: (0.54), 2736: (0.75), 2737: (0.69), 2738: (0.89), 2739: (0.51), 2740: (0.28), 2741: (0.48), 2742: (0.32), 2743: (0.18), 2744: (0.19), 2745: (0.27), 2746: (0.28), 2747: (0.30), 2748: (0.24), 2749: (0.21), 2750: (0.17), 2751: (0.23), 2752: (0.30), 2753: (0.36), 2754: (0.46), 2755: (0.33), 2756: (0.48), 2757: (0.56), 2758: (0.68), 2759: (0.43), 2760: (0.30), 2761: (0.24), 2762: (0.31), 2763: (0.28), 2764: (0.25), 2765: (0.36), 2766: (0.43), 2767: (0.43), 2768: (0.39), 2769: (0.46), 2770: (0.52), 2771: (0.36), 2772: (0.27), 2773: (0.35), 2774: (0.37), 2775: (0.40), 2776: (0.32), 2777: (0.38), 2778: (0.32), 2779: (0.41), 2780: (0.49), 2781: (0.50), 2782: (0.20), 2783: (0.24), 2784: (0.24), 2785: (0.34), 2786: (0.26), 2787: (0.31), 2788: (0.27), 2789: (0.40), 2790: (0.50), 2791: (0.27), 2792: (0.29), 2793: (0.14), 2794: (0.17), 2795: (0.15), 2796: (0.18), 2797: (0.15), 2798: (0.22), 2799: (0.26), 2800: (0.33), 2801: (0.37), 2802: (0.32), 2803: (0.26), 2804: (0.18), 2805: (0.17), 2806: (0.23), 2807: (0.19), 2808: (0.25), 2809: (0.14), 2810: (0.18), 2811: (0.24), 2812: (0.30), 2813: (0.24), 2814: (0.18), 2815: (0.17), 2816: (0.17), 2817: (0.19), 2818: (0.21), 2819: (0.17), 2820: (0.17), 2821: (0.26), 2822: (0.20), 2823: (0.23), 2824: (0.22), 2825: (0.19), 2826: (0.14), 2827: (0.19), 2828: (0.17), 2829: (0.15), 2830: (0.21), 2831: (0.18), 2832: (0.14), 2833: (0.14), 2834: (0.12), 2835: (0.06), 2836: (0.08), 2837: (0.08), 2838: (0.12), 2839: (0.10), 2840: (0.10), 2841: (0.12), 2842: (0.23), 2843: (0.18), 2844: (0.21), 2845: (0.20), 2846: (0.11), 2847: (0.08), 2848: (0.12), 2849: (0.17), 2850: (0.11), 2851: (0.16), 2852: (0.32), 2853: (0.24), 2854: (0.29), 2855: (0.32), 2856: (0.28), 2857: (0.21), 2858: (0.18), 2859: (0.18), 2860: (0.15), 2861: (0.16), 2862: (0.26), 2863: (0.25), 2864: (0.26), 2865: (0.21), 2866: (0.15), 2867: (0.18), 2868: (0.13), 2869: (0.16), 2870: (0.10), 2871: (0.13), 2872: (0.14), 2873: (0.20), 2874: (0.31), 2875: (0.32), 2876: (0.18), 2877: (0.19), 2878: (0.11), 2879: (0.10), 2880: (0.18), 2881: (0.20), 2882: (0.24), 2883: (0.28), 2884: (0.30), 2885: (0.37), 2886: (0.38), 2887: (0.44), 2888: (0.42), 2889: (0.57), 2890: (0.50), 2891: (0.51), 2892: (0.42), 2893: (0.37), 2894: (0.39), 2895: (0.47), 2896: (0.47), 2897: (0.31), 2898: (0.15), 2899: (0.17), 2900: (0.26), 2901: (0.32), 2902: (0.21), 2903: (0.22), 2904: (0.26), 2905: (0.18), 2906: (0.23), 2907: (0.63), 2908: (0.42), 2909: (0.13), 2910: (0.26), 2911: (0.37), 2912: (0.36), 2913: (0.17), 2914: (0.15), 2915: (0.15), 2916: (0.19), 2917: (0.22), 2918: (0.20), 2919: (0.12), 2920: (0.22), 2921: (0.30), 2922: (0.53), 2923: (0.47), 2924: (0.50), 2925: (0.57), 2926: (0.56), 2927: (0.48), 2928: (0.54), 2929: (0.76), 2930: (0.60), 2931: (0.34), 2932: (0.37), 2933: (0.46), 2934: (0.55), 2935: (0.44), 2936: (0.42), 2937: (0.55), 2938: (0.49), 2939: (0.47), 2940: (0.45), 2941: (0.38), 2942: (0.21), 2943: (0.20), 2944: (0.26), 2945: (0.42), 2946: (0.33), 2947: (0.29), 2948: (0.52), 2949: (0.78), 2950: (0.71), 2951: (0.76), 2952: (0.43), 2953: (0.56), 2954: (0.48), 2955: (0.47), 2956: (0.29), 2957: (0.28), 2958: (0.33), 2959: (0.28), 2960: (0.37), 2961: (0.41), 2962: (0.38), 2963: (0.18), 2964: (0.24), 2965: (0.23), 2966: (0.25), 2967: (0.28), 2968: (0.33), 2969: (0.72), 2970: (0.66), 2971: (0.37), 2972: (0.60), 2973: (0.58), 2974: (0.39), 2975: (0.31), 2976: (0.25), 2977: (0.30), 2978: (0.24), 2979: (0.20), 2980: (0.34), 2981: (0.47), 2982: (0.35), 2983: (0.23), 2984: (0.19), 2985: (0.18), 2986: (0.20), 2987: (0.20), 2988: (0.20), 2989: (0.21), 2990: (0.22), 2991: (0.26), 2992: (0.25), 2993: (0.23), 2994: (0.21), 2995: (0.23), 2996: (0.23), 2997: (0.30), 2998: (0.17), 2999: (0.26), 3000: (0.28), 3001: (0.28), 3002: (0.29), 3003: (0.21), 3004: (0.15), 3005: (0.22), 3006: (0.27), 3007: (0.29), 3008: (0.31), 3009: (0.34), 3010: (0.36), 3011: (0.34), 3012: (0.42), 3013: (0.37), 3014: (0.37), 3015: (0.33), 3016: (0.37), 3017: (0.27), 3018: (0.32), 3019: (0.36), 3020: (0.27), 3021: (0.29), 3022: (0.29), 3023: (0.34), 3024: (0.21), 3025: (0.09), 3026: (0.16), 3027: (0.09), 3028: (0.08), 3029: (0.12), 3030: (0.13), 3031: (0.12), 3032: (0.14), 3033: (0.15), 3034: (0.13), 3035: (0.12), 3036: (0.17), 3037: (0.17), 3038: (0.13), 3039: (0.07), 3040: (0.08), 3041: (0.10), 3042: (0.12), 3043: (0.14), 3044: (0.13), 3045: (0.14), 3046: (0.09), 3047: (0.18), 3048: (0.20), 3049: (0.27), 3050: (0.33), 3051: (0.25), 3052: (0.15), 3053: (0.14), 3054: (0.16), 3055: (0.15), 3056: (0.18), 3057: (0.21), 3058: (0.31), 3059: (0.28), 3060: (0.27), 3061: (0.38), 3062: (0.29), 3063: (0.25), 3064: (0.25), 3065: (0.23), 3066: (0.12), 3067: (0.12), 3068: (0.15), 3069: (0.10), 3070: (0.14), 3071: (0.12), 3072: (0.14), 3073: (0.15), 3074: (0.18), 3075: (0.24), 3076: (0.24), 3077: (0.09), 3078: (0.13), 3079: (0.20), 3080: (0.23), 3081: (0.23), 3082: (0.22), 3083: (0.22), 3084: (0.22), 3085: (0.30), 3086: (0.27), 3087: (0.24), 3088: (0.17), 3089: (0.29), 3090: (0.31), 3091: (0.37), 3092: (0.39), 3093: (0.26), 3094: (0.24), 3095: (0.31), 3096: (0.27), 3097: (0.28), 3098: (0.23), 3099: (0.17), 3100: (0.22), 3101: (0.32), 3102: (0.26), 3103: (0.25), 3104: (0.30), 3105: (0.30), 3106: (0.25), 3107: (0.29), 3108: (0.22), 3109: (0.17), 3110: (0.14), 3111: (0.19), 3112: (0.24), 3113: (0.26), 3114: (0.27), 3115: (0.29), 3116: (0.33), 3117: (0.49), 3118: (0.93), 3119: (0.32), 3120: (0.40), 3121: (0.22), 3122: (0.14), 3123: (0.19), 3124: (0.22), 3125: (0.23), 3126: (0.28), 3127: (0.34), 3128: (0.39), 3129: (0.22), 3130: (0.28), 3131: (0.23), 3132: (0.14), 3133: (0.17), 3134: (0.16), 3135: (0.17), 3136: (0.22), 3137: (0.29), 3138: (0.23), 3139: (0.15), 3140: (0.27), 3141: (0.30), 3142: (0.36), 3143: (0.35), 3144: (0.35), 3145: (0.31), 3146: (0.26), 3147: (0.20), 3148: (0.19), 3149: (0.29), 3150: (0.26), 3151: (0.18), 3152: (0.21), 3153: (0.21), 3154: (0.38), 3155: (0.39), 3156: (0.34), 3157: (0.44), 3158: (0.66), 3159: (0.95), 3160: (0.77), 3161: (0.61), 3162: (0.44), 3163: (0.40), 3164: (0.49), 3165: (0.29), 3166: (0.32), 3167: (0.38), 3168: (0.33), 3169: (0.27), 3170: (0.32), 3171: (0.21), 3172: (0.12), 3173: (0.15), 3174: (0.16), 3175: (0.28), 3176: (0.21), 3177: (0.39), 3178: (0.23), 3179: (0.21), 3180: (0.25), 3181: (0.16), 3182: (0.23), 3183: (0.23), 3184: (0.26), 3185: (0.29), 3186: (0.38), 3187: (0.27), 3188: (0.24), 3189: (0.21), 3190: (0.22), 3191: (0.21), 3192: (0.19), 3193: (0.16), 3194: (0.17), 3195: (0.15), 3196: (0.11), 3197: (0.14), 3198: (0.15), 3199: (0.27), 3200: (0.27), 3201: (0.26), 3202: (0.41), 3203: (0.24), 3204: (0.08), 3205: (0.14), 3206: (0.17), 3207: (0.16), 3208: (0.15), 3209: (0.15), 3210: (0.16), 3211: (0.22), 3212: (0.31), 3213: (0.23), 3214: (0.17), 3215: (0.18), 3216: (0.19), 3217: (0.17), 3218: (0.26), 3219: (0.23), 3220: (0.30), 3221: (0.19), 3222: (0.24), 3223: (0.21), 3224: (0.16), 3225: (0.20), 3226: (0.21), 3227: (0.39), 3228: (0.36), 3229: (0.32), 3230: (0.27), 3231: (0.20), 3232: (0.23), 3233: (0.20), 3234: (0.23), 3235: (0.18), 3236: (0.13), 3237: (0.15), 3238: (0.17), 3239: (0.17), 3240: (0.16), 3241: (0.16), 3242: (0.19), 3243: (0.18), 3244: (0.20), 3245: (0.15), 3246: (0.12), 3247: (0.26), 3248: (0.27), 3249: (0.30), 3250: (0.33), 3251: (0.25), 3252: (0.27), 3253: (0.30), 3254: (0.35), 3255: (0.32), 3256: (0.24), 3257: (0.19), 3258: (0.25), 3259: (0.23), 3260: (0.39), 3261: (0.29), 3262: (0.23), 3263: (0.26), 3264: (0.17), 3265: (0.27), 3266: (0.24), 3267: (0.21), 3268: (0.27), 3269: (0.29), 3270: (0.22), 3271: (0.24), 3272: (0.35), 3273: (0.25), 3274: (0.22), 3275: (0.20), 3276: (0.25), 3277: (0.18), 3278: (0.13), 3279: (0.18), 3280: (0.29), 3281: (0.27), 3282: (0.24), 3283: (0.29), 3284: (0.33), 3285: (0.24), 3286: (0.37), 3287: (0.34), 3288: (0.57), 3289: (0.44), 3290: (0.61), 3291: (0.40), 3292: (0.26), 3293: (0.31), 3294: (0.38), 3295: (0.30), 3296: (0.24), 3297: (0.20), 3298: (0.23), 3299: (0.26), 3300: (0.22), 3301: (0.25), 3302: (0.21), 3303: (0.22), 3304: (0.27), 3305: (0.32), 3306: (0.26), 3307: (0.33), 3308: (0.25), 3309: (0.23), 3310: (0.27), 3311: (0.23), 3312: (0.19), 3313: (0.17), 3314: (0.24), 3315: (0.29), 3316: (0.27), 3317: (0.26), 3318: (0.33), 3319: (0.25), 3320: (0.39), 3321: (0.34), 3322: (0.35), 3323: (0.28), 3324: (0.32), 3325: (0.25), 3326: (0.20), 3327: (0.19), 3328: (0.19), 3329: (0.19), 3330: (0.17), 3331: (0.19), 3332: (0.16), 3333: (0.17), 3334: (0.25), 3335: (0.20), 3336: (0.21), 3337: (0.20), 3338: (0.20), 3339: (0.19), 3340: (0.18), 3341: (0.20), 3342: (0.16), 3343: (0.14), 3344: (0.14), 3345: (0.12), 3346: (0.09), 3347: (0.06), 3348: (0.06), 3349: (0.06), 3350: (0.05), 3351: (0.08), 3352: (0.13), 3353: (0.13), 3354: (0.10), 3355: (0.13), 3356: (0.13), 3357: (0.12), 3358: (0.18), 3359: (0.15), 3360: (0.19), 3361: (0.18), 3362: (0.13), 3363: (0.11), 3364: (0.17), 3365: (0.21), 3366: (0.17), 3367: (0.16), 3368: (0.18), 3369: (0.11), 3370: (0.09), 3371: (0.09), 3372: (0.10), 3373: (0.07), 3374: (0.09), 3375: (0.51), 3376: (0.46), 3377: (0.38), 3378: (0.27), 3379: (0.29), 3380: (0.15), 3381: (0.16), 3382: (0.10), 3383: (0.13), 3384: (0.08), 3385: (0.05), 3386: (0.06), 3387: (0.06), 3388: (0.04), 3389: (0.02), 3390: (0.01), 3391: (0.01), 3392: (0.01), 3393: (0.00), 3394: (0.01), 3395: (0.01), 3396: (0.02), 3397: (0.03), 3398: (0.02), 3399: (0.02), 3400: (0.01), 3401: (0.01), 3402: (0.03), 3403: (0.02), 3404: (0.03), 3405: (0.03), 3406: (0.05), 3407: (0.05), 3408: (0.02), 3409: (0.01), 3410: (0.03), 3411: (0.06), 3412: (0.03), 3413: (0.02), 3414: (0.03), 3415: (0.02), 3416: (0.03), 3417: (0.05), 3418: (0.05), 3419: (0.04), 3420: (0.03), 3421: (0.06), 3422: (0.04), 3423: (0.02), 3424: (0.01), 3425: (0.02), 3426: (0.01), 3427: (0.01), 3428: (0.01), 3429: (0.01), 3430: (0.01), 3431: (0.01), 3432: (0.01), 3433: (0.01), 3434: (0.01), 3435: (0.01), 3436: (0.01), 3437: (0.01), 3438: (0.02), 3439: (0.02), 3440: (0.02), 3441: (0.02), 3442: (0.02), 3443: (0.01), 3444: (0.01), 3445: (0.01), 3446: (0.01), 3447: (0.01), 3448: (0.01), 3449: (0.01), 3450: (0.01), 3451: (0.01), 3452: (0.01), 3453: (0.02), 3454: (0.02), 3455: (0.02), 3456: (0.02), 3457: (0.02), 3458: (0.01), 3459: (0.01), 3460: (0.01), 3461: (0.01), 3462: (0.01), 3463: (0.01), 3464: (0.01), 3465: (0.01), 3466: (0.01), 3467: (0.01), 3468: (0.01), 3469: (0.01), 3470: (0.01), 3471: (0.01), 3472: (0.01), 3473: (0.01), 3474: (0.01), 3475: (0.01), 3476: (0.01), 3477: (0.01), 3478: (0.01), 3479: (0.01), 3480: (0.01), 3481: (0.01), 3482: (0.01), 3483: (0.01), 3484: (0.02), 3485: (0.02), 3486: (0.02), 3487: (0.01), 3488: (0.01), 3489: (0.01), 3490: (0.01), 3491: (0.01), 3492: (0.02), 3493: (0.01), 3494: (0.01), 3495: (0.01), 3496: (0.01), 3497: (0.01), 3498: (0.04), 3499: (0.03), 3500: (0.01), 3501: (0.01), 3502: (0.01), 3503: (0.01), 3504: (0.02), 3505: (0.04), 3506: (0.03), 3507: (0.01), 3508: (0.01), 3509: (0.01), 3510: (0.02), 3511: (0.01), 3512: (0.01), 3513: (0.01), 3514: (0.01), 3515: (0.01), 3516: (0.02), 3517: (0.01), 3518: (0.01), 3519: (0.01), 3520: (0.02), 3521: (0.01), 3522: (0.02), 3523: (0.02), 3524: (0.02), 3525: (0.02), 3526: (0.02), 3527: (0.01), 3528: (0.01), 3529: (0.01), 3530: (0.01), 3531: (0.01), 3532: (0.01), 3533: (0.01), 3534: (0.01), 3535: (0.01), 3536: (0.02), 3537: (0.02), 3538: (0.02), 3539: (0.02), 3540: (0.02), 3541: (0.01), 3542: (0.01), 3543: (0.02), 3544: (0.01), 3545: (0.01), 3546: (0.01), 3547: (0.01), 3548: (0.01), 3549: (0.01), 3550: (0.01), 3551: (0.02), 3552: (0.01), 3553: (0.01), 3554: (0.01), 3555: (0.01), 3556: (0.02), 3557: (0.02), 3558: (0.02), 3559: (0.02), 3560: (0.02), 3561: (0.02), 3562: (0.02), 3563: (0.03), 3564: (0.04), 3565: (0.04), 3566: (0.04), 3567: (0.04), 3568: (0.03), 3569: (0.04), 3570: (0.03), 3571: (0.04), 3572: (0.04), 3573: (0.04), 3574: (0.05), 3575: (0.05), 3576: (0.05), 3577: (0.06), 3578: (0.06), 3579: (0.04), 3580: (0.02), 3581: (0.03), 3582: (0.03), 3583: (0.09), 3584: (0.05), 3585: (0.02), 3586: (0.03), 3587: (0.05), 3588: (0.07), 3589: (0.04), 3590: (0.04), 3591: (0.04), 3592: (0.07), 3593: (0.04), 3594: (0.04), 3595: (0.05), 3596: (0.05), 3597: (0.06), 3598: (0.06), 3599: (0.05), 3600: (0.05), 3601: (0.07), 3602: (0.06), 3603: (0.04), 3604: (0.05), 3605: (0.03), 3606: (0.03), 3607: (0.03), 3608: (0.02), 3609: (0.02), 3610: (0.01), 3611: (0.02), 3612: (0.02), 3613: (0.02), 3614: (0.01), 3615: (0.01), 3616: (0.02), 3617: (0.01), 3618: (0.01), 3619: (0.01), 3620: (0.01), 3621: (0.02), 3622: (0.02), 3623: (0.01), 3624: (0.02), 3625: (0.02), 3626: (0.02), 3627: (0.02), 3628: (0.02), 3629: (0.01), 3630: (0.02), 3631: (0.01), 3632: (0.01), 3633: (0.01), 3634: (0.01), 3635: (0.02), 3636: (0.02), 3637: (0.03), 3638: (0.03), 3639: (0.03), 3640: (0.02), 3641: (0.02), 3642: (0.02), 3643: (0.02), 3644: (0.02), 3645: (0.02), 3646: (0.03), 3647: (0.04), 3648: (0.03), 3649: (0.06), 3650: (0.08), 3651: (0.09), 3652: (0.05), 3653: (0.06), 3654: (0.04), 3655: (0.03), 3656: (0.04), 3657: (0.06), 3658: (0.07), 3659: (0.09), 3660: (0.06), 3661: (0.09), 3662: (0.09), 3663: (0.10), 3664: (0.07), 3665: (0.07), 3666: (0.07), 3667: (0.05), 3668: (0.05), 3669: (0.08), 3670: (0.06), 3671: (0.06), 3672: (0.09), 3673: (0.08), 3674: (0.09), 3675: (0.09), 3676: (0.11), 3677: (0.08), 3678: (0.06), 3679: (0.03), 3680: (0.03), 3681: (0.03), 3682: (0.05), 3683: (0.06), 3684: (0.05), 3685: (0.05), 3686: (0.03), 3687: (0.03), 3688: (0.03), 3689: (0.02), 3690: (0.01), 3691: (0.01), 3692: (0.01), 3693: (0.01), 3694: (0.01), 3695: (0.01), 3696: (0.02), 3697: (0.01), 3698: (0.02), 3699: (0.05), 3700: (0.05), 3701: (0.02), 3702: (0.01), 3703: (0.01), 3704: (0.02), 3705: (0.02), 3706: (0.02), 3707: (0.01), 3708: (0.01), 3709: (0.02), 3710: (0.13), 3711: (0.18), 3712: (0.14), 3713: (0.10), 3714: (0.10), 3715: (0.11), 3716: (0.17), 3717: (0.16), 3718: (0.07), 3719: (0.09), 3720: (0.08), 3721: (0.11), 3722: (0.18), 3723: (0.21), 3724: (0.23), 3725: (0.37), 3726: (0.50), 3727: (0.47), 3728: (0.36), 3729: (0.28), 3730: (0.40), 3731: (0.33), 3732: (0.22), 3733: (0.29), 3734: (0.36), 3735: (0.28), 3736: (0.35), 3737: (0.64), 3738: (0.70), 3739: (0.49), 3740: (0.60), 3741: (0.43), 3742: (0.30), 3743: (0.38), 3744: (0.30), 3745: (0.35), 3746: (0.42), 3747: (0.45), 3748: (0.45), 3749: (0.36), 3750: (0.42), 3751: (0.35), 3752: (0.12), 3753: (0.11), 3754: (0.12), 3755: (0.11), 3756: (0.21), 3757: (0.20), 3758: (0.27), 3759: (0.24), 3760: (0.31), 3761: (0.25), 3762: (0.23), 3763: (0.18), 3764: (0.27), 3765: (0.28), 3766: (0.51), 3767: (0.50), 3768: (0.28), 3769: (0.25), 3770: (0.44), 3771: (0.37), 3772: (0.28), 3773: (0.27), 3774: (0.26), 3775: (0.25), 3776: (0.28), 3777: (0.23), 3778: (0.25), 3779: (0.31), 3780: (0.34), 3781: (0.31), 3782: (0.30), 3783: (0.23), 3784: (0.14), 3785: (0.12), 3786: (0.19), 3787: (0.20), 3788: (0.17), 3789: (0.15), 3790: (0.16), 3791: (0.20), 3792: (0.25), 3793: (0.35), 3794: (0.17), 3795: (0.17), 3796: (0.35), 3797: (0.32), 3798: (0.38), 3799: (0.33), 3800: (0.33), 3801: (0.32), 3802: (0.40), 3803: (0.35), 3804: (0.22), 3805: (0.25), 3806: (0.19), 3807: (0.15), 3808: (0.18), 3809: (0.21), 3810: (0.24), 3811: (0.27), 3812: (0.25), 3813: (0.31), 3814: (0.30), 3815: (0.24), 3816: (0.21), 3817: (0.16), 3818: (0.25), 3819: (0.18), 3820: (0.19), 3821: (0.28), 3822: (0.19), 3823: (0.19), 3824: (0.25), 3825: (0.25), 3826: (0.18), 3827: (0.22), 3828: (0.16), 3829: (0.21), 3830: (0.21), 3831: (0.16), 3832: (0.15), 3833: (0.21), 3834: (0.23), 3835: (0.25), 3836: (0.26), 3837: (0.22), 3838: (0.21), 3839: (0.24), 3840: (0.18), 3841: (0.15), 3842: (0.17), 3843: (0.21), 3844: (0.26), 3845: (0.23), 3846: (0.18), 3847: (0.08), 3848: (0.11), 3849: (0.13), 3850: (0.13), 3851: (0.14), 3852: (0.19), 3853: (0.17), 3854: (0.27), 3855: (0.29), 3856: (0.19), 3857: (0.24), 3858: (0.14), 3859: (0.11), 3860: (0.14), 3861: (0.14), 3862: (0.12), 3863: (0.11), 3864: (0.25), 3865: (0.36), 3866: (0.30), 3867: (0.29), 3868: (0.29), 3869: (0.10), 3870: (0.13), 3871: (0.17), 3872: (0.16), 3873: (0.16), 3874: (0.21), 3875: (0.25), 3876: (0.23), 3877: (0.21), 3878: (0.14), 3879: (0.09), 3880: (0.12), 3881: (0.11), 3882: (0.12), 3883: (0.13), 3884: (0.18), 3885: (0.18), 3886: (0.24), 3887: (0.33), 3888: (0.24), 3889: (0.17), 3890: (0.11), 3891: (0.13), 3892: (0.17), 3893: (0.22), 3894: (0.20), 3895: (0.29), 3896: (0.22), 3897: (0.26), 3898: (0.26), 3899: (0.29), 3900: (0.33), 3901: (0.43), 3902: (0.62), 3903: (0.52), 3904: (0.44), 3905: (0.43), 3906: (0.41), 3907: (0.39), 3908: (0.46), 3909: (0.37), 3910: (0.36), 3911: (0.30), 3912: (0.30), 3913: (0.47), 3914: (0.44), 3915: (0.37), 3916: (0.44), 3917: (0.52), 3918: (0.44), 3919: (0.35), 3920: (0.27), 3921: (0.13), 3922: (0.16), 3923: (0.29), 3924: (0.42), 3925: (0.37), 3926: (0.21), 3927: (0.21), 3928: (0.17), 3929: (0.26), 3930: (0.25), 3931: (0.18), 3932: (0.18), 3933: (0.27), 3934: (0.23), 3935: (0.24), 3936: (0.31), 3937: (0.25), 3938: (0.27), 3939: (0.34), 3940: (0.31), 3941: (0.29), 3942: (0.35), 3943: (0.30), 3944: (0.32), 3945: (0.35), 3946: (0.43), 3947: (0.29), 3948: (0.27), 3949: (0.27), 3950: (0.29), 3951: (0.29), 3952: (0.22), 3953: (0.13), 3954: (0.16), 3955: (0.21), 3956: (0.28), 3957: (0.29), 3958: (0.22), 3959: (0.17), 3960: (0.25), 3961: (0.28), 3962: (0.40), 3963: (0.37), 3964: (0.32), 3965: (0.31), 3966: (0.29), 3967: (0.26), 3968: (0.26), 3969: (0.23), 3970: (0.27), 3971: (0.26), 3972: (0.24), 3973: (0.25), 3974: (0.35), 3975: (0.20), 3976: (0.18), 3977: (0.24), 3978: (0.31), 3979: (0.26), 3980: (0.21), 3981: (0.27), 3982: (0.30), 3983: (0.34), 3984: (0.30), 3985: (0.31), 3986: (0.35), 3987: (0.35), 3988: (0.31), 3989: (0.20), 3990: (0.29), 3991: (0.24), 3992: (0.20), 3993: (0.25), 3994: (0.25), 3995: (0.16), 3996: (0.19), 3997: (0.23), 3998: (0.25), 3999: (0.27), 4000: (0.30), 4001: (0.41), 4002: (0.50), 4003: (0.36), 4004: (0.44), 4005: (0.50), 4006: (0.33), 4007: (0.42), 4008: (0.30), 4009: (0.30), 4010: (0.29), 4011: (0.29), 4012: (0.24), 4013: (0.26), 4014: (0.38), 4015: (0.39), 4016: (0.28), 4017: (0.32), 4018: (0.46), 4019: (0.47), 4020: (0.38), 4021: (0.51), 4022: (0.46), 4023: (0.42), 4024: (0.44), 4025: (0.63), 4026: (0.54), 4027: (0.52), 4028: (0.41), 4029: (0.46), 4030: (0.50), 4031: (0.55), 4032: (0.53), 4033: (0.51), 4034: (0.40), 4035: (0.26), 4036: (0.34), 4037: (0.25), 4038: (0.20), 4039: (0.21), 4040: (0.18), 4041: (0.23), 4042: (0.29), 4043: (0.27), 4044: (0.28), 4045: (0.24), 4046: (0.29), 4047: (0.30), 4048: (0.23), 4049: (0.24), 4050: (0.20), 4051: (0.15), 4052: (0.16), 4053: (0.16), 4054: (0.15), 4055: (0.18), 4056: (0.16), 4057: (0.22), 4058: (0.17), 4059: (0.18), 4060: (0.27), 4061: (0.24), 4062: (0.26), 4063: (0.33), 4064: (0.30), 4065: (0.32), 4066: (0.39), 4067: (0.25), 4068: (0.22), 4069: (0.28), 4070: (0.38), 4071: (0.43), 4072: (0.50), 4073: (0.36), 4074: (0.38), 4075: (0.39), 4076: (0.37), 4077: (0.37), 4078: (0.28), 4079: (0.16), 4080: (0.20), 4081: (0.25), 4082: (0.21), 4083: (0.26), 4084: (0.26), 4085: (0.33), 4086: (0.24), 4087: (0.29), 4088: (0.38), 4089: (0.24), 4090: (0.16), 4091: (0.36), 4092: (0.36), 4093: (0.44), 4094: (0.35), 4095: (0.35), 4096: (0.24), 4097: (0.33), 4098: (0.30), 4099: (0.28), 4100: (0.20), 4101: (0.28), 4102: (0.31), 4103: (0.43), 4104: (0.58), 4105: (0.41), 4106: (0.29), 4107: (0.36), 4108: (0.35), 4109: (0.39), 4110: (0.40), 4111: (0.39), 4112: (0.28), 4113: (0.35), 4114: (0.41), 4115: (0.44), 4116: (0.30), 4117: (0.34), 4118: (0.36), 4119: (0.29), 4120: (0.42), 4121: (0.24), 4122: (0.18), 4123: (0.21), 4124: (0.32), 4125: (0.35), 4126: (0.33), 4127: (0.33), 4128: (0.34), 4129: (0.41), 4130: (0.36), 4131: (0.42), 4132: (0.29), 4133: (0.35), 4134: (0.21), 4135: (0.23), 4136: (0.23), 4137: (0.20), 4138: (0.16), 4139: (0.18), 4140: (0.24), 4141: (0.21), 4142: (0.24), 4143: (0.19), 4144: (0.20), 4145: (0.22), 4146: (0.25), 4147: (0.17), 4148: (0.22), 4149: (0.24), 4150: (0.26), 4151: (0.25), 4152: (0.24), 4153: (0.21), 4154: (0.27), 4155: (0.33), 4156: (0.29), 4157: (0.26), 4158: (0.21), 4159: (0.25), 4160: (0.25), 4161: (0.21), 4162: (0.27), 4163: (0.21), 4164: (0.18), 4165: (0.20), 4166: (0.27), 4167: (0.33), 4168: (0.36), 4169: (0.24), 4170: (0.27), 4171: (0.31), 4172: (0.37), 4173: (0.40), 4174: (0.32), 4175: (0.30), 4176: (0.32), 4177: (0.45), 4178: (0.38), 4179: (0.45), 4180: (0.31), 4181: (0.36), 4182: (0.27), 4183: (0.22), 4184: (0.19), 4185: (0.12), 4186: (0.20), 4187: (0.23), 4188: (0.22), 4189: (0.25), 4190: (0.22), 4191: (0.18), 4192: (0.32), 4193: (0.25), 4194: (0.21), 4195: (0.26), 4196: (0.23), 4197: (0.33), 4198: (0.31), 4199: (0.31), 4200: (0.23), 4201: (0.23), 4202: (0.23), 4203: (0.22), 4204: (0.21), 4205: (0.15), 4206: (0.14), 4207: (0.18), 4208: (0.24), 4209: (0.26), 4210: (0.26), 4211: (0.25), 4212: (0.27), 4213: (0.23), 4214: (0.30), 4215: (0.31), 4216: (0.19), 4217: (0.15), 4218: (0.17), 4219: (0.18), 4220: (0.17), 4221: (0.25), 4222: (0.21), 4223: (0.22), 4224: (0.24), 4225: (0.29), 4226: (0.21), 4227: (0.19), 4228: (0.28), 4229: (0.19), 4230: (0.27), 4231: (0.25), 4232: (0.27), 4233: (0.36), 4234: (0.29), 4235: (0.29), 4236: (0.25), 4237: (0.36), 4238: (0.31), 4239: (0.40), 4240: (0.52), 4241: (0.49), 4242: (0.63), 4243: (0.42), 4244: (0.35), 4245: (0.33), 4246: (0.31), 4247: (0.31), 4248: (0.23), 4249: (0.35), 4250: (0.39), 4251: (0.35), 4252: (0.38), 4253: (0.28), 4254: (0.35), 4255: (0.40), 4256: (0.45), 4257: (0.44), 4258: (0.25), 4259: (0.26), 4260: (0.41), 4261: (0.36), 4262: (0.47), 4263: (0.37), 4264: (0.33), 4265: (0.34), 4266: (0.51), 4267: (0.50), 4268: (0.53), 4269: (0.30), 4270: (0.30), 4271: (0.31), 4272: (0.33), 4273: (0.45), 4274: (0.33), 4275: (0.31), 4276: (0.28), 4277: (0.30), 4278: (0.27), 4279: (0.28), 4280: (0.30), 4281: (0.35), 4282: (0.39), 4283: (0.40), 4284: (0.43), 4285: (0.40), 4286: (0.39), 4287: (0.38), 4288: (0.37), 4289: (0.47), 4290: (0.37), 4291: (0.31), 4292: (0.42), 4293: (0.46), 4294: (0.49), 4295: (0.49), 4296: (0.50), 4297: (0.36), 4298: (0.50), 4299: (0.59), 4300: (0.71), 4301: (0.68), 4302: (0.69), 4303: (0.65), 4304: (0.61), 4305: (0.48), 4306: (0.44), 4307: (0.38), 4308: (0.52), 4309: (0.49), 4310: (0.50), 4311: (0.42), 4312: (0.40), 4313: (0.42), 4314: (0.49), 4315: (0.48), 4316: (0.45), 4317: (0.39), 4318: (0.25), 4319: (0.35), 4320: (0.44), 4321: (0.33), 4322: (0.32), 4323: (0.43), 4324: (0.41), 4325: (0.44), 4326: (0.49), 4327: (0.46), 4328: (0.35), 4329: (0.34), 4330: (0.28), 4331: (0.33), 4332: (0.37), 4333: (0.45), 4334: (0.41), 4335: (0.42), 4336: (0.47), 4337: (0.31), 4338: (0.21), 4339: (0.17), 4340: (0.15), 4341: (0.18), 4342: (0.14), 4343: (0.11), 4344: (0.17), 4345: (0.19), 4346: (0.15), 4347: (0.18), 4348: (0.17), 4349: (0.16), 4350: (0.21), 4351: (0.16), 4352: (0.20), 4353: (0.12), 4354: (0.11), 4355: (0.12), 4356: (0.13), 4357: (0.10), 4358: (0.09), 4359: (0.05), 4360: (0.04), 4361: (0.04), 4362: (0.08), 4363: (0.08), 4364: (0.08), 4365: (0.10), 4366: (0.09), 4367: (0.09), 4368: (0.10), 4369: (0.07), 4370: (0.07), 4371: (0.05), 4372: (0.07), 4373: (0.11), 4374: (0.05), 4375: (0.03), 4376: (0.06), 4377: (0.16), 4378: (0.09), 4379: (0.10), 4380: (0.04), 4381: (0.02), 4382: (0.01), 4383: (0.01), 4384: (0.02), 4385: (0.03), 4386: (0.03), 4387: (0.31), 4388: (0.85), 4389: (0.52), 4390: (0.27), 4391: (0.22), 4392: (0.16), 4393: (0.11), 4394: (0.10), 4395: (0.12), 4396: (0.14), 4397: (0.09), 4398: (0.09), 4399: (0.08), 4400: (0.09), 4401: (0.04), 4402: (0.02), 4403: (0.02), 4404: (0.01), 4405: (0.01), 4406: (0.01), 4407: (0.01), 4408: (0.02), 4409: (0.03), 4410: (0.02), 4411: (0.01), 4412: (0.01), 4413: (0.01), 4414: (0.01), 4415: (0.00), 4416: (0.00), 4417: (0.00), 4418: (0.00), 4419: (0.00), 4420: (0.00), 4421: (0.00), 4422: (0.00), 4423: (0.00), 4424: (0.00), 4425: (0.00), 4426: (0.00), 4427: (0.00), 4428: (0.00), 4429: (0.00), 4430: (0.00), 4431: (0.00), 4432: (0.00), 4433: (0.00), 4434: (0.00), 4435: (0.00), 4436: (0.00), 4437: (0.00), 4438: (0.00), 4439: (0.00), 4440: (0.00), 4441: (0.00), 4442: (0.00), 4443: (0.00), 4444: (0.00), 4445: (0.00), 4446: (0.00), 4447: (0.00), 4448: (0.00), 4449: (0.00), 4450: (0.00), 4451: (0.00), 4452: (0.00), 4453: (0.00), 4454: (0.00), 4455: (0.00), 4456: (0.00), 4457: (0.00), 4458: (0.00), 4459: (0.00), 4460: (0.00), 4461: (0.00), 4462: (0.00), 4463: (0.00)\"#@param {type:\"string\"}\n",
        "rotation_3d_z = \"0: (0.00), 1: (0.00), 2: (0.00), 3: (0.00), 4: (0.00), 5: (0.00), 6: (0.00), 7: (0.03), 8: (0.02), 9: (0.02), 10: (0.01), 11: (0.01), 12: (0.01), 13: (0.01), 14: (0.01), 15: (0.01), 16: (0.01), 17: (0.01), 18: (0.06), 19: (0.05), 20: (0.04), 21: (0.03), 22: (0.03), 23: (0.03), 24: (0.04), 25: (0.05), 26: (0.04), 27: (0.04), 28: (0.03), 29: (0.03), 30: (0.02), 31: (0.02), 32: (0.02), 33: (0.02), 34: (0.03), 35: (0.04), 36: (0.04), 37: (0.03), 38: (0.03), 39: (0.02), 40: (0.06), 41: (0.04), 42: (0.04), 43: (0.03), 44: (0.02), 45: (0.03), 46: (0.04), 47: (0.03), 48: (0.03), 49: (0.03), 50: (0.04), 51: (0.07), 52: (0.05), 53: (0.04), 54: (0.03), 55: (0.03), 56: (0.03), 57: (0.04), 58: (0.03), 59: (0.03), 60: (0.05), 61: (0.08), 62: (0.07), 63: (0.07), 64: (0.07), 65: (0.05), 66: (0.05), 67: (0.06), 68: (0.07), 69: (0.06), 70: (0.05), 71: (0.04), 72: (0.04), 73: (0.04), 74: (0.04), 75: (0.03), 76: (0.03), 77: (0.05), 78: (0.05), 79: (0.06), 80: (0.05), 81: (0.04), 82: (0.12), 83: (0.14), 84: (0.13), 85: (0.08), 86: (0.05), 87: (0.05), 88: (0.05), 89: (0.05), 90: (0.03), 91: (0.02), 92: (0.03), 93: (0.10), 94: (0.07), 95: (0.06), 96: (0.05), 97: (0.03), 98: (0.03), 99: (0.02), 100: (0.01), 101: (0.01), 102: (0.01), 103: (0.06), 104: (0.09), 105: (0.10), 106: (0.07), 107: (0.07), 108: (0.06), 109: (0.07), 110: (0.06), 111: (0.05), 112: (0.04), 113: (0.03), 114: (0.03), 115: (0.03), 116: (0.02), 117: (0.02), 118: (0.02), 119: (0.03), 120: (0.04), 121: (0.03), 122: (0.02), 123: (0.02), 124: (0.03), 125: (0.05), 126: (0.05), 127: (0.06), 128: (0.09), 129: (0.08), 130: (0.09), 131: (0.08), 132: (0.07), 133: (0.06), 134: (0.06), 135: (0.11), 136: (0.08), 137: (0.07), 138: (0.06), 139: (0.06), 140: (0.04), 141: (0.06), 142: (0.05), 143: (0.04), 144: (0.03), 145: (0.11), 146: (0.11), 147: (0.10), 148: (0.09), 149: (0.08), 150: (0.07), 151: (0.06), 152: (0.05), 153: (0.05), 154: (0.04), 155: (0.04), 156: (0.03), 157: (0.04), 158: (0.03), 159: (0.03), 160: (0.04), 161: (0.06), 162: (0.06), 163: (0.05), 164: (0.04), 165: (0.04), 166: (0.06), 167: (0.11), 168: (0.10), 169: (0.10), 170: (0.09), 171: (0.10), 172: (0.12), 173: (0.12), 174: (0.10), 175: (0.09), 176: (0.10), 177: (0.17), 178: (0.11), 179: (0.12), 180: (0.09), 181: (0.07), 182: (0.05), 183: (0.06), 184: (0.04), 185: (0.06), 186: (0.07), 187: (0.13), 188: (0.09), 189: (0.09), 190: (0.06), 191: (0.06), 192: (0.04), 193: (0.07), 194: (0.06), 195: (0.05), 196: (0.04), 197: (0.04), 198: (0.03), 199: (0.03), 200: (0.03), 201: (0.02), 202: (0.02), 203: (0.05), 204: (0.06), 205: (0.05), 206: (0.05), 207: (0.04), 208: (0.04), 209: (0.11), 210: (0.06), 211: (0.05), 212: (0.04), 213: (0.07), 214: (0.10), 215: (0.09), 216: (0.06), 217: (0.04), 218: (0.04), 219: (0.10), 220: (0.08), 221: (0.07), 222: (0.06), 223: (0.06), 224: (0.05), 225: (0.05), 226: (0.07), 227: (0.05), 228: (0.05), 229: (0.10), 230: (0.10), 231: (0.09), 232: (0.08), 233: (0.07), 234: (0.06), 235: (0.06), 236: (0.06), 237: (0.05), 238: (0.04), 239: (0.05), 240: (0.03), 241: (0.03), 242: (0.04), 243: (0.06), 244: (0.05), 245: (0.06), 246: (0.05), 247: (0.06), 248: (0.06), 249: (0.04), 250: (0.04), 251: (0.10), 252: (0.07), 253: (0.07), 254: (0.06), 255: (0.05), 256: (0.04), 257: (0.06), 258: (0.06), 259: (0.04), 260: (0.03), 261: (0.05), 262: (0.07), 263: (0.05), 264: (0.04), 265: (0.03), 266: (0.03), 267: (0.02), 268: (0.02), 269: (0.02), 270: (0.01), 271: (0.02), 272: (0.12), 273: (0.09), 274: (0.10), 275: (0.11), 276: (0.09), 277: (0.07), 278: (0.06), 279: (0.06), 280: (0.05), 281: (0.05), 282: (0.05), 283: (0.04), 284: (0.05), 285: (0.08), 286: (0.08), 287: (0.09), 288: (0.09), 289: (0.07), 290: (0.08), 291: (0.09), 292: (0.09), 293: (0.08), 294: (0.08), 295: (0.08), 296: (0.08), 297: (0.07), 298: (0.08), 299: (0.08), 300: (0.07), 301: (0.06), 302: (0.06), 303: (0.09), 304: (0.11), 305: (0.06), 306: (0.05), 307: (0.05), 308: (0.04), 309: (0.03), 310: (0.04), 311: (0.03), 312: (0.03), 313: (0.03), 314: (0.14), 315: (0.11), 316: (0.08), 317: (0.08), 318: (0.06), 319: (0.05), 320: (0.05), 321: (0.05), 322: (0.05), 323: (0.04), 324: (0.04), 325: (0.03), 326: (0.03), 327: (0.03), 328: (0.03), 329: (0.03), 330: (0.05), 331: (0.05), 332: (0.06), 333: (0.05), 334: (0.03), 335: (0.06), 336: (0.10), 337: (0.09), 338: (0.08), 339: (0.08), 340: (0.08), 341: (0.08), 342: (0.06), 343: (0.06), 344: (0.04), 345: (0.05), 346: (0.09), 347: (0.07), 348: (0.07), 349: (0.06), 350: (0.05), 351: (0.07), 352: (0.07), 353: (0.07), 354: (0.03), 355: (0.03), 356: (0.11), 357: (0.11), 358: (0.08), 359: (0.12), 360: (0.13), 361: (0.07), 362: (0.12), 363: (0.18), 364: (0.14), 365: (0.08), 366: (0.09), 367: (0.17), 368: (0.13), 369: (0.08), 370: (0.05), 371: (0.04), 372: (0.07), 373: (0.05), 374: (0.04), 375: (0.03), 376: (0.04), 377: (0.07), 378: (0.07), 379: (0.07), 380: (0.06), 381: (0.04), 382: (0.06), 383: (0.11), 384: (0.10), 385: (0.13), 386: (0.07), 387: (0.08), 388: (0.16), 389: (0.16), 390: (0.13), 391: (0.09), 392: (0.07), 393: (0.07), 394: (0.07), 395: (0.09), 396: (0.07), 397: (0.07), 398: (0.12), 399: (0.14), 400: (0.11), 401: (0.12), 402: (0.09), 403: (0.11), 404: (0.15), 405: (0.14), 406: (0.11), 407: (0.08), 408: (0.07), 409: (0.10), 410: (0.12), 411: (0.10), 412: (0.09), 413: (0.09), 414: (0.09), 415: (0.10), 416: (0.09), 417: (0.05), 418: (0.04), 419: (0.05), 420: (0.09), 421: (0.05), 422: (0.04), 423: (0.04), 424: (0.05), 425: (0.04), 426: (0.05), 427: (0.04), 428: (0.04), 429: (0.03), 430: (0.06), 431: (0.10), 432: (0.06), 433: (0.03), 434: (0.03), 435: (0.04), 436: (0.04), 437: (0.02), 438: (0.02), 439: (0.01), 440: (0.03), 441: (0.07), 442: (0.07), 443: (0.06), 444: (0.07), 445: (0.06), 446: (0.12), 447: (0.10), 448: (0.09), 449: (0.07), 450: (0.07), 451: (0.06), 452: (0.05), 453: (0.05), 454: (0.04), 455: (0.05), 456: (0.09), 457: (0.11), 458: (0.08), 459: (0.08), 460: (0.08), 461: (0.05), 462: (0.15), 463: (0.11), 464: (0.07), 465: (0.05), 466: (0.07), 467: (0.07), 468: (0.07), 469: (0.09), 470: (0.06), 471: (0.05), 472: (0.08), 473: (0.07), 474: (0.07), 475: (0.08), 476: (0.07), 477: (0.06), 478: (0.05), 479: (0.04), 480: (0.04), 481: (0.03), 482: (0.04), 483: (0.13), 484: (0.09), 485: (0.08), 486: (0.07), 487: (0.06), 488: (0.05), 489: (0.06), 490: (0.06), 491: (0.05), 492: (0.06), 493: (0.06), 494: (0.07), 495: (0.07), 496: (0.05), 497: (0.05), 498: (0.06), 499: (0.06), 500: (0.08), 501: (0.06), 502: (0.05), 503: (0.04), 504: (0.10), 505: (0.11), 506: (0.08), 507: (0.06), 508: (0.05), 509: (0.06), 510: (0.10), 511: (0.07), 512: (0.05), 513: (0.05), 514: (0.08), 515: (0.20), 516: (0.09), 517: (0.07), 518: (0.06), 519: (0.05), 520: (0.04), 521: (0.05), 522: (0.04), 523: (0.04), 524: (0.04), 525: (0.04), 526: (0.04), 527: (0.03), 528: (0.03), 529: (0.03), 530: (0.02), 531: (0.02), 532: (0.02), 533: (0.02), 534: (0.03), 535: (0.02), 536: (0.02), 537: (0.03), 538: (0.02), 539: (0.03), 540: (0.02), 541: (0.02), 542: (0.02), 543: (0.02), 544: (0.02), 545: (0.01), 546: (0.02), 547: (0.01), 548: (0.01), 549: (0.01), 550: (0.01), 551: (0.02), 552: (0.02), 553: (0.01), 554: (0.01), 555: (0.01), 556: (0.01), 557: (0.01), 558: (0.01), 559: (0.02), 560: (0.02), 561: (0.02), 562: (0.02), 563: (0.02), 564: (0.02), 565: (0.01), 566: (0.02), 567: (0.01), 568: (0.01), 569: (0.02), 570: (0.05), 571: (0.04), 572: (0.04), 573: (0.04), 574: (0.04), 575: (0.03), 576: (0.03), 577: (0.04), 578: (0.05), 579: (0.03), 580: (0.03), 581: (0.05), 582: (0.08), 583: (0.07), 584: (0.10), 585: (0.12), 586: (0.07), 587: (0.04), 588: (0.03), 589: (0.03), 590: (0.04), 591: (0.06), 592: (0.09), 593: (0.04), 594: (0.03), 595: (0.03), 596: (0.03), 597: (0.02), 598: (0.03), 599: (0.05), 600: (0.06), 601: (0.04), 602: (0.03), 603: (0.04), 604: (0.04), 605: (0.04), 606: (0.05), 607: (0.04), 608: (0.04), 609: (0.05), 610: (0.06), 611: (0.09), 612: (0.15), 613: (0.10), 614: (0.07), 615: (0.06), 616: (0.06), 617: (0.03), 618: (0.02), 619: (0.03), 620: (0.04), 621: (0.04), 622: (0.04), 623: (0.04), 624: (0.03), 625: (0.03), 626: (0.05), 627: (0.06), 628: (0.06), 629: (0.04), 630: (0.04), 631: (0.02), 632: (0.03), 633: (0.03), 634: (0.04), 635: (0.03), 636: (0.03), 637: (0.04), 638: (0.05), 639: (0.04), 640: (0.04), 641: (0.05), 642: (0.03), 643: (0.03), 644: (0.01), 645: (0.02), 646: (0.02), 647: (0.01), 648: (0.02), 649: (0.02), 650: (0.02), 651: (0.02), 652: (0.02), 653: (0.02), 654: (0.02), 655: (0.02), 656: (0.03), 657: (0.03), 658: (0.03), 659: (0.04), 660: (0.05), 661: (0.01), 662: (0.01), 663: (0.02), 664: (0.02), 665: (0.03), 666: (0.03), 667: (0.04), 668: (0.04), 669: (0.03), 670: (0.04), 671: (0.07), 672: (0.01), 673: (0.02), 674: (0.03), 675: (0.04), 676: (0.04), 677: (0.06), 678: (0.07), 679: (0.06), 680: (0.06), 681: (0.04), 682: (0.01), 683: (0.06), 684: (0.03), 685: (0.05), 686: (0.04), 687: (0.03), 688: (0.02), 689: (0.01), 690: (0.01), 691: (0.01), 692: (0.02), 693: (0.03), 694: (0.01), 695: (0.02), 696: (0.02), 697: (0.01), 698: (0.02), 699: (0.03), 700: (0.03), 701: (0.03), 702: (0.01), 703: (0.02), 704: (0.01), 705: (0.00), 706: (0.01), 707: (0.00), 708: (0.00), 709: (0.01), 710: (0.01), 711: (0.02), 712: (0.02), 713: (0.02), 714: (0.01), 715: (0.01), 716: (0.01), 717: (0.02), 718: (0.03), 719: (0.04), 720: (0.02), 721: (0.01), 722: (0.02), 723: (0.01), 724: (0.01), 725: (0.00), 726: (0.00), 727: (0.01), 728: (0.01), 729: (0.01), 730: (0.01), 731: (0.01), 732: (0.01), 733: (0.03), 734: (0.02), 735: (0.02), 736: (0.04), 737: (0.04), 738: (0.02), 739: (0.03), 740: (0.03), 741: (0.03), 742: (0.02), 743: (0.03), 744: (0.06), 745: (0.05), 746: (0.03), 747: (0.04), 748: (0.04), 749: (0.03), 750: (0.05), 751: (0.06), 752: (0.06), 753: (0.04), 754: (0.01), 755: (0.02), 756: (0.01), 757: (0.01), 758: (0.01), 759: (0.01), 760: (0.01), 761: (0.02), 762: (0.02), 763: (0.01), 764: (0.01), 765: (0.02), 766: (0.02), 767: (0.01), 768: (0.01), 769: (0.01), 770: (0.01), 771: (0.02), 772: (0.01), 773: (0.01), 774: (0.01), 775: (0.02), 776: (0.01), 777: (0.02), 778: (0.02), 779: (0.04), 780: (0.06), 781: (0.04), 782: (0.02), 783: (0.04), 784: (0.03), 785: (0.04), 786: (0.04), 787: (0.03), 788: (0.02), 789: (0.01), 790: (0.02), 791: (0.01), 792: (0.00), 793: (0.00), 794: (0.00), 795: (0.00), 796: (0.00), 797: (0.01), 798: (0.01), 799: (0.01), 800: (0.01), 801: (0.01), 802: (0.01), 803: (0.02), 804: (0.01), 805: (0.00), 806: (0.00), 807: (0.00), 808: (0.01), 809: (0.00), 810: (0.00), 811: (0.00), 812: (0.00), 813: (0.00), 814: (0.00), 815: (0.00), 816: (0.00), 817: (0.01), 818: (0.00), 819: (0.01), 820: (0.03), 821: (0.03), 822: (0.02), 823: (0.03), 824: (0.02), 825: (0.02), 826: (0.04), 827: (0.04), 828: (0.02), 829: (0.03), 830: (0.01), 831: (0.01), 832: (0.07), 833: (0.15), 834: (0.08), 835: (0.08), 836: (0.22), 837: (0.09), 838: (0.01), 839: (0.01), 840: (0.00), 841: (0.00), 842: (0.01), 843: (0.01), 844: (0.00), 845: (0.00), 846: (0.00), 847: (0.00), 848: (0.00), 849: (0.00), 850: (0.00), 851: (0.00), 852: (0.00), 853: (0.00), 854: (0.00), 855: (0.00), 856: (0.00), 857: (0.00), 858: (0.01), 859: (0.01), 860: (0.01), 861: (0.01), 862: (0.00), 863: (0.00), 864: (0.00), 865: (0.00), 866: (0.00), 867: (0.00), 868: (0.00), 869: (0.00), 870: (0.00), 871: (0.00), 872: (0.00), 873: (0.00), 874: (0.00), 875: (0.00), 876: (0.00), 877: (0.00), 878: (0.00), 879: (0.01), 880: (0.00), 881: (0.01), 882: (0.01), 883: (0.00), 884: (0.00), 885: (0.00), 886: (0.00), 887: (0.01), 888: (0.01), 889: (0.00), 890: (0.00), 891: (0.01), 892: (0.01), 893: (0.01), 894: (0.00), 895: (0.01), 896: (0.01), 897: (0.01), 898: (0.02), 899: (0.01), 900: (0.01), 901: (0.01), 902: (0.01), 903: (0.00), 904: (0.00), 905: (0.00), 906: (0.01), 907: (0.01), 908: (0.01), 909: (0.01), 910: (0.01), 911: (0.01), 912: (0.02), 913: (0.03), 914: (0.03), 915: (0.03), 916: (0.03), 917: (0.03), 918: (0.03), 919: (0.02), 920: (0.01), 921: (0.01), 922: (0.01), 923: (0.01), 924: (0.01), 925: (0.01), 926: (0.01), 927: (0.01), 928: (0.02), 929: (0.03), 930: (0.02), 931: (0.02), 932: (0.01), 933: (0.03), 934: (0.02), 935: (0.01), 936: (0.01), 937: (0.02), 938: (0.02), 939: (0.02), 940: (0.01), 941: (0.01), 942: (0.01), 943: (0.01), 944: (0.02), 945: (0.01), 946: (0.01), 947: (0.01), 948: (0.00), 949: (0.00), 950: (0.00), 951: (0.00), 952: (0.01), 953: (0.01), 954: (0.01), 955: (0.00), 956: (0.00), 957: (0.00), 958: (0.00), 959: (0.00), 960: (0.00), 961: (0.00), 962: (0.00), 963: (0.00), 964: (0.00), 965: (0.00), 966: (0.00), 967: (0.00), 968: (0.00), 969: (0.00), 970: (0.00), 971: (0.00), 972: (0.00), 973: (0.00), 974: (0.00), 975: (0.00), 976: (0.00), 977: (0.00), 978: (0.00), 979: (0.00), 980: (0.00), 981: (0.00), 982: (0.00), 983: (0.00), 984: (0.00), 985: (0.00), 986: (0.00), 987: (0.00), 988: (0.00), 989: (0.00), 990: (0.00), 991: (0.00), 992: (0.00), 993: (0.00), 994: (0.00), 995: (0.00), 996: (0.00), 997: (0.00), 998: (0.00), 999: (0.00), 1000: (0.01), 1001: (0.01), 1002: (0.01), 1003: (0.02), 1004: (0.02), 1005: (0.02), 1006: (0.03), 1007: (0.03), 1008: (0.03), 1009: (0.02), 1010: (0.02), 1011: (0.03), 1012: (0.03), 1013: (0.03), 1014: (0.03), 1015: (0.05), 1016: (0.04), 1017: (0.03), 1018: (0.04), 1019: (0.01), 1020: (0.02), 1021: (0.05), 1022: (0.08), 1023: (0.07), 1024: (0.08), 1025: (0.08), 1026: (0.08), 1027: (0.10), 1028: (0.14), 1029: (0.17), 1030: (0.23), 1031: (0.16), 1032: (0.20), 1033: (0.23), 1034: (0.17), 1035: (0.14), 1036: (0.13), 1037: (0.12), 1038: (0.18), 1039: (0.20), 1040: (0.15), 1041: (0.10), 1042: (0.06), 1043: (0.05), 1044: (0.04), 1045: (0.04), 1046: (0.05), 1047: (0.06), 1048: (0.08), 1049: (0.09), 1050: (0.09), 1051: (0.08), 1052: (0.04), 1053: (0.04), 1054: (0.04), 1055: (0.07), 1056: (0.08), 1057: (0.11), 1058: (0.13), 1059: (0.08), 1060: (0.08), 1061: (0.08), 1062: (0.06), 1063: (0.03), 1064: (0.05), 1065: (0.04), 1066: (0.04), 1067: (0.04), 1068: (0.05), 1069: (0.09), 1070: (0.12), 1071: (0.13), 1072: (0.10), 1073: (0.06), 1074: (0.10), 1075: (0.11), 1076: (0.11), 1077: (0.14), 1078: (0.18), 1079: (0.29), 1080: (0.19), 1081: (0.18), 1082: (0.20), 1083: (0.13), 1084: (0.08), 1085: (0.07), 1086: (0.08), 1087: (0.05), 1088: (0.04), 1089: (0.05), 1090: (0.08), 1091: (0.06), 1092: (0.07), 1093: (0.05), 1094: (0.02), 1095: (0.02), 1096: (0.05), 1097: (0.06), 1098: (0.09), 1099: (0.07), 1100: (0.07), 1101: (0.08), 1102: (0.09), 1103: (0.10), 1104: (0.07), 1105: (0.06), 1106: (0.06), 1107: (0.03), 1108: (0.05), 1109: (0.04), 1110: (0.04), 1111: (0.08), 1112: (0.07), 1113: (0.07), 1114: (0.07), 1115: (0.12), 1116: (0.10), 1117: (0.11), 1118: (0.10), 1119: (0.11), 1120: (0.10), 1121: (0.06), 1122: (0.08), 1123: (0.07), 1124: (0.10), 1125: (0.08), 1126: (0.04), 1127: (0.06), 1128: (0.04), 1129: (0.04), 1130: (0.06), 1131: (0.05), 1132: (0.12), 1133: (0.10), 1134: (0.09), 1135: (0.08), 1136: (0.08), 1137: (0.09), 1138: (0.18), 1139: (0.13), 1140: (0.09), 1141: (0.07), 1142: (0.07), 1143: (0.09), 1144: (0.07), 1145: (0.07), 1146: (0.02), 1147: (0.01), 1148: (0.04), 1149: (0.03), 1150: (0.04), 1151: (0.05), 1152: (0.06), 1153: (0.09), 1154: (0.07), 1155: (0.08), 1156: (0.07), 1157: (0.08), 1158: (0.07), 1159: (0.12), 1160: (0.12), 1161: (0.17), 1162: (0.16), 1163: (0.12), 1164: (0.14), 1165: (0.09), 1166: (0.08), 1167: (0.05), 1168: (0.02), 1169: (0.04), 1170: (0.09), 1171: (0.09), 1172: (0.14), 1173: (0.18), 1174: (0.14), 1175: (0.12), 1176: (0.13), 1177: (0.07), 1178: (0.03), 1179: (0.03), 1180: (0.04), 1181: (0.03), 1182: (0.05), 1183: (0.03), 1184: (0.04), 1185: (0.03), 1186: (0.04), 1187: (0.08), 1188: (0.11), 1189: (0.09), 1190: (0.07), 1191: (0.06), 1192: (0.08), 1193: (0.15), 1194: (0.08), 1195: (0.12), 1196: (0.15), 1197: (0.18), 1198: (0.18), 1199: (0.13), 1200: (0.10), 1201: (0.17), 1202: (0.13), 1203: (0.12), 1204: (0.18), 1205: (0.17), 1206: (0.25), 1207: (0.31), 1208: (0.30), 1209: (0.26), 1210: (0.15), 1211: (0.05), 1212: (0.05), 1213: (0.08), 1214: (0.11), 1215: (0.09), 1216: (0.07), 1217: (0.07), 1218: (0.05), 1219: (0.09), 1220: (0.07), 1221: (0.04), 1222: (0.08), 1223: (0.11), 1224: (0.10), 1225: (0.08), 1226: (0.11), 1227: (0.17), 1228: (0.26), 1229: (0.27), 1230: (0.24), 1231: (0.07), 1232: (0.03), 1233: (0.04), 1234: (0.06), 1235: (0.06), 1236: (0.06), 1237: (0.09), 1238: (0.11), 1239: (0.12), 1240: (0.12), 1241: (0.10), 1242: (0.04), 1243: (0.09), 1244: (0.11), 1245: (0.10), 1246: (0.14), 1247: (0.09), 1248: (0.11), 1249: (0.12), 1250: (0.12), 1251: (0.11), 1252: (0.09), 1253: (0.07), 1254: (0.06), 1255: (0.07), 1256: (0.06), 1257: (0.09), 1258: (0.06), 1259: (0.11), 1260: (0.08), 1261: (0.08), 1262: (0.08), 1263: (0.03), 1264: (0.06), 1265: (0.06), 1266: (0.05), 1267: (0.05), 1268: (0.04), 1269: (0.05), 1270: (0.05), 1271: (0.06), 1272: (0.05), 1273: (0.02), 1274: (0.03), 1275: (0.04), 1276: (0.02), 1277: (0.02), 1278: (0.04), 1279: (0.04), 1280: (0.04), 1281: (0.06), 1282: (0.05), 1283: (0.05), 1284: (0.03), 1285: (0.10), 1286: (0.10), 1287: (0.11), 1288: (0.11), 1289: (0.11), 1290: (0.10), 1291: (0.11), 1292: (0.07), 1293: (0.06), 1294: (0.03), 1295: (0.02), 1296: (0.06), 1297: (0.07), 1298: (0.07), 1299: (0.08), 1300: (0.08), 1301: (0.11), 1302: (0.08), 1303: (0.08), 1304: (0.06), 1305: (0.05), 1306: (0.09), 1307: (0.07), 1308: (0.05), 1309: (0.05), 1310: (0.09), 1311: (0.09), 1312: (0.10), 1313: (0.09), 1314: (0.09), 1315: (0.09), 1316: (0.09), 1317: (0.08), 1318: (0.07), 1319: (0.07), 1320: (0.09), 1321: (0.12), 1322: (0.13), 1323: (0.14), 1324: (0.12), 1325: (0.09), 1326: (0.08), 1327: (0.09), 1328: (0.09), 1329: (0.08), 1330: (0.07), 1331: (0.07), 1332: (0.06), 1333: (0.06), 1334: (0.07), 1335: (0.07), 1336: (0.06), 1337: (0.03), 1338: (0.03), 1339: (0.06), 1340: (0.10), 1341: (0.05), 1342: (0.05), 1343: (0.08), 1344: (0.08), 1345: (0.08), 1346: (0.11), 1347: (0.11), 1348: (0.06), 1349: (0.05), 1350: (0.04), 1351: (0.06), 1352: (0.07), 1353: (0.05), 1354: (0.04), 1355: (0.06), 1356: (0.05), 1357: (0.07), 1358: (0.05), 1359: (0.09), 1360: (0.13), 1361: (0.14), 1362: (0.21), 1363: (0.23), 1364: (0.22), 1365: (0.16), 1366: (0.15), 1367: (0.19), 1368: (0.22), 1369: (0.20), 1370: (0.20), 1371: (0.27), 1372: (0.23), 1373: (0.26), 1374: (0.27), 1375: (0.30), 1376: (0.33), 1377: (0.34), 1378: (0.43), 1379: (0.22), 1380: (0.32), 1381: (0.30), 1382: (0.50), 1383: (0.50), 1384: (0.53), 1385: (0.49), 1386: (0.55), 1387: (0.41), 1388: (0.65), 1389: (0.69), 1390: (0.34), 1391: (0.69), 1392: (0.44), 1393: (0.26), 1394: (0.32), 1395: (0.30), 1396: (0.31), 1397: (0.40), 1398: (0.44), 1399: (0.31), 1400: (0.16), 1401: (0.28), 1402: (0.33), 1403: (0.47), 1404: (0.46), 1405: (0.49), 1406: (0.78), 1407: (0.77), 1408: (0.74), 1409: (0.43), 1410: (0.59), 1411: (0.76), 1412: (0.51), 1413: (0.38), 1414: (0.39), 1415: (0.45), 1416: (0.47), 1417: (0.59), 1418: (0.57), 1419: (0.37), 1420: (0.48), 1421: (0.42), 1422: (0.31), 1423: (0.29), 1424: (0.47), 1425: (0.54), 1426: (0.33), 1427: (0.42), 1428: (0.35), 1429: (0.35), 1430: (0.30), 1431: (0.32), 1432: (0.14), 1433: (0.20), 1434: (0.21), 1435: (0.24), 1436: (0.21), 1437: (0.17), 1438: (0.20), 1439: (0.31), 1440: (0.34), 1441: (0.19), 1442: (0.14), 1443: (0.08), 1444: (0.07), 1445: (0.09), 1446: (0.12), 1447: (0.11), 1448: (0.18), 1449: (0.29), 1450: (0.33), 1451: (0.29), 1452: (0.31), 1453: (0.23), 1454: (0.14), 1455: (0.17), 1456: (0.17), 1457: (0.13), 1458: (0.15), 1459: (0.14), 1460: (0.20), 1461: (0.23), 1462: (0.23), 1463: (0.16), 1464: (0.12), 1465: (0.14), 1466: (0.14), 1467: (0.12), 1468: (0.15), 1469: (0.18), 1470: (0.37), 1471: (0.41), 1472: (0.24), 1473: (0.21), 1474: (0.16), 1475: (0.15), 1476: (0.12), 1477: (0.12), 1478: (0.10), 1479: (0.10), 1480: (0.13), 1481: (0.13), 1482: (0.15), 1483: (0.13), 1484: (0.06), 1485: (0.05), 1486: (0.05), 1487: (0.05), 1488: (0.07), 1489: (0.06), 1490: (0.09), 1491: (0.11), 1492: (0.25), 1493: (0.18), 1494: (0.22), 1495: (0.19), 1496: (0.13), 1497: (0.10), 1498: (0.14), 1499: (0.14), 1500: (0.11), 1501: (0.14), 1502: (0.23), 1503: (0.25), 1504: (0.31), 1505: (0.29), 1506: (0.12), 1507: (0.10), 1508: (0.12), 1509: (0.14), 1510: (0.14), 1511: (0.14), 1512: (0.17), 1513: (0.17), 1514: (0.16), 1515: (0.13), 1516: (0.08), 1517: (0.09), 1518: (0.09), 1519: (0.11), 1520: (0.07), 1521: (0.08), 1522: (0.14), 1523: (0.17), 1524: (0.23), 1525: (0.22), 1526: (0.12), 1527: (0.08), 1528: (0.10), 1529: (0.11), 1530: (0.14), 1531: (0.12), 1532: (0.19), 1533: (0.23), 1534: (0.34), 1535: (0.33), 1536: (0.30), 1537: (0.36), 1538: (0.27), 1539: (0.29), 1540: (0.33), 1541: (0.30), 1542: (0.33), 1543: (0.55), 1544: (0.63), 1545: (0.66), 1546: (0.54), 1547: (0.59), 1548: (0.33), 1549: (0.35), 1550: (0.37), 1551: (0.63), 1552: (0.69), 1553: (0.60), 1554: (0.59), 1555: (0.81), 1556: (0.96), 1557: (1.00), 1558: (0.46), 1559: (0.25), 1560: (0.20), 1561: (0.12), 1562: (0.12), 1563: (0.10), 1564: (0.07), 1565: (0.09), 1566: (0.12), 1567: (0.13), 1568: (0.11), 1569: (0.09), 1570: (0.22), 1571: (0.36), 1572: (0.44), 1573: (0.29), 1574: (0.30), 1575: (0.31), 1576: (0.27), 1577: (0.37), 1578: (0.45), 1579: (0.47), 1580: (0.52), 1581: (0.47), 1582: (0.48), 1583: (0.42), 1584: (0.33), 1585: (0.40), 1586: (0.39), 1587: (0.33), 1588: (0.23), 1589: (0.16), 1590: (0.13), 1591: (0.12), 1592: (0.14), 1593: (0.15), 1594: (0.24), 1595: (0.20), 1596: (0.16), 1597: (0.16), 1598: (0.30), 1599: (0.46), 1600: (0.38), 1601: (0.43), 1602: (0.24), 1603: (0.17), 1604: (0.13), 1605: (0.21), 1606: (0.14), 1607: (0.19), 1608: (0.24), 1609: (0.17), 1610: (0.16), 1611: (0.14), 1612: (0.15), 1613: (0.17), 1614: (0.16), 1615: (0.19), 1616: (0.27), 1617: (0.26), 1618: (0.18), 1619: (0.23), 1620: (0.27), 1621: (0.19), 1622: (0.16), 1623: (0.19), 1624: (0.28), 1625: (0.23), 1626: (0.18), 1627: (0.23), 1628: (0.19), 1629: (0.31), 1630: (0.40), 1631: (0.37), 1632: (0.24), 1633: (0.14), 1634: (0.14), 1635: (0.16), 1636: (0.19), 1637: (0.25), 1638: (0.29), 1639: (0.40), 1640: (0.40), 1641: (0.46), 1642: (0.37), 1643: (0.24), 1644: (0.19), 1645: (0.24), 1646: (0.27), 1647: (0.32), 1648: (0.19), 1649: (0.25), 1650: (0.25), 1651: (0.25), 1652: (0.34), 1653: (0.21), 1654: (0.18), 1655: (0.27), 1656: (0.30), 1657: (0.28), 1658: (0.29), 1659: (0.32), 1660: (0.33), 1661: (0.30), 1662: (0.36), 1663: (0.28), 1664: (0.29), 1665: (0.30), 1666: (0.23), 1667: (0.22), 1668: (0.27), 1669: (0.30), 1670: (0.25), 1671: (0.20), 1672: (0.18), 1673: (0.23), 1674: (0.21), 1675: (0.13), 1676: (0.17), 1677: (0.13), 1678: (0.14), 1679: (0.14), 1680: (0.16), 1681: (0.16), 1682: (0.16), 1683: (0.17), 1684: (0.17), 1685: (0.18), 1686: (0.22), 1687: (0.18), 1688: (0.16), 1689: (0.09), 1690: (0.08), 1691: (0.06), 1692: (0.09), 1693: (0.17), 1694: (0.16), 1695: (0.17), 1696: (0.12), 1697: (0.25), 1698: (0.25), 1699: (0.29), 1700: (0.32), 1701: (0.32), 1702: (0.14), 1703: (0.12), 1704: (0.14), 1705: (0.13), 1706: (0.19), 1707: (0.20), 1708: (0.22), 1709: (0.23), 1710: (0.21), 1711: (0.18), 1712: (0.21), 1713: (0.24), 1714: (0.20), 1715: (0.18), 1716: (0.15), 1717: (0.13), 1718: (0.19), 1719: (0.12), 1720: (0.13), 1721: (0.09), 1722: (0.11), 1723: (0.16), 1724: (0.20), 1725: (0.29), 1726: (0.23), 1727: (0.12), 1728: (0.22), 1729: (0.25), 1730: (0.30), 1731: (0.41), 1732: (0.28), 1733: (0.23), 1734: (0.27), 1735: (0.31), 1736: (0.25), 1737: (0.25), 1738: (0.20), 1739: (0.31), 1740: (0.32), 1741: (0.38), 1742: (0.40), 1743: (0.33), 1744: (0.28), 1745: (0.34), 1746: (0.26), 1747: (0.22), 1748: (0.17), 1749: (0.14), 1750: (0.20), 1751: (0.29), 1752: (0.19), 1753: (0.18), 1754: (0.20), 1755: (0.24), 1756: (0.19), 1757: (0.21), 1758: (0.16), 1759: (0.12), 1760: (0.09), 1761: (0.13), 1762: (0.12), 1763: (0.11), 1764: (0.15), 1765: (0.18), 1766: (0.19), 1767: (0.17), 1768: (0.27), 1769: (0.17), 1770: (0.24), 1771: (0.13), 1772: (0.09), 1773: (0.11), 1774: (0.12), 1775: (0.15), 1776: (0.15), 1777: (0.18), 1778: (0.16), 1779: (0.11), 1780: (0.12), 1781: (0.11), 1782: (0.10), 1783: (0.12), 1784: (0.11), 1785: (0.14), 1786: (0.16), 1787: (0.16), 1788: (0.17), 1789: (0.21), 1790: (0.17), 1791: (0.12), 1792: (0.16), 1793: (0.18), 1794: (0.23), 1795: (0.21), 1796: (0.14), 1797: (0.19), 1798: (0.20), 1799: (0.24), 1800: (0.18), 1801: (0.13), 1802: (0.14), 1803: (0.16), 1804: (0.23), 1805: (0.24), 1806: (0.25), 1807: (0.57), 1808: (0.60), 1809: (0.67), 1810: (0.58), 1811: (0.40), 1812: (0.30), 1813: (0.23), 1814: (0.35), 1815: (0.21), 1816: (0.28), 1817: (0.27), 1818: (0.20), 1819: (0.17), 1820: (0.18), 1821: (0.14), 1822: (0.08), 1823: (0.12), 1824: (0.15), 1825: (0.21), 1826: (0.20), 1827: (0.23), 1828: (0.14), 1829: (0.19), 1830: (0.22), 1831: (0.13), 1832: (0.15), 1833: (0.17), 1834: (0.20), 1835: (0.17), 1836: (0.19), 1837: (0.18), 1838: (0.15), 1839: (0.15), 1840: (0.14), 1841: (0.13), 1842: (0.15), 1843: (0.11), 1844: (0.10), 1845: (0.08), 1846: (0.08), 1847: (0.06), 1848: (0.07), 1849: (0.15), 1850: (0.12), 1851: (0.14), 1852: (0.17), 1853: (0.12), 1854: (0.06), 1855: (0.10), 1856: (0.13), 1857: (0.18), 1858: (0.18), 1859: (0.18), 1860: (0.19), 1861: (0.21), 1862: (0.21), 1863: (0.15), 1864: (0.13), 1865: (0.15), 1866: (0.16), 1867: (0.15), 1868: (0.19), 1869: (0.15), 1870: (0.19), 1871: (0.13), 1872: (0.17), 1873: (0.13), 1874: (0.12), 1875: (0.13), 1876: (0.15), 1877: (0.30), 1878: (0.30), 1879: (0.27), 1880: (0.28), 1881: (0.18), 1882: (0.23), 1883: (0.27), 1884: (0.24), 1885: (0.13), 1886: (0.11), 1887: (0.13), 1888: (0.11), 1889: (0.09), 1890: (0.09), 1891: (0.10), 1892: (0.13), 1893: (0.15), 1894: (0.15), 1895: (0.11), 1896: (0.08), 1897: (0.20), 1898: (0.21), 1899: (0.23), 1900: (0.24), 1901: (0.17), 1902: (0.17), 1903: (0.20), 1904: (0.25), 1905: (0.24), 1906: (0.19), 1907: (0.17), 1908: (0.23), 1909: (0.24), 1910: (0.37), 1911: (0.24), 1912: (0.23), 1913: (0.26), 1914: (0.13), 1915: (0.19), 1916: (0.15), 1917: (0.14), 1918: (0.18), 1919: (0.24), 1920: (0.19), 1921: (0.17), 1922: (0.26), 1923: (0.15), 1924: (0.17), 1925: (0.16), 1926: (0.17), 1927: (0.16), 1928: (0.09), 1929: (0.16), 1930: (0.23), 1931: (0.25), 1932: (0.23), 1933: (0.33), 1934: (0.35), 1935: (0.27), 1936: (0.38), 1937: (0.39), 1938: (0.38), 1939: (0.27), 1940: (0.46), 1941: (0.29), 1942: (0.20), 1943: (0.19), 1944: (0.21), 1945: (0.18), 1946: (0.15), 1947: (0.14), 1948: (0.20), 1949: (0.18), 1950: (0.16), 1951: (0.18), 1952: (0.18), 1953: (0.20), 1954: (0.26), 1955: (0.22), 1956: (0.18), 1957: (0.29), 1958: (0.22), 1959: (0.28), 1960: (0.25), 1961: (0.23), 1962: (0.21), 1963: (0.21), 1964: (0.21), 1965: (0.22), 1966: (0.22), 1967: (0.21), 1968: (0.26), 1969: (0.22), 1970: (0.33), 1971: (0.32), 1972: (0.32), 1973: (0.31), 1974: (0.27), 1975: (0.23), 1976: (0.19), 1977: (0.17), 1978: (0.15), 1979: (0.15), 1980: (0.16), 1981: (0.18), 1982: (0.22), 1983: (0.22), 1984: (0.23), 1985: (0.21), 1986: (0.18), 1987: (0.21), 1988: (0.15), 1989: (0.17), 1990: (0.13), 1991: (0.14), 1992: (0.13), 1993: (0.12), 1994: (0.11), 1995: (0.09), 1996: (0.05), 1997: (0.00), 1998: (0.01), 1999: (0.02), 2000: (0.04), 2001: (0.06), 2002: (0.07), 2003: (0.06), 2004: (0.08), 2005: (0.10), 2006: (0.09), 2007: (0.08), 2008: (0.06), 2009: (0.10), 2010: (0.12), 2011: (0.11), 2012: (0.08), 2013: (0.07), 2014: (0.19), 2015: (0.14), 2016: (0.11), 2017: (0.11), 2018: (0.03), 2019: (0.01), 2020: (0.01), 2021: (0.00), 2022: (0.00), 2023: (0.01), 2024: (0.01), 2025: (0.03), 2026: (0.12), 2027: (0.19), 2028: (0.18), 2029: (0.13), 2030: (0.09), 2031: (0.10), 2032: (0.04), 2033: (0.01), 2034: (0.02), 2035: (0.04), 2036: (0.05), 2037: (0.06), 2038: (0.04), 2039: (0.07), 2040: (0.10), 2041: (0.12), 2042: (0.17), 2043: (0.16), 2044: (0.11), 2045: (0.11), 2046: (0.10), 2047: (0.09), 2048: (0.07), 2049: (0.06), 2050: (0.07), 2051: (0.11), 2052: (0.14), 2053: (0.09), 2054: (0.01), 2055: (0.02), 2056: (0.04), 2057: (0.06), 2058: (0.07), 2059: (0.06), 2060: (0.07), 2061: (0.11), 2062: (0.09), 2063: (0.05), 2064: (0.04), 2065: (0.01), 2066: (0.05), 2067: (0.04), 2068: (0.07), 2069: (0.08), 2070: (0.08), 2071: (0.08), 2072: (0.09), 2073: (0.10), 2074: (0.10), 2075: (0.04), 2076: (0.03), 2077: (0.04), 2078: (0.02), 2079: (0.03), 2080: (0.04), 2081: (0.06), 2082: (0.07), 2083: (0.08), 2084: (0.08), 2085: (0.08), 2086: (0.08), 2087: (0.10), 2088: (0.10), 2089: (0.08), 2090: (0.08), 2091: (0.11), 2092: (0.13), 2093: (0.11), 2094: (0.12), 2095: (0.10), 2096: (0.04), 2097: (0.01), 2098: (0.03), 2099: (0.03), 2100: (0.03), 2101: (0.03), 2102: (0.05), 2103: (0.06), 2104: (0.03), 2105: (0.03), 2106: (0.01), 2107: (0.01), 2108: (0.04), 2109: (0.04), 2110: (0.05), 2111: (0.06), 2112: (0.06), 2113: (0.09), 2114: (0.06), 2115: (0.06), 2116: (0.03), 2117: (0.02), 2118: (0.02), 2119: (0.03), 2120: (0.03), 2121: (0.04), 2122: (0.02), 2123: (0.03), 2124: (0.06), 2125: (0.05), 2126: (0.06), 2127: (0.05), 2128: (0.06), 2129: (0.09), 2130: (0.08), 2131: (0.05), 2132: (0.05), 2133: (0.05), 2134: (0.07), 2135: (0.08), 2136: (0.05), 2137: (0.07), 2138: (0.05), 2139: (0.03), 2140: (0.04), 2141: (0.02), 2142: (0.04), 2143: (0.07), 2144: (0.09), 2145: (0.09), 2146: (0.05), 2147: (0.09), 2148: (0.08), 2149: (0.07), 2150: (0.09), 2151: (0.06), 2152: (0.10), 2153: (0.08), 2154: (0.05), 2155: (0.04), 2156: (0.04), 2157: (0.05), 2158: (0.03), 2159: (0.01), 2160: (0.01), 2161: (0.03), 2162: (0.03), 2163: (0.06), 2164: (0.05), 2165: (0.05), 2166: (0.07), 2167: (0.08), 2168: (0.05), 2169: (0.05), 2170: (0.06), 2171: (0.05), 2172: (0.06), 2173: (0.09), 2174: (0.08), 2175: (0.10), 2176: (0.10), 2177: (0.11), 2178: (0.08), 2179: (0.09), 2180: (0.04), 2181: (0.02), 2182: (0.05), 2183: (0.08), 2184: (0.10), 2185: (0.11), 2186: (0.08), 2187: (0.10), 2188: (0.08), 2189: (0.08), 2190: (0.07), 2191: (0.01), 2192: (0.03), 2193: (0.03), 2194: (0.03), 2195: (0.03), 2196: (0.04), 2197: (0.07), 2198: (0.21), 2199: (0.40), 2200: (0.33), 2201: (0.36), 2202: (0.08), 2203: (0.10), 2204: (0.06), 2205: (0.04), 2206: (0.04), 2207: (0.04), 2208: (0.07), 2209: (0.09), 2210: (0.14), 2211: (0.15), 2212: (0.06), 2213: (0.11), 2214: (0.10), 2215: (0.14), 2216: (0.11), 2217: (0.15), 2218: (0.07), 2219: (0.18), 2220: (0.19), 2221: (0.13), 2222: (0.21), 2223: (0.08), 2224: (0.08), 2225: (0.05), 2226: (0.04), 2227: (0.05), 2228: (0.03), 2229: (0.03), 2230: (0.05), 2231: (0.05), 2232: (0.04), 2233: (0.02), 2234: (0.01), 2235: (0.06), 2236: (0.06), 2237: (0.07), 2238: (0.10), 2239: (0.13), 2240: (0.19), 2241: (0.16), 2242: (0.15), 2243: (0.10), 2244: (0.04), 2245: (0.05), 2246: (0.05), 2247: (0.03), 2248: (0.04), 2249: (0.07), 2250: (0.05), 2251: (0.07), 2252: (0.08), 2253: (0.11), 2254: (0.05), 2255: (0.08), 2256: (0.12), 2257: (0.11), 2258: (0.08), 2259: (0.10), 2260: (0.08), 2261: (0.15), 2262: (0.14), 2263: (0.10), 2264: (0.07), 2265: (0.06), 2266: (0.05), 2267: (0.06), 2268: (0.04), 2269: (0.03), 2270: (0.02), 2271: (0.06), 2272: (0.11), 2273: (0.04), 2274: (0.01), 2275: (0.01), 2276: (0.01), 2277: (0.04), 2278: (0.03), 2279: (0.04), 2280: (0.03), 2281: (0.04), 2282: (0.02), 2283: (0.01), 2284: (0.01), 2285: (0.01), 2286: (0.01), 2287: (0.03), 2288: (0.04), 2289: (0.02), 2290: (0.03), 2291: (0.04), 2292: (0.02), 2293: (0.02), 2294: (0.03), 2295: (0.03), 2296: (0.01), 2297: (0.04), 2298: (0.06), 2299: (0.04), 2300: (0.04), 2301: (0.05), 2302: (0.04), 2303: (0.05), 2304: (0.03), 2305: (0.03), 2306: (0.03), 2307: (0.01), 2308: (0.04), 2309: (0.07), 2310: (0.06), 2311: (0.07), 2312: (0.08), 2313: (0.08), 2314: (0.10), 2315: (0.06), 2316: (0.07), 2317: (0.02), 2318: (0.01), 2319: (0.04), 2320: (0.05), 2321: (0.06), 2322: (0.08), 2323: (0.06), 2324: (0.06), 2325: (0.04), 2326: (0.03), 2327: (0.02), 2328: (0.01), 2329: (0.02), 2330: (0.01), 2331: (0.02), 2332: (0.02), 2333: (0.02), 2334: (0.04), 2335: (0.03), 2336: (0.05), 2337: (0.07), 2338: (0.11), 2339: (0.09), 2340: (0.03), 2341: (0.04), 2342: (0.05), 2343: (0.06), 2344: (0.05), 2345: (0.05), 2346: (0.05), 2347: (0.05), 2348: (0.05), 2349: (0.02), 2350: (0.02), 2351: (0.06), 2352: (0.06), 2353: (0.06), 2354: (0.06), 2355: (0.06), 2356: (0.06), 2357: (0.06), 2358: (0.05), 2359: (0.02), 2360: (0.03), 2361: (0.05), 2362: (0.06), 2363: (0.05), 2364: (0.08), 2365: (0.15), 2366: (0.09), 2367: (0.08), 2368: (0.08), 2369: (0.05), 2370: (0.06), 2371: (0.08), 2372: (0.13), 2373: (0.09), 2374: (0.10), 2375: (0.11), 2376: (0.12), 2377: (0.15), 2378: (0.17), 2379: (0.16), 2380: (0.22), 2381: (0.17), 2382: (0.13), 2383: (0.16), 2384: (0.15), 2385: (0.16), 2386: (0.12), 2387: (0.18), 2388: (0.23), 2389: (0.24), 2390: (0.21), 2391: (0.11), 2392: (0.05), 2393: (0.04), 2394: (0.04), 2395: (0.05), 2396: (0.05), 2397: (0.04), 2398: (0.11), 2399: (0.14), 2400: (0.09), 2401: (0.14), 2402: (0.07), 2403: (0.04), 2404: (0.07), 2405: (0.07), 2406: (0.09), 2407: (0.11), 2408: (0.15), 2409: (0.22), 2410: (0.15), 2411: (0.13), 2412: (0.18), 2413: (0.08), 2414: (0.08), 2415: (0.06), 2416: (0.08), 2417: (0.10), 2418: (0.11), 2419: (0.13), 2420: (0.18), 2421: (0.17), 2422: (0.12), 2423: (0.09), 2424: (0.18), 2425: (0.25), 2426: (0.24), 2427: (0.29), 2428: (0.28), 2429: (0.24), 2430: (0.16), 2431: (0.21), 2432: (0.21), 2433: (0.16), 2434: (0.08), 2435: (0.06), 2436: (0.12), 2437: (0.09), 2438: (0.06), 2439: (0.07), 2440: (0.08), 2441: (0.08), 2442: (0.13), 2443: (0.11), 2444: (0.08), 2445: (0.03), 2446: (0.07), 2447: (0.12), 2448: (0.15), 2449: (0.11), 2450: (0.07), 2451: (0.06), 2452: (0.07), 2453: (0.10), 2454: (0.05), 2455: (0.04), 2456: (0.05), 2457: (0.03), 2458: (0.05), 2459: (0.06), 2460: (0.06), 2461: (0.11), 2462: (0.10), 2463: (0.13), 2464: (0.13), 2465: (0.20), 2466: (0.12), 2467: (0.13), 2468: (0.14), 2469: (0.13), 2470: (0.12), 2471: (0.16), 2472: (0.18), 2473: (0.21), 2474: (0.13), 2475: (0.09), 2476: (0.04), 2477: (0.07), 2478: (0.06), 2479: (0.07), 2480: (0.14), 2481: (0.08), 2482: (0.15), 2483: (0.11), 2484: (0.08), 2485: (0.09), 2486: (0.19), 2487: (0.09), 2488: (0.15), 2489: (0.15), 2490: (0.12), 2491: (0.12), 2492: (0.21), 2493: (0.27), 2494: (0.13), 2495: (0.11), 2496: (0.04), 2497: (0.03), 2498: (0.07), 2499: (0.05), 2500: (0.05), 2501: (0.08), 2502: (0.06), 2503: (0.09), 2504: (0.09), 2505: (0.12), 2506: (0.10), 2507: (0.08), 2508: (0.08), 2509: (0.10), 2510: (0.11), 2511: (0.14), 2512: (0.16), 2513: (0.15), 2514: (0.16), 2515: (0.12), 2516: (0.12), 2517: (0.11), 2518: (0.08), 2519: (0.05), 2520: (0.13), 2521: (0.15), 2522: (0.12), 2523: (0.24), 2524: (0.27), 2525: (0.17), 2526: (0.12), 2527: (0.12), 2528: (0.12), 2529: (0.11), 2530: (0.06), 2531: (0.06), 2532: (0.08), 2533: (0.06), 2534: (0.08), 2535: (0.06), 2536: (0.07), 2537: (0.05), 2538: (0.06), 2539: (0.06), 2540: (0.11), 2541: (0.13), 2542: (0.12), 2543: (0.16), 2544: (0.11), 2545: (0.14), 2546: (0.14), 2547: (0.19), 2548: (0.15), 2549: (0.15), 2550: (0.14), 2551: (0.23), 2552: (0.23), 2553: (0.19), 2554: (0.17), 2555: (0.17), 2556: (0.17), 2557: (0.27), 2558: (0.24), 2559: (0.37), 2560: (0.20), 2561: (0.14), 2562: (0.12), 2563: (0.14), 2564: (0.20), 2565: (0.26), 2566: (0.26), 2567: (0.15), 2568: (0.12), 2569: (0.13), 2570: (0.15), 2571: (0.11), 2572: (0.09), 2573: (0.09), 2574: (0.11), 2575: (0.14), 2576: (0.14), 2577: (0.15), 2578: (0.22), 2579: (0.26), 2580: (0.23), 2581: (0.08), 2582: (0.07), 2583: (0.07), 2584: (0.09), 2585: (0.09), 2586: (0.05), 2587: (0.10), 2588: (0.15), 2589: (0.29), 2590: (0.22), 2591: (0.23), 2592: (0.11), 2593: (0.13), 2594: (0.14), 2595: (0.12), 2596: (0.10), 2597: (0.08), 2598: (0.13), 2599: (0.19), 2600: (0.19), 2601: (0.13), 2602: (0.07), 2603: (0.09), 2604: (0.17), 2605: (0.09), 2606: (0.08), 2607: (0.10), 2608: (0.07), 2609: (0.12), 2610: (0.12), 2611: (0.11), 2612: (0.10), 2613: (0.05), 2614: (0.06), 2615: (0.06), 2616: (0.05), 2617: (0.06), 2618: (0.08), 2619: (0.11), 2620: (0.06), 2621: (0.06), 2622: (0.06), 2623: (0.04), 2624: (0.02), 2625: (0.04), 2626: (0.04), 2627: (0.06), 2628: (0.04), 2629: (0.05), 2630: (0.05), 2631: (0.08), 2632: (0.08), 2633: (0.09), 2634: (0.08), 2635: (0.14), 2636: (0.12), 2637: (0.18), 2638: (0.22), 2639: (0.15), 2640: (0.14), 2641: (0.15), 2642: (0.10), 2643: (0.13), 2644: (0.08), 2645: (0.05), 2646: (0.12), 2647: (0.10), 2648: (0.11), 2649: (0.11), 2650: (0.13), 2651: (0.13), 2652: (0.14), 2653: (0.12), 2654: (0.07), 2655: (0.06), 2656: (0.12), 2657: (0.09), 2658: (0.13), 2659: (0.11), 2660: (0.15), 2661: (0.13), 2662: (0.14), 2663: (0.18), 2664: (0.21), 2665: (0.18), 2666: (0.14), 2667: (0.08), 2668: (0.06), 2669: (0.07), 2670: (0.15), 2671: (0.18), 2672: (0.20), 2673: (0.17), 2674: (0.15), 2675: (0.13), 2676: (0.12), 2677: (0.08), 2678: (0.05), 2679: (0.06), 2680: (0.06), 2681: (0.05), 2682: (0.06), 2683: (0.07), 2684: (0.13), 2685: (0.12), 2686: (0.08), 2687: (0.03), 2688: (0.02), 2689: (0.05), 2690: (0.09), 2691: (0.05), 2692: (0.04), 2693: (0.07), 2694: (0.07), 2695: (0.07), 2696: (0.12), 2697: (0.11), 2698: (0.06), 2699: (0.07), 2700: (0.05), 2701: (0.06), 2702: (0.07), 2703: (0.10), 2704: (0.09), 2705: (0.08), 2706: (0.08), 2707: (0.10), 2708: (0.08), 2709: (0.11), 2710: (0.23), 2711: (0.19), 2712: (0.29), 2713: (0.36), 2714: (0.38), 2715: (0.20), 2716: (0.18), 2717: (0.34), 2718: (0.45), 2719: (0.38), 2720: (0.40), 2721: (0.49), 2722: (0.47), 2723: (0.40), 2724: (0.59), 2725: (0.62), 2726: (0.45), 2727: (0.48), 2728: (0.53), 2729: (0.57), 2730: (0.52), 2731: (0.51), 2732: (0.82), 2733: (0.75), 2734: (0.40), 2735: (0.54), 2736: (0.75), 2737: (0.69), 2738: (0.89), 2739: (0.51), 2740: (0.28), 2741: (0.48), 2742: (0.32), 2743: (0.18), 2744: (0.19), 2745: (0.27), 2746: (0.28), 2747: (0.30), 2748: (0.24), 2749: (0.21), 2750: (0.17), 2751: (0.23), 2752: (0.30), 2753: (0.36), 2754: (0.46), 2755: (0.33), 2756: (0.48), 2757: (0.56), 2758: (0.68), 2759: (0.43), 2760: (0.30), 2761: (0.24), 2762: (0.31), 2763: (0.28), 2764: (0.25), 2765: (0.36), 2766: (0.43), 2767: (0.43), 2768: (0.39), 2769: (0.46), 2770: (0.52), 2771: (0.36), 2772: (0.27), 2773: (0.35), 2774: (0.37), 2775: (0.40), 2776: (0.32), 2777: (0.38), 2778: (0.32), 2779: (0.41), 2780: (0.49), 2781: (0.50), 2782: (0.20), 2783: (0.24), 2784: (0.24), 2785: (0.34), 2786: (0.26), 2787: (0.31), 2788: (0.27), 2789: (0.40), 2790: (0.50), 2791: (0.27), 2792: (0.29), 2793: (0.14), 2794: (0.17), 2795: (0.15), 2796: (0.18), 2797: (0.15), 2798: (0.22), 2799: (0.26), 2800: (0.33), 2801: (0.37), 2802: (0.32), 2803: (0.26), 2804: (0.18), 2805: (0.17), 2806: (0.23), 2807: (0.19), 2808: (0.25), 2809: (0.14), 2810: (0.18), 2811: (0.24), 2812: (0.30), 2813: (0.24), 2814: (0.18), 2815: (0.17), 2816: (0.17), 2817: (0.19), 2818: (0.21), 2819: (0.17), 2820: (0.17), 2821: (0.26), 2822: (0.20), 2823: (0.23), 2824: (0.22), 2825: (0.19), 2826: (0.14), 2827: (0.19), 2828: (0.17), 2829: (0.15), 2830: (0.21), 2831: (0.18), 2832: (0.14), 2833: (0.14), 2834: (0.12), 2835: (0.06), 2836: (0.08), 2837: (0.08), 2838: (0.12), 2839: (0.10), 2840: (0.10), 2841: (0.12), 2842: (0.23), 2843: (0.18), 2844: (0.21), 2845: (0.20), 2846: (0.11), 2847: (0.08), 2848: (0.12), 2849: (0.17), 2850: (0.11), 2851: (0.16), 2852: (0.32), 2853: (0.24), 2854: (0.29), 2855: (0.32), 2856: (0.28), 2857: (0.21), 2858: (0.18), 2859: (0.18), 2860: (0.15), 2861: (0.16), 2862: (0.26), 2863: (0.25), 2864: (0.26), 2865: (0.21), 2866: (0.15), 2867: (0.18), 2868: (0.13), 2869: (0.16), 2870: (0.10), 2871: (0.13), 2872: (0.14), 2873: (0.20), 2874: (0.31), 2875: (0.32), 2876: (0.18), 2877: (0.19), 2878: (0.11), 2879: (0.10), 2880: (0.18), 2881: (0.20), 2882: (0.24), 2883: (0.28), 2884: (0.30), 2885: (0.37), 2886: (0.38), 2887: (0.44), 2888: (0.42), 2889: (0.57), 2890: (0.50), 2891: (0.51), 2892: (0.42), 2893: (0.37), 2894: (0.39), 2895: (0.47), 2896: (0.47), 2897: (0.31), 2898: (0.15), 2899: (0.17), 2900: (0.26), 2901: (0.32), 2902: (0.21), 2903: (0.22), 2904: (0.26), 2905: (0.18), 2906: (0.23), 2907: (0.63), 2908: (0.42), 2909: (0.13), 2910: (0.26), 2911: (0.37), 2912: (0.36), 2913: (0.17), 2914: (0.15), 2915: (0.15), 2916: (0.19), 2917: (0.22), 2918: (0.20), 2919: (0.12), 2920: (0.22), 2921: (0.30), 2922: (0.53), 2923: (0.47), 2924: (0.50), 2925: (0.57), 2926: (0.56), 2927: (0.48), 2928: (0.54), 2929: (0.76), 2930: (0.60), 2931: (0.34), 2932: (0.37), 2933: (0.46), 2934: (0.55), 2935: (0.44), 2936: (0.42), 2937: (0.55), 2938: (0.49), 2939: (0.47), 2940: (0.45), 2941: (0.38), 2942: (0.21), 2943: (0.20), 2944: (0.26), 2945: (0.42), 2946: (0.33), 2947: (0.29), 2948: (0.52), 2949: (0.78), 2950: (0.71), 2951: (0.76), 2952: (0.43), 2953: (0.56), 2954: (0.48), 2955: (0.47), 2956: (0.29), 2957: (0.28), 2958: (0.33), 2959: (0.28), 2960: (0.37), 2961: (0.41), 2962: (0.38), 2963: (0.18), 2964: (0.24), 2965: (0.23), 2966: (0.25), 2967: (0.28), 2968: (0.33), 2969: (0.72), 2970: (0.66), 2971: (0.37), 2972: (0.60), 2973: (0.58), 2974: (0.39), 2975: (0.31), 2976: (0.25), 2977: (0.30), 2978: (0.24), 2979: (0.20), 2980: (0.34), 2981: (0.47), 2982: (0.35), 2983: (0.23), 2984: (0.19), 2985: (0.18), 2986: (0.20), 2987: (0.20), 2988: (0.20), 2989: (0.21), 2990: (0.22), 2991: (0.26), 2992: (0.25), 2993: (0.23), 2994: (0.21), 2995: (0.23), 2996: (0.23), 2997: (0.30), 2998: (0.17), 2999: (0.26), 3000: (0.28), 3001: (0.28), 3002: (0.29), 3003: (0.21), 3004: (0.15), 3005: (0.22), 3006: (0.27), 3007: (0.29), 3008: (0.31), 3009: (0.34), 3010: (0.36), 3011: (0.34), 3012: (0.42), 3013: (0.37), 3014: (0.37), 3015: (0.33), 3016: (0.37), 3017: (0.27), 3018: (0.32), 3019: (0.36), 3020: (0.27), 3021: (0.29), 3022: (0.29), 3023: (0.34), 3024: (0.21), 3025: (0.09), 3026: (0.16), 3027: (0.09), 3028: (0.08), 3029: (0.12), 3030: (0.13), 3031: (0.12), 3032: (0.14), 3033: (0.15), 3034: (0.13), 3035: (0.12), 3036: (0.17), 3037: (0.17), 3038: (0.13), 3039: (0.07), 3040: (0.08), 3041: (0.10), 3042: (0.12), 3043: (0.14), 3044: (0.13), 3045: (0.14), 3046: (0.09), 3047: (0.18), 3048: (0.20), 3049: (0.27), 3050: (0.33), 3051: (0.25), 3052: (0.15), 3053: (0.14), 3054: (0.16), 3055: (0.15), 3056: (0.18), 3057: (0.21), 3058: (0.31), 3059: (0.28), 3060: (0.27), 3061: (0.38), 3062: (0.29), 3063: (0.25), 3064: (0.25), 3065: (0.23), 3066: (0.12), 3067: (0.12), 3068: (0.15), 3069: (0.10), 3070: (0.14), 3071: (0.12), 3072: (0.14), 3073: (0.15), 3074: (0.18), 3075: (0.24), 3076: (0.24), 3077: (0.09), 3078: (0.13), 3079: (0.20), 3080: (0.23), 3081: (0.23), 3082: (0.22), 3083: (0.22), 3084: (0.22), 3085: (0.30), 3086: (0.27), 3087: (0.24), 3088: (0.17), 3089: (0.29), 3090: (0.31), 3091: (0.37), 3092: (0.39), 3093: (0.26), 3094: (0.24), 3095: (0.31), 3096: (0.27), 3097: (0.28), 3098: (0.23), 3099: (0.17), 3100: (0.22), 3101: (0.32), 3102: (0.26), 3103: (0.25), 3104: (0.30), 3105: (0.30), 3106: (0.25), 3107: (0.29), 3108: (0.22), 3109: (0.17), 3110: (0.14), 3111: (0.19), 3112: (0.24), 3113: (0.26), 3114: (0.27), 3115: (0.29), 3116: (0.33), 3117: (0.49), 3118: (0.93), 3119: (0.32), 3120: (0.40), 3121: (0.22), 3122: (0.14), 3123: (0.19), 3124: (0.22), 3125: (0.23), 3126: (0.28), 3127: (0.34), 3128: (0.39), 3129: (0.22), 3130: (0.28), 3131: (0.23), 3132: (0.14), 3133: (0.17), 3134: (0.16), 3135: (0.17), 3136: (0.22), 3137: (0.29), 3138: (0.23), 3139: (0.15), 3140: (0.27), 3141: (0.30), 3142: (0.36), 3143: (0.35), 3144: (0.35), 3145: (0.31), 3146: (0.26), 3147: (0.20), 3148: (0.19), 3149: (0.29), 3150: (0.26), 3151: (0.18), 3152: (0.21), 3153: (0.21), 3154: (0.38), 3155: (0.39), 3156: (0.34), 3157: (0.44), 3158: (0.66), 3159: (0.95), 3160: (0.77), 3161: (0.61), 3162: (0.44), 3163: (0.40), 3164: (0.49), 3165: (0.29), 3166: (0.32), 3167: (0.38), 3168: (0.33), 3169: (0.27), 3170: (0.32), 3171: (0.21), 3172: (0.12), 3173: (0.15), 3174: (0.16), 3175: (0.28), 3176: (0.21), 3177: (0.39), 3178: (0.23), 3179: (0.21), 3180: (0.25), 3181: (0.16), 3182: (0.23), 3183: (0.23), 3184: (0.26), 3185: (0.29), 3186: (0.38), 3187: (0.27), 3188: (0.24), 3189: (0.21), 3190: (0.22), 3191: (0.21), 3192: (0.19), 3193: (0.16), 3194: (0.17), 3195: (0.15), 3196: (0.11), 3197: (0.14), 3198: (0.15), 3199: (0.27), 3200: (0.27), 3201: (0.26), 3202: (0.41), 3203: (0.24), 3204: (0.08), 3205: (0.14), 3206: (0.17), 3207: (0.16), 3208: (0.15), 3209: (0.15), 3210: (0.16), 3211: (0.22), 3212: (0.31), 3213: (0.23), 3214: (0.17), 3215: (0.18), 3216: (0.19), 3217: (0.17), 3218: (0.26), 3219: (0.23), 3220: (0.30), 3221: (0.19), 3222: (0.24), 3223: (0.21), 3224: (0.16), 3225: (0.20), 3226: (0.21), 3227: (0.39), 3228: (0.36), 3229: (0.32), 3230: (0.27), 3231: (0.20), 3232: (0.23), 3233: (0.20), 3234: (0.23), 3235: (0.18), 3236: (0.13), 3237: (0.15), 3238: (0.17), 3239: (0.17), 3240: (0.16), 3241: (0.16), 3242: (0.19), 3243: (0.18), 3244: (0.20), 3245: (0.15), 3246: (0.12), 3247: (0.26), 3248: (0.27), 3249: (0.30), 3250: (0.33), 3251: (0.25), 3252: (0.27), 3253: (0.30), 3254: (0.35), 3255: (0.32), 3256: (0.24), 3257: (0.19), 3258: (0.25), 3259: (0.23), 3260: (0.39), 3261: (0.29), 3262: (0.23), 3263: (0.26), 3264: (0.17), 3265: (0.27), 3266: (0.24), 3267: (0.21), 3268: (0.27), 3269: (0.29), 3270: (0.22), 3271: (0.24), 3272: (0.35), 3273: (0.25), 3274: (0.22), 3275: (0.20), 3276: (0.25), 3277: (0.18), 3278: (0.13), 3279: (0.18), 3280: (0.29), 3281: (0.27), 3282: (0.24), 3283: (0.29), 3284: (0.33), 3285: (0.24), 3286: (0.37), 3287: (0.34), 3288: (0.57), 3289: (0.44), 3290: (0.61), 3291: (0.40), 3292: (0.26), 3293: (0.31), 3294: (0.38), 3295: (0.30), 3296: (0.24), 3297: (0.20), 3298: (0.23), 3299: (0.26), 3300: (0.22), 3301: (0.25), 3302: (0.21), 3303: (0.22), 3304: (0.27), 3305: (0.32), 3306: (0.26), 3307: (0.33), 3308: (0.25), 3309: (0.23), 3310: (0.27), 3311: (0.23), 3312: (0.19), 3313: (0.17), 3314: (0.24), 3315: (0.29), 3316: (0.27), 3317: (0.26), 3318: (0.33), 3319: (0.25), 3320: (0.39), 3321: (0.34), 3322: (0.35), 3323: (0.28), 3324: (0.32), 3325: (0.25), 3326: (0.20), 3327: (0.19), 3328: (0.19), 3329: (0.19), 3330: (0.17), 3331: (0.19), 3332: (0.16), 3333: (0.17), 3334: (0.25), 3335: (0.20), 3336: (0.21), 3337: (0.20), 3338: (0.20), 3339: (0.19), 3340: (0.18), 3341: (0.20), 3342: (0.16), 3343: (0.14), 3344: (0.14), 3345: (0.12), 3346: (0.09), 3347: (0.06), 3348: (0.06), 3349: (0.06), 3350: (0.05), 3351: (0.08), 3352: (0.13), 3353: (0.13), 3354: (0.10), 3355: (0.13), 3356: (0.13), 3357: (0.12), 3358: (0.18), 3359: (0.15), 3360: (0.19), 3361: (0.18), 3362: (0.13), 3363: (0.11), 3364: (0.17), 3365: (0.21), 3366: (0.17), 3367: (0.16), 3368: (0.18), 3369: (0.11), 3370: (0.09), 3371: (0.09), 3372: (0.10), 3373: (0.07), 3374: (0.09), 3375: (0.51), 3376: (0.46), 3377: (0.38), 3378: (0.27), 3379: (0.29), 3380: (0.15), 3381: (0.16), 3382: (0.10), 3383: (0.13), 3384: (0.08), 3385: (0.05), 3386: (0.06), 3387: (0.06), 3388: (0.04), 3389: (0.02), 3390: (0.01), 3391: (0.01), 3392: (0.01), 3393: (0.00), 3394: (0.01), 3395: (0.01), 3396: (0.02), 3397: (0.03), 3398: (0.02), 3399: (0.02), 3400: (0.01), 3401: (0.01), 3402: (0.03), 3403: (0.02), 3404: (0.03), 3405: (0.03), 3406: (0.05), 3407: (0.05), 3408: (0.02), 3409: (0.01), 3410: (0.03), 3411: (0.06), 3412: (0.03), 3413: (0.02), 3414: (0.03), 3415: (0.02), 3416: (0.03), 3417: (0.05), 3418: (0.05), 3419: (0.04), 3420: (0.03), 3421: (0.06), 3422: (0.04), 3423: (0.02), 3424: (0.01), 3425: (0.02), 3426: (0.01), 3427: (0.01), 3428: (0.01), 3429: (0.01), 3430: (0.01), 3431: (0.01), 3432: (0.01), 3433: (0.01), 3434: (0.01), 3435: (0.01), 3436: (0.01), 3437: (0.01), 3438: (0.02), 3439: (0.02), 3440: (0.02), 3441: (0.02), 3442: (0.02), 3443: (0.01), 3444: (0.01), 3445: (0.01), 3446: (0.01), 3447: (0.01), 3448: (0.01), 3449: (0.01), 3450: (0.01), 3451: (0.01), 3452: (0.01), 3453: (0.02), 3454: (0.02), 3455: (0.02), 3456: (0.02), 3457: (0.02), 3458: (0.01), 3459: (0.01), 3460: (0.01), 3461: (0.01), 3462: (0.01), 3463: (0.01), 3464: (0.01), 3465: (0.01), 3466: (0.01), 3467: (0.01), 3468: (0.01), 3469: (0.01), 3470: (0.01), 3471: (0.01), 3472: (0.01), 3473: (0.01), 3474: (0.01), 3475: (0.01), 3476: (0.01), 3477: (0.01), 3478: (0.01), 3479: (0.01), 3480: (0.01), 3481: (0.01), 3482: (0.01), 3483: (0.01), 3484: (0.02), 3485: (0.02), 3486: (0.02), 3487: (0.01), 3488: (0.01), 3489: (0.01), 3490: (0.01), 3491: (0.01), 3492: (0.02), 3493: (0.01), 3494: (0.01), 3495: (0.01), 3496: (0.01), 3497: (0.01), 3498: (0.04), 3499: (0.03), 3500: (0.01), 3501: (0.01), 3502: (0.01), 3503: (0.01), 3504: (0.02), 3505: (0.04), 3506: (0.03), 3507: (0.01), 3508: (0.01), 3509: (0.01), 3510: (0.02), 3511: (0.01), 3512: (0.01), 3513: (0.01), 3514: (0.01), 3515: (0.01), 3516: (0.02), 3517: (0.01), 3518: (0.01), 3519: (0.01), 3520: (0.02), 3521: (0.01), 3522: (0.02), 3523: (0.02), 3524: (0.02), 3525: (0.02), 3526: (0.02), 3527: (0.01), 3528: (0.01), 3529: (0.01), 3530: (0.01), 3531: (0.01), 3532: (0.01), 3533: (0.01), 3534: (0.01), 3535: (0.01), 3536: (0.02), 3537: (0.02), 3538: (0.02), 3539: (0.02), 3540: (0.02), 3541: (0.01), 3542: (0.01), 3543: (0.02), 3544: (0.01), 3545: (0.01), 3546: (0.01), 3547: (0.01), 3548: (0.01), 3549: (0.01), 3550: (0.01), 3551: (0.02), 3552: (0.01), 3553: (0.01), 3554: (0.01), 3555: (0.01), 3556: (0.02), 3557: (0.02), 3558: (0.02), 3559: (0.02), 3560: (0.02), 3561: (0.02), 3562: (0.02), 3563: (0.03), 3564: (0.04), 3565: (0.04), 3566: (0.04), 3567: (0.04), 3568: (0.03), 3569: (0.04), 3570: (0.03), 3571: (0.04), 3572: (0.04), 3573: (0.04), 3574: (0.05), 3575: (0.05), 3576: (0.05), 3577: (0.06), 3578: (0.06), 3579: (0.04), 3580: (0.02), 3581: (0.03), 3582: (0.03), 3583: (0.09), 3584: (0.05), 3585: (0.02), 3586: (0.03), 3587: (0.05), 3588: (0.07), 3589: (0.04), 3590: (0.04), 3591: (0.04), 3592: (0.07), 3593: (0.04), 3594: (0.04), 3595: (0.05), 3596: (0.05), 3597: (0.06), 3598: (0.06), 3599: (0.05), 3600: (0.05), 3601: (0.07), 3602: (0.06), 3603: (0.04), 3604: (0.05), 3605: (0.03), 3606: (0.03), 3607: (0.03), 3608: (0.02), 3609: (0.02), 3610: (0.01), 3611: (0.02), 3612: (0.02), 3613: (0.02), 3614: (0.01), 3615: (0.01), 3616: (0.02), 3617: (0.01), 3618: (0.01), 3619: (0.01), 3620: (0.01), 3621: (0.02), 3622: (0.02), 3623: (0.01), 3624: (0.02), 3625: (0.02), 3626: (0.02), 3627: (0.02), 3628: (0.02), 3629: (0.01), 3630: (0.02), 3631: (0.01), 3632: (0.01), 3633: (0.01), 3634: (0.01), 3635: (0.02), 3636: (0.02), 3637: (0.03), 3638: (0.03), 3639: (0.03), 3640: (0.02), 3641: (0.02), 3642: (0.02), 3643: (0.02), 3644: (0.02), 3645: (0.02), 3646: (0.03), 3647: (0.04), 3648: (0.03), 3649: (0.06), 3650: (0.08), 3651: (0.09), 3652: (0.05), 3653: (0.06), 3654: (0.04), 3655: (0.03), 3656: (0.04), 3657: (0.06), 3658: (0.07), 3659: (0.09), 3660: (0.06), 3661: (0.09), 3662: (0.09), 3663: (0.10), 3664: (0.07), 3665: (0.07), 3666: (0.07), 3667: (0.05), 3668: (0.05), 3669: (0.08), 3670: (0.06), 3671: (0.06), 3672: (0.09), 3673: (0.08), 3674: (0.09), 3675: (0.09), 3676: (0.11), 3677: (0.08), 3678: (0.06), 3679: (0.03), 3680: (0.03), 3681: (0.03), 3682: (0.05), 3683: (0.06), 3684: (0.05), 3685: (0.05), 3686: (0.03), 3687: (0.03), 3688: (0.03), 3689: (0.02), 3690: (0.01), 3691: (0.01), 3692: (0.01), 3693: (0.01), 3694: (0.01), 3695: (0.01), 3696: (0.02), 3697: (0.01), 3698: (0.02), 3699: (0.05), 3700: (0.05), 3701: (0.02), 3702: (0.01), 3703: (0.01), 3704: (0.02), 3705: (0.02), 3706: (0.02), 3707: (0.01), 3708: (0.01), 3709: (0.02), 3710: (0.13), 3711: (0.18), 3712: (0.14), 3713: (0.10), 3714: (0.10), 3715: (0.11), 3716: (0.17), 3717: (0.16), 3718: (0.07), 3719: (0.09), 3720: (0.08), 3721: (0.11), 3722: (0.18), 3723: (0.21), 3724: (0.23), 3725: (0.37), 3726: (0.50), 3727: (0.47), 3728: (0.36), 3729: (0.28), 3730: (0.40), 3731: (0.33), 3732: (0.22), 3733: (0.29), 3734: (0.36), 3735: (0.28), 3736: (0.35), 3737: (0.64), 3738: (0.70), 3739: (0.49), 3740: (0.60), 3741: (0.43), 3742: (0.30), 3743: (0.38), 3744: (0.30), 3745: (0.35), 3746: (0.42), 3747: (0.45), 3748: (0.45), 3749: (0.36), 3750: (0.42), 3751: (0.35), 3752: (0.12), 3753: (0.11), 3754: (0.12), 3755: (0.11), 3756: (0.21), 3757: (0.20), 3758: (0.27), 3759: (0.24), 3760: (0.31), 3761: (0.25), 3762: (0.23), 3763: (0.18), 3764: (0.27), 3765: (0.28), 3766: (0.51), 3767: (0.50), 3768: (0.28), 3769: (0.25), 3770: (0.44), 3771: (0.37), 3772: (0.28), 3773: (0.27), 3774: (0.26), 3775: (0.25), 3776: (0.28), 3777: (0.23), 3778: (0.25), 3779: (0.31), 3780: (0.34), 3781: (0.31), 3782: (0.30), 3783: (0.23), 3784: (0.14), 3785: (0.12), 3786: (0.19), 3787: (0.20), 3788: (0.17), 3789: (0.15), 3790: (0.16), 3791: (0.20), 3792: (0.25), 3793: (0.35), 3794: (0.17), 3795: (0.17), 3796: (0.35), 3797: (0.32), 3798: (0.38), 3799: (0.33), 3800: (0.33), 3801: (0.32), 3802: (0.40), 3803: (0.35), 3804: (0.22), 3805: (0.25), 3806: (0.19), 3807: (0.15), 3808: (0.18), 3809: (0.21), 3810: (0.24), 3811: (0.27), 3812: (0.25), 3813: (0.31), 3814: (0.30), 3815: (0.24), 3816: (0.21), 3817: (0.16), 3818: (0.25), 3819: (0.18), 3820: (0.19), 3821: (0.28), 3822: (0.19), 3823: (0.19), 3824: (0.25), 3825: (0.25), 3826: (0.18), 3827: (0.22), 3828: (0.16), 3829: (0.21), 3830: (0.21), 3831: (0.16), 3832: (0.15), 3833: (0.21), 3834: (0.23), 3835: (0.25), 3836: (0.26), 3837: (0.22), 3838: (0.21), 3839: (0.24), 3840: (0.18), 3841: (0.15), 3842: (0.17), 3843: (0.21), 3844: (0.26), 3845: (0.23), 3846: (0.18), 3847: (0.08), 3848: (0.11), 3849: (0.13), 3850: (0.13), 3851: (0.14), 3852: (0.19), 3853: (0.17), 3854: (0.27), 3855: (0.29), 3856: (0.19), 3857: (0.24), 3858: (0.14), 3859: (0.11), 3860: (0.14), 3861: (0.14), 3862: (0.12), 3863: (0.11), 3864: (0.25), 3865: (0.36), 3866: (0.30), 3867: (0.29), 3868: (0.29), 3869: (0.10), 3870: (0.13), 3871: (0.17), 3872: (0.16), 3873: (0.16), 3874: (0.21), 3875: (0.25), 3876: (0.23), 3877: (0.21), 3878: (0.14), 3879: (0.09), 3880: (0.12), 3881: (0.11), 3882: (0.12), 3883: (0.13), 3884: (0.18), 3885: (0.18), 3886: (0.24), 3887: (0.33), 3888: (0.24), 3889: (0.17), 3890: (0.11), 3891: (0.13), 3892: (0.17), 3893: (0.22), 3894: (0.20), 3895: (0.29), 3896: (0.22), 3897: (0.26), 3898: (0.26), 3899: (0.29), 3900: (0.33), 3901: (0.43), 3902: (0.62), 3903: (0.52), 3904: (0.44), 3905: (0.43), 3906: (0.41), 3907: (0.39), 3908: (0.46), 3909: (0.37), 3910: (0.36), 3911: (0.30), 3912: (0.30), 3913: (0.47), 3914: (0.44), 3915: (0.37), 3916: (0.44), 3917: (0.52), 3918: (0.44), 3919: (0.35), 3920: (0.27), 3921: (0.13), 3922: (0.16), 3923: (0.29), 3924: (0.42), 3925: (0.37), 3926: (0.21), 3927: (0.21), 3928: (0.17), 3929: (0.26), 3930: (0.25), 3931: (0.18), 3932: (0.18), 3933: (0.27), 3934: (0.23), 3935: (0.24), 3936: (0.31), 3937: (0.25), 3938: (0.27), 3939: (0.34), 3940: (0.31), 3941: (0.29), 3942: (0.35), 3943: (0.30), 3944: (0.32), 3945: (0.35), 3946: (0.43), 3947: (0.29), 3948: (0.27), 3949: (0.27), 3950: (0.29), 3951: (0.29), 3952: (0.22), 3953: (0.13), 3954: (0.16), 3955: (0.21), 3956: (0.28), 3957: (0.29), 3958: (0.22), 3959: (0.17), 3960: (0.25), 3961: (0.28), 3962: (0.40), 3963: (0.37), 3964: (0.32), 3965: (0.31), 3966: (0.29), 3967: (0.26), 3968: (0.26), 3969: (0.23), 3970: (0.27), 3971: (0.26), 3972: (0.24), 3973: (0.25), 3974: (0.35), 3975: (0.20), 3976: (0.18), 3977: (0.24), 3978: (0.31), 3979: (0.26), 3980: (0.21), 3981: (0.27), 3982: (0.30), 3983: (0.34), 3984: (0.30), 3985: (0.31), 3986: (0.35), 3987: (0.35), 3988: (0.31), 3989: (0.20), 3990: (0.29), 3991: (0.24), 3992: (0.20), 3993: (0.25), 3994: (0.25), 3995: (0.16), 3996: (0.19), 3997: (0.23), 3998: (0.25), 3999: (0.27), 4000: (0.30), 4001: (0.41), 4002: (0.50), 4003: (0.36), 4004: (0.44), 4005: (0.50), 4006: (0.33), 4007: (0.42), 4008: (0.30), 4009: (0.30), 4010: (0.29), 4011: (0.29), 4012: (0.24), 4013: (0.26), 4014: (0.38), 4015: (0.39), 4016: (0.28), 4017: (0.32), 4018: (0.46), 4019: (0.47), 4020: (0.38), 4021: (0.51), 4022: (0.46), 4023: (0.42), 4024: (0.44), 4025: (0.63), 4026: (0.54), 4027: (0.52), 4028: (0.41), 4029: (0.46), 4030: (0.50), 4031: (0.55), 4032: (0.53), 4033: (0.51), 4034: (0.40), 4035: (0.26), 4036: (0.34), 4037: (0.25), 4038: (0.20), 4039: (0.21), 4040: (0.18), 4041: (0.23), 4042: (0.29), 4043: (0.27), 4044: (0.28), 4045: (0.24), 4046: (0.29), 4047: (0.30), 4048: (0.23), 4049: (0.24), 4050: (0.20), 4051: (0.15), 4052: (0.16), 4053: (0.16), 4054: (0.15), 4055: (0.18), 4056: (0.16), 4057: (0.22), 4058: (0.17), 4059: (0.18), 4060: (0.27), 4061: (0.24), 4062: (0.26), 4063: (0.33), 4064: (0.30), 4065: (0.32), 4066: (0.39), 4067: (0.25), 4068: (0.22), 4069: (0.28), 4070: (0.38), 4071: (0.43), 4072: (0.50), 4073: (0.36), 4074: (0.38), 4075: (0.39), 4076: (0.37), 4077: (0.37), 4078: (0.28), 4079: (0.16), 4080: (0.20), 4081: (0.25), 4082: (0.21), 4083: (0.26), 4084: (0.26), 4085: (0.33), 4086: (0.24), 4087: (0.29), 4088: (0.38), 4089: (0.24), 4090: (0.16), 4091: (0.36), 4092: (0.36), 4093: (0.44), 4094: (0.35), 4095: (0.35), 4096: (0.24), 4097: (0.33), 4098: (0.30), 4099: (0.28), 4100: (0.20), 4101: (0.28), 4102: (0.31), 4103: (0.43), 4104: (0.58), 4105: (0.41), 4106: (0.29), 4107: (0.36), 4108: (0.35), 4109: (0.39), 4110: (0.40), 4111: (0.39), 4112: (0.28), 4113: (0.35), 4114: (0.41), 4115: (0.44), 4116: (0.30), 4117: (0.34), 4118: (0.36), 4119: (0.29), 4120: (0.42), 4121: (0.24), 4122: (0.18), 4123: (0.21), 4124: (0.32), 4125: (0.35), 4126: (0.33), 4127: (0.33), 4128: (0.34), 4129: (0.41), 4130: (0.36), 4131: (0.42), 4132: (0.29), 4133: (0.35), 4134: (0.21), 4135: (0.23), 4136: (0.23), 4137: (0.20), 4138: (0.16), 4139: (0.18), 4140: (0.24), 4141: (0.21), 4142: (0.24), 4143: (0.19), 4144: (0.20), 4145: (0.22), 4146: (0.25), 4147: (0.17), 4148: (0.22), 4149: (0.24), 4150: (0.26), 4151: (0.25), 4152: (0.24), 4153: (0.21), 4154: (0.27), 4155: (0.33), 4156: (0.29), 4157: (0.26), 4158: (0.21), 4159: (0.25), 4160: (0.25), 4161: (0.21), 4162: (0.27), 4163: (0.21), 4164: (0.18), 4165: (0.20), 4166: (0.27), 4167: (0.33), 4168: (0.36), 4169: (0.24), 4170: (0.27), 4171: (0.31), 4172: (0.37), 4173: (0.40), 4174: (0.32), 4175: (0.30), 4176: (0.32), 4177: (0.45), 4178: (0.38), 4179: (0.45), 4180: (0.31), 4181: (0.36), 4182: (0.27), 4183: (0.22), 4184: (0.19), 4185: (0.12), 4186: (0.20), 4187: (0.23), 4188: (0.22), 4189: (0.25), 4190: (0.22), 4191: (0.18), 4192: (0.32), 4193: (0.25), 4194: (0.21), 4195: (0.26), 4196: (0.23), 4197: (0.33), 4198: (0.31), 4199: (0.31), 4200: (0.23), 4201: (0.23), 4202: (0.23), 4203: (0.22), 4204: (0.21), 4205: (0.15), 4206: (0.14), 4207: (0.18), 4208: (0.24), 4209: (0.26), 4210: (0.26), 4211: (0.25), 4212: (0.27), 4213: (0.23), 4214: (0.30), 4215: (0.31), 4216: (0.19), 4217: (0.15), 4218: (0.17), 4219: (0.18), 4220: (0.17), 4221: (0.25), 4222: (0.21), 4223: (0.22), 4224: (0.24), 4225: (0.29), 4226: (0.21), 4227: (0.19), 4228: (0.28), 4229: (0.19), 4230: (0.27), 4231: (0.25), 4232: (0.27), 4233: (0.36), 4234: (0.29), 4235: (0.29), 4236: (0.25), 4237: (0.36), 4238: (0.31), 4239: (0.40), 4240: (0.52), 4241: (0.49), 4242: (0.63), 4243: (0.42), 4244: (0.35), 4245: (0.33), 4246: (0.31), 4247: (0.31), 4248: (0.23), 4249: (0.35), 4250: (0.39), 4251: (0.35), 4252: (0.38), 4253: (0.28), 4254: (0.35), 4255: (0.40), 4256: (0.45), 4257: (0.44), 4258: (0.25), 4259: (0.26), 4260: (0.41), 4261: (0.36), 4262: (0.47), 4263: (0.37), 4264: (0.33), 4265: (0.34), 4266: (0.51), 4267: (0.50), 4268: (0.53), 4269: (0.30), 4270: (0.30), 4271: (0.31), 4272: (0.33), 4273: (0.45), 4274: (0.33), 4275: (0.31), 4276: (0.28), 4277: (0.30), 4278: (0.27), 4279: (0.28), 4280: (0.30), 4281: (0.35), 4282: (0.39), 4283: (0.40), 4284: (0.43), 4285: (0.40), 4286: (0.39), 4287: (0.38), 4288: (0.37), 4289: (0.47), 4290: (0.37), 4291: (0.31), 4292: (0.42), 4293: (0.46), 4294: (0.49), 4295: (0.49), 4296: (0.50), 4297: (0.36), 4298: (0.50), 4299: (0.59), 4300: (0.71), 4301: (0.68), 4302: (0.69), 4303: (0.65), 4304: (0.61), 4305: (0.48), 4306: (0.44), 4307: (0.38), 4308: (0.52), 4309: (0.49), 4310: (0.50), 4311: (0.42), 4312: (0.40), 4313: (0.42), 4314: (0.49), 4315: (0.48), 4316: (0.45), 4317: (0.39), 4318: (0.25), 4319: (0.35), 4320: (0.44), 4321: (0.33), 4322: (0.32), 4323: (0.43), 4324: (0.41), 4325: (0.44), 4326: (0.49), 4327: (0.46), 4328: (0.35), 4329: (0.34), 4330: (0.28), 4331: (0.33), 4332: (0.37), 4333: (0.45), 4334: (0.41), 4335: (0.42), 4336: (0.47), 4337: (0.31), 4338: (0.21), 4339: (0.17), 4340: (0.15), 4341: (0.18), 4342: (0.14), 4343: (0.11), 4344: (0.17), 4345: (0.19), 4346: (0.15), 4347: (0.18), 4348: (0.17), 4349: (0.16), 4350: (0.21), 4351: (0.16), 4352: (0.20), 4353: (0.12), 4354: (0.11), 4355: (0.12), 4356: (0.13), 4357: (0.10), 4358: (0.09), 4359: (0.05), 4360: (0.04), 4361: (0.04), 4362: (0.08), 4363: (0.08), 4364: (0.08), 4365: (0.10), 4366: (0.09), 4367: (0.09), 4368: (0.10), 4369: (0.07), 4370: (0.07), 4371: (0.05), 4372: (0.07), 4373: (0.11), 4374: (0.05), 4375: (0.03), 4376: (0.06), 4377: (0.16), 4378: (0.09), 4379: (0.10), 4380: (0.04), 4381: (0.02), 4382: (0.01), 4383: (0.01), 4384: (0.02), 4385: (0.03), 4386: (0.03), 4387: (0.31), 4388: (0.85), 4389: (0.52), 4390: (0.27), 4391: (0.22), 4392: (0.16), 4393: (0.11), 4394: (0.10), 4395: (0.12), 4396: (0.14), 4397: (0.09), 4398: (0.09), 4399: (0.08), 4400: (0.09), 4401: (0.04), 4402: (0.02), 4403: (0.02), 4404: (0.01), 4405: (0.01), 4406: (0.01), 4407: (0.01), 4408: (0.02), 4409: (0.03), 4410: (0.02), 4411: (0.01), 4412: (0.01), 4413: (0.01), 4414: (0.01), 4415: (0.00), 4416: (0.00), 4417: (0.00), 4418: (0.00), 4419: (0.00), 4420: (0.00), 4421: (0.00), 4422: (0.00), 4423: (0.00), 4424: (0.00), 4425: (0.00), 4426: (0.00), 4427: (0.00), 4428: (0.00), 4429: (0.00), 4430: (0.00), 4431: (0.00), 4432: (0.00), 4433: (0.00), 4434: (0.00), 4435: (0.00), 4436: (0.00), 4437: (0.00), 4438: (0.00), 4439: (0.00), 4440: (0.00), 4441: (0.00), 4442: (0.00), 4443: (0.00), 4444: (0.00), 4445: (0.00), 4446: (0.00), 4447: (0.00), 4448: (0.00), 4449: (0.00), 4450: (0.00), 4451: (0.00), 4452: (0.00), 4453: (0.00), 4454: (0.00), 4455: (0.00), 4456: (0.00), 4457: (0.00), 4458: (0.00), 4459: (0.00), 4460: (0.00), 4461: (0.00), 4462: (0.00), 4463: (0.00)\"#@param {type:\"string\"}\n",
        "\n",
        "\n",
        "cam_code = \"\"#@param {type:\"string\"}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown #### Depth Warping\n",
        "use_depth_warping = False #@param {type:\"boolean\"}\n",
        "midas_depth_model = \"dpt_large\"\n",
        "midas_weight = 0.3#@param {type:\"number\"}\n",
        "near_plane = 200#@param {type:\"number\"}\n",
        "far_plane = 10000#@param {type:\"number\"}\n",
        "fov = 40#@param {type:\"number\"}\n",
        "padding_mode = 'border'#@param {type:\"string\"}\n",
        "sampling_mode = 'bicubic'#@param {type:\"string\"}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown #### Turbo\n",
        "turbo_mode = False #@param {type:\"boolean\"}\n",
        "turbo_steps = \"3\" #@param [\"2\",\"3\",\"4\",\"5\",\"6\"] {type:\"string\"}\n",
        "turbo_preroll = 10 # frames\n",
        "if turbo_mode and animation_mode != '3D':\n",
        "    print('=====')\n",
        "    print('Turbo mode only available with 3D animations. Disabling Turbo.')\n",
        "    print('=====')\n",
        "    turbo_mode = False\n",
        "\n",
        "if len(cam_code):\n",
        "    exec(cam_code)\n",
        "\n",
        "\n",
        "try:\n",
        "    angle_series = get_inbetweens(parse_key_frames(angle))\n",
        "except RuntimeError as e:\n",
        "    print(\n",
        "        \"WARNING: You have selected to use key frames, but you have not \"\n",
        "        \"formatted `angle` correctly for key frames.\\n\"\n",
        "        \"Attempting to interpret `angle` as \"\n",
        "        f'\"0: ({angle})\"\\n'\n",
        "        \"Please read the instructions to find out how to use key frames \"\n",
        "        \"correctly.\\n\"\n",
        "    )\n",
        "    angle = f\"0: ({angle})\"\n",
        "    angle_series = get_inbetweens(parse_key_frames(angle))\n",
        "\n",
        "try:\n",
        "    zoom_series = get_inbetweens(parse_key_frames(zoom))\n",
        "except RuntimeError as e:\n",
        "    print(\n",
        "        \"WARNING: You have selected to use key frames, but you have not \"\n",
        "        \"formatted `zoom` correctly for key frames.\\n\"\n",
        "        \"Attempting to interpret `zoom` as \"\n",
        "        f'\"0: ({zoom})\"\\n'\n",
        "        \"Please read the instructions to find out how to use key frames \"\n",
        "        \"correctly.\\n\"\n",
        "    )\n",
        "    zoom = f\"0: ({zoom})\"\n",
        "    zoom_series = get_inbetweens(parse_key_frames(zoom))\n",
        "\n",
        "try:\n",
        "    translation_x_series = get_inbetweens(parse_key_frames(translation_x))\n",
        "except RuntimeError as e:\n",
        "    print(\n",
        "        \"WARNING: You have selected to use key frames, but you have not \"\n",
        "        \"formatted `translation_x` correctly for key frames.\\n\"\n",
        "        \"Attempting to interpret `translation_x` as \"\n",
        "        f'\"0: ({translation_x})\"\\n'\n",
        "        \"Please read the instructions to find out how to use key frames \"\n",
        "        \"correctly.\\n\"\n",
        "    )\n",
        "    translation_x = f\"0: ({translation_x})\"\n",
        "    translation_x_series = get_inbetweens(parse_key_frames(translation_x))\n",
        "\n",
        "try:\n",
        "    translation_y_series = get_inbetweens(parse_key_frames(translation_y))\n",
        "except RuntimeError as e:\n",
        "    print(\n",
        "        \"WARNING: You have selected to use key frames, but you have not \"\n",
        "        \"formatted `translation_y` correctly for key frames.\\n\"\n",
        "        \"Attempting to interpret `translation_y` as \"\n",
        "        f'\"0: ({translation_y})\"\\n'\n",
        "        \"Please read the instructions to find out how to use key frames \"\n",
        "        \"correctly.\\n\"\n",
        "    )\n",
        "    translation_y = f\"0: ({translation_y})\"\n",
        "    translation_y_series = get_inbetweens(parse_key_frames(translation_y))\n",
        "\n",
        "try:\n",
        "    translation_z_series = get_inbetweens(parse_key_frames(translation_z))\n",
        "except RuntimeError as e:\n",
        "    print(\n",
        "        \"WARNING: You have selected to use key frames, but you have not \"\n",
        "        \"formatted `translation_z` correctly for key frames.\\n\"\n",
        "        \"Attempting to interpret `translation_z` as \"\n",
        "        f'\"0: ({translation_z})\"\\n'\n",
        "        \"Please read the instructions to find out how to use key frames \"\n",
        "        \"correctly.\\n\"\n",
        "    )\n",
        "    translation_z = f\"0: ({translation_z})\"\n",
        "    translation_z_series = get_inbetweens(parse_key_frames(translation_z))\n",
        "\n",
        "try:\n",
        "    rotation_3d_x_series = get_inbetweens(parse_key_frames(rotation_3d_x))\n",
        "except RuntimeError as e:\n",
        "    print(\n",
        "        \"WARNING: You have selected to use key frames, but you have not \"\n",
        "        \"formatted `rotation_3d_x` correctly for key frames.\\n\"\n",
        "        \"Attempting to interpret `rotation_3d_x` as \"\n",
        "        f'\"0: ({rotation_3d_x})\"\\n'\n",
        "        \"Please read the instructions to find out how to use key frames \"\n",
        "        \"correctly.\\n\"\n",
        "    )\n",
        "    rotation_3d_x = f\"0: ({rotation_3d_x})\"\n",
        "    rotation_3d_x_series = get_inbetweens(parse_key_frames(rotation_3d_x))\n",
        "\n",
        "try:\n",
        "    rotation_3d_y_series = get_inbetweens(parse_key_frames(rotation_3d_y))\n",
        "except RuntimeError as e:\n",
        "    print(\n",
        "        \"WARNING: You have selected to use key frames, but you have not \"\n",
        "        \"formatted `rotation_3d_y` correctly for key frames.\\n\"\n",
        "        \"Attempting to interpret `rotation_3d_y` as \"\n",
        "        f'\"0: ({rotation_3d_y})\"\\n'\n",
        "        \"Please read the instructions to find out how to use key frames \"\n",
        "        \"correctly.\\n\"\n",
        "    )\n",
        "    rotation_3d_y = f\"0: ({rotation_3d_y})\"\n",
        "    rotation_3d_y_series = get_inbetweens(parse_key_frames(rotation_3d_y))\n",
        "\n",
        "try:\n",
        "    rotation_3d_z_series = get_inbetweens(parse_key_frames(rotation_3d_z))\n",
        "except RuntimeError as e:\n",
        "    print(\n",
        "        \"WARNING: You have selected to use key frames, but you have not \"\n",
        "        \"formatted `rotation_3d_z` correctly for key frames.\\n\"\n",
        "        \"Attempting to interpret `rotation_3d_z` as \"\n",
        "        f'\"0: ({rotation_3d_z})\"\\n'\n",
        "        \"Please read the instructions to find out how to use key frames \"\n",
        "        \"correctly.\\n\"\n",
        "    )\n",
        "    rotation_3d_z = f\"0: ({rotation_3d_z})\"\n",
        "    rotation_3d_z_series = get_inbetweens(parse_key_frames(rotation_3d_z))    \n",
        "\n",
        "if preview_rect_frame_delta < 1:\n",
        "    preview_rect_frame_delta = 1\n",
        "\n",
        "do_it()\n",
        "\n",
        "mp4 = open('anim_preview.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "display.display( display.HTML(f'<video controls loop><source src=\"{data_url}\" type=\"video/mp4\"></video>') )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o3SMIo1_Jx7"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# Animation Generators\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze7wd_pY_Jx8"
      },
      "source": [
        "# Random keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1hWtxF9Q_Jx9"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown Generate a random series of key frames<br>\n",
        "#@markdown Every `frame_delta` frames a random value between `min_value` and `max_value` is used.<br>\n",
        "#@markdown You can paste the resulting string into any of the camera attributes above\n",
        "max_frames = 250 #@param {type:\"integer\"}\n",
        "frame_delta = 24 #@param {type:\"integer\"}\n",
        "frame_delta_variance = 0.5 #@param {type:\"number\"}\n",
        "min_value = -.5 #@param {type:\"number\"}\n",
        "max_value = .5 #@param {type:\"number\"}\n",
        "\n",
        "import math\n",
        "import random\n",
        "\n",
        "frame = 0\n",
        "value = 0\n",
        "values = []\n",
        "key_str = \"\"\n",
        "while frame < max_frames:\n",
        "    key_str += f\"{frame}:({value:0.3f}),\"\n",
        "    frame += int(frame_delta + frame_delta_variance * (random.random()*2.0-1.0) * frame_delta)\n",
        "    value = min_value + (max_value - min_value) * random.random()\n",
        "    values.append(value)\n",
        "key_str = key_str[0:-1] # remove trailing ,\n",
        "\n",
        "values = get_inbetweens(parse_key_frames(key_str))\n",
        "\n",
        "# show plot of the value over time\n",
        "figure, axis = plt.subplots(1, 1)\n",
        "axis.set_title(\"Values\")\n",
        "axis.plot([f for f in range(len(values))], values, color='r', label='x')\n",
        "plt.show()\n",
        "\n",
        "# easy control for copy/pasting\n",
        "layout = Layout(width='75%')\n",
        "value_widget = Text(value=key_str, description='values:', layout=layout)\n",
        "widgets.VBox([value_widget])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dyA_gsQ_Jx9"
      },
      "source": [
        "# Perlin noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q1FbyIXN_Jx-"
      },
      "outputs": [],
      "source": [
        "max_frames = 250 #@param {type:\"integer\"}\n",
        "octaves = 1 #@param {type:\"integer\"}\n",
        "freq_scale = 5 #@param {type:\"number\"}\n",
        "min_value = -.5 #@param {type:\"number\"}\n",
        "max_value = .5 #@param {type:\"number\"}\n",
        "\n",
        "amplitude = max_value - min_value\n",
        "mean = (max_value + min_value) / 2\n",
        "\n",
        "noise = PerlinNoise(octaves=octaves)\n",
        "\n",
        "key_str = \"\"\n",
        "values = []\n",
        "phase = random.random()\n",
        "for frame, t in enumerate(np.linspace(0, 1, max_frames)):\n",
        "    value = mean + amplitude * noise(t*freq_scale + phase)\n",
        "    key_str += f\"{frame}:({value:0.3f}),\"\n",
        "    values.append(value)\n",
        "key_str = key_str[0:-1] # remove trailing ,\n",
        "\n",
        "# show plot of the value over time\n",
        "xs = [f for f in range(max_frames)]\n",
        "figure, axis = plt.subplots(1, 1)\n",
        "axis.set_title(\"Values\")\n",
        "axis.plot(xs, values, color='r', label='x')\n",
        "plt.show()\n",
        "\n",
        "# easy control for copy/pasting\n",
        "layout = Layout(width='75%')\n",
        "value_widget = Text(value=key_str, description='values:', layout=layout)\n",
        "widgets.VBox([value_widget])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6vJsJ0U_Jx_"
      },
      "source": [
        "# [Wiggle 5.1](https://colab.research.google.com/github/zippy731/wiggle/blob/main/Wiggle_Standalone_5_1.ipynb) by [zippy731](https://twitter.com/zippy731)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N4jXBTdS_Jx_"
      },
      "outputs": [],
      "source": [
        "#======= WIGGLE MODE\n",
        "#@markdown ---\n",
        "#@markdown ####**Wiggle:**\n",
        "#@markdown Generates semirandom keyframes for zoom / spin / translation. \n",
        "#@markdown Set ranges below, then run this cell.\n",
        "#@markdown\n",
        "\n",
        "#.. can be embedded directly into DD5 notebook.  Copy this code into \n",
        "#animation settings tab, just before 'Coherency Settings'\n",
        "#Then comment out standalone-only code and uncomment 'embedded-only' section.\n",
        "\n",
        "#standalone-only:\n",
        "import random\n",
        "wiggle_frames = 6000#@param {type:\"number\"}\n",
        "max_frames = wiggle_frames\n",
        "#end standalone-only\n",
        "\n",
        "#embedded-only:\n",
        "use_wiggle = True #@param {type:\"boolean\"} \n",
        "wiggle_show_params = True #@param {type:\"boolean\"} \n",
        "#end embedded-only code\n",
        "\n",
        "#@markdown Wiggle preroll and episodes (frames) and duration variability:\n",
        "preroll_frames = 24#@param {type:\"integer\"}\n",
        "episode_duration = 60#@param {type:\"integer\"}\n",
        "wig_ads_input = '0.4,0.4,0.4'#@param {type:\"string\"}\n",
        "wig_adsmix = [float(x) for x in wig_ads_input.split(',')]\n",
        "wig_time_var = 0.8#@param {type:\"number\"}\n",
        "#@markdown Wiggle loop: force wiggle motion to restart every [n] frames. Useful for motion matching in loops.\n",
        "wig_loop = False  #@param {type:\"boolean\"} \n",
        "wig_loop_frames = 360#@param {type:\"integer\"}\n",
        "#@markdown Wiggle time phases (3 values, sum to 1.0):\n",
        "#@markdown Zoom (2D) and trz (3D) ranges and quiet factor\n",
        "wig_zoom_min_max = '0,0'#@param {type:\"string\"}\n",
        "wig_zoom_range= [float(x) for x in wig_zoom_min_max.split(',')]\n",
        "wig_trz_min_max = '6,8'#@param {type:\"string\"}\n",
        "wig_trz_range = [int(x) for x in wig_trz_min_max.split(',')]\n",
        "wig_zoom_quiet_factor =  1.0#@param {type:\"number\"}# wig_zoom_quiet_scale_factor//scale of zoom quiet periods, as function of above range\n",
        "#@markdown angle (2D) trx,try(2D/3D) and rotx,roty,rotz (3D) ranges and quiet factor\n",
        "\n",
        "wig_angle_min_max = '0,0'#@param {type:\"string\"}\n",
        "wig_angle_range= [float(x) for x in wig_angle_min_max.split(',')]\n",
        "wig_trx_min_max = '-3,3'#@param {type:\"string\"}\n",
        "wig_trx_range= [float(x) for x in wig_trx_min_max.split(',')]\n",
        "wig_try_min_max = '-3,3'#@param {type:\"string\"}\n",
        "wig_try_range= [float(x) for x in wig_try_min_max.split(',')]\n",
        "\n",
        "wig_rotx_min_max = '-.5,.5'#@param {type:\"string\"}\n",
        "wig_rotx_range= [float(x) for x in wig_rotx_min_max.split(',')]\n",
        "wig_roty_min_max = '-.5,.5'#@param {type:\"string\"}\n",
        "wig_roty_range= [float(x) for x in wig_roty_min_max.split(',')]\n",
        "wig_rotz_min_max = '-.5,.5'#@param {type:\"string\"}\n",
        "wig_rotz_range= [float(x) for x in wig_rotz_min_max.split(',')]\n",
        "wig_motion_quiet_factor=.9 #@param {type:\"number\"}\n",
        "#@markdown GLIDE MODE: tr_x and tr_y yoked to rot_z and rot_x, respectively.\n",
        "#@markdown *ADDS* to tr_x and tr_y values set above.\n",
        "# ht @BrokenMindset!\n",
        "##wig_glide_mode = True #@param {type:\"boolean\"} \n",
        "wig_glide_x_factor = 0 #@param {type:\"number\"}\n",
        "wig_glide_y_factor =  0#@param {type:\"number\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if use_wiggle:\n",
        "    #calculate wiggle keyframes, inject into diffusion notebook  \n",
        "\n",
        "    #calc time ranges   \n",
        "    episode_count = round((max_frames)/(episode_duration*.8),0)\n",
        "    wig_attack_range=(round(episode_duration*wig_adsmix[0]*(1-wig_time_var),0),round(episode_duration*wig_adsmix[0]*(1+wig_time_var),0))\n",
        "    wig_decay_range=(round(episode_duration*wig_adsmix[1]*(1-wig_time_var),0),round(episode_duration*wig_adsmix[1]*(1+wig_time_var),0))\n",
        "    wig_sustain_range=(round(episode_duration*wig_adsmix[2]*(1-wig_time_var),0),round(episode_duration*wig_adsmix[2]*(1+wig_time_var),0))\n",
        "    #------------\n",
        "\n",
        "    episodes = [(0,1.0,0,0,0,0,0,0,0)] #initialize episodes list\n",
        "    #ep is: (frame,zoom,angle,trx,try,trz,rotx,roty,rotz)\n",
        "    episode_starts = [0]\n",
        "    episode_peaks = [0]\n",
        "    i = 1\n",
        "    skip_1 = 0\n",
        "    wig_frame_count = round(preroll_frames,0)\n",
        "    while i < episode_count:\n",
        "      #attack: quick ramp to motion\n",
        "      if wig_time_var == 0:\n",
        "        skip_1 = wig_attack_range[0]\n",
        "      else:\n",
        "        skip_1 = round(random.randrange(wig_attack_range[0],wig_attack_range[1]),0)\n",
        "      wig_frame_count += int(skip_1)\n",
        "      zoom_1 = 1+round(random.uniform(wig_zoom_range[0],wig_zoom_range[1]),3)\n",
        "      trz_1 = round(random.uniform(wig_trz_range[0],wig_trz_range[1]),3)\n",
        "      angle_1 = round(random.uniform(wig_angle_range[0],wig_angle_range[1]),3)\n",
        "      rotx_1 = round(random.uniform(wig_rotx_range[0],wig_rotx_range[1]),3) \n",
        "      roty_1 = round(random.uniform(wig_roty_range[0],wig_roty_range[1]),3) \n",
        "      rotz_1 = round(random.uniform(wig_rotz_range[0],wig_rotz_range[1]),3) \n",
        "      trx_1 = round(random.uniform(wig_trx_range[0],wig_trx_range[1]),3)+round((rotz_1*wig_glide_x_factor),3)\n",
        "      try_1 = round(random.uniform(wig_try_range[0],wig_try_range[1]),3)+round((rotx_1*wig_glide_y_factor),3)\n",
        "\n",
        "\n",
        "      episodes.append((wig_frame_count,zoom_1,angle_1,trx_1,try_1,trz_1,rotx_1,roty_1,rotz_1))\n",
        "      episode_starts.append((wig_frame_count))\n",
        "      #decay: ramp down to element of interest\n",
        "      if wig_time_var == 0:\n",
        "        skip_1 = wig_decay_range[0]\n",
        "      else:\n",
        "        skip_1 = round(random.randrange(wig_decay_range[0],wig_decay_range[1]),0)\n",
        "      wig_frame_count += int(skip_1)\n",
        "      zoom_1 = 1+(round(wig_zoom_quiet_factor*random.uniform(wig_zoom_range[0],wig_zoom_range[1]),3))\n",
        "      trz_1 = round(wig_zoom_quiet_factor*random.uniform(wig_trz_range[0],wig_trz_range[1]),3)\n",
        "      angle_1 = round(wig_motion_quiet_factor*random.uniform(wig_angle_range[0],wig_angle_range[1]),3)\n",
        "      rotx_1 = round(wig_motion_quiet_factor*random.uniform(wig_rotx_range[0],wig_rotx_range[1]),3)\n",
        "      roty_1 = round(wig_motion_quiet_factor*random.uniform(wig_roty_range[0],wig_roty_range[1]),3)\n",
        "      rotz_1 = round(wig_motion_quiet_factor*random.uniform(wig_rotz_range[0],wig_rotz_range[1]),3)\n",
        "      trx_1 = round(wig_motion_quiet_factor*random.uniform(wig_trx_range[0],wig_trx_range[1]),3)+round((rotz_1*wig_glide_x_factor),3)\n",
        "      try_1 = round(wig_motion_quiet_factor*random.uniform(wig_try_range[0],wig_try_range[1]),3)+round((rotx_1*wig_glide_y_factor),3)\n",
        "      episodes.append((wig_frame_count,zoom_1,angle_1,trx_1,try_1,trz_1,rotx_1,roty_1,rotz_1))\n",
        "      episode_peaks.append((wig_frame_count))\n",
        "      #sustain: pause during element of interest\n",
        "      if wig_time_var == 0:\n",
        "        skip_1 = wig_sustain_range[0]\n",
        "      else:\n",
        "        skip_1 = round(random.randrange(wig_sustain_range[0],wig_sustain_range[1]),0)\n",
        "      wig_frame_count += int(skip_1)\n",
        "      zoom_1 = 1+(round(wig_zoom_quiet_factor*random.uniform(wig_zoom_range[0],wig_zoom_range[1]),3))\n",
        "      trz_1 = round(wig_zoom_quiet_factor*random.uniform(wig_trz_range[0],wig_trz_range[1]),3)     \n",
        "      angle_1 = round(wig_motion_quiet_factor*random.uniform(wig_angle_range[0],wig_angle_range[1]),3)\n",
        "      rotx_1 = round(wig_motion_quiet_factor*random.uniform(wig_rotx_range[0],wig_rotx_range[1]),3)\n",
        "      roty_1 = round(wig_motion_quiet_factor*random.uniform(wig_roty_range[0],wig_roty_range[1]),3)\n",
        "      rotz_1 = round(wig_motion_quiet_factor*random.uniform(wig_rotz_range[0],wig_rotz_range[1]),3)\n",
        "      trx_1 = round(wig_motion_quiet_factor*random.uniform(wig_trx_range[0],wig_trx_range[1]),3)+round((rotz_1*wig_glide_x_factor),3)\n",
        "      try_1 = round(wig_motion_quiet_factor*random.uniform(wig_try_range[0],wig_try_range[1]),3)+round((rotx_1*wig_glide_y_factor),3)\n",
        "      episodes.append((wig_frame_count,zoom_1,angle_1,trx_1,try_1,trz_1,rotx_1,roty_1,rotz_1))\n",
        "      i+=1\n",
        "\n",
        "   \n",
        "    if wig_loop==True and wig_loop_frames > (episode_duration*2):\n",
        "      #rebuild episode list w repeats\n",
        "      looping_episodes = [i for i in episodes if i[0] < wig_loop_frames and i[0]>0]\n",
        "      wig_ep_loop = [(0,1.0,0,0,0,0,0,0,0)] \n",
        "      i=0\n",
        "      while i < (int(max_frames/wig_loop_frames)+1):\n",
        "        # now update episode list w new starts\n",
        "        j=0\n",
        "        while j < len(looping_episodes):\n",
        "          old_ep = list(looping_episodes[j])\n",
        "          new_ep_start = old_ep[0]+i*wig_loop_frames\n",
        "          new_ep = [new_ep_start,old_ep[1],old_ep[2],old_ep[3],old_ep[4],old_ep[5],old_ep[6],old_ep[7],old_ep[8]]\n",
        "          wig_ep_loop.append(new_ep)\n",
        "          j+=1\n",
        "        i+=1\n",
        "      episodes = wig_ep_loop\n",
        "      \n",
        "    #trim off any episode > max_frames\n",
        "    cleaned_episodes = [i for i in episodes if i[0] < max_frames]\n",
        "    episodes = cleaned_episodes\n",
        "    cleaned_episode_starts = [i for i in episode_starts if i < max_frames]\n",
        "    episode_starts = cleaned_episode_starts\n",
        "    cleaned_episode_peaks = [i for i in episode_peaks if i < max_frames]\n",
        "    episode_peaks = cleaned_episode_peaks\n",
        "\n",
        "    #build full schedule\n",
        "    keyframe_frames = [item[0] for item in episodes]\n",
        "\n",
        "    #Build keyframe strings \n",
        "    wig_zoom_string=''\n",
        "    wig_angle_string=''\n",
        "    wig_trx_string=''\n",
        "    wig_try_string=''\n",
        "    wig_trz_string=''\n",
        "    wig_rotx_string=''\n",
        "    wig_roty_string=''\n",
        "    wig_rotz_string=''\n",
        "    # iterate thru episodes, generate keyframe strings\n",
        "    ### reformat as keyframe strings for testing\n",
        "    i = 0\n",
        "    while i < len(episodes):\n",
        "      wig_zoom_string += str(int(episodes[i][0]))+':('+str(episodes[i][1])+'),'\n",
        "      wig_angle_string += str(round(episodes[i][0],0))+':('+str(episodes[i][2])+'),'\n",
        "      wig_trx_string += str(round(episodes[i][0],0))+':('+str(episodes[i][3])+'),'\n",
        "      wig_try_string += str(round(episodes[i][0],0))+':('+str(episodes[i][4])+'),'\n",
        "      wig_trz_string += str(round(episodes[i][0],0))+':('+str(episodes[i][5])+'),'\n",
        "      wig_rotx_string += str(round(episodes[i][0],0))+':('+str(episodes[i][6])+'),'\n",
        "      wig_roty_string += str(round(episodes[i][0],0))+':('+str(episodes[i][7])+'),'\n",
        "      wig_rotz_string += str(round(episodes[i][0],0))+':('+str(episodes[i][8])+'),'\n",
        "      i+=1    \n",
        "\n",
        "    zoom = wig_zoom_string\n",
        "    angle = wig_angle_string \n",
        "    translation_x = wig_trx_string\n",
        "    translation_y =  wig_try_string\n",
        "    translation_z =  wig_trz_string\n",
        "    rotation_3d_x = wig_rotx_string\n",
        "    rotation_3d_y = wig_roty_string\n",
        "    rotation_3d_z = wig_rotz_string\n",
        "\n",
        "#============= END WIGGLE\n",
        "\n",
        "# pharmapsychotic: displaying as widgets for easier copy to clipboard action\n",
        "\n",
        "code_str = \"\"\n",
        "code_str += f\"(zoom,angle,translation_x,translation_y,translation_z,rotation_3d_x,rotation_3d_y,rotation_3d_z) = \"\n",
        "code_str += f\"('{zoom}','{angle}','{translation_x}','{translation_y}','{translation_z}','{rotation_3d_x}','{rotation_3d_y}','{rotation_3d_z}')\"\n",
        "\n",
        "print(\"\\nCopy and paste the cam_code text above to preview. When you get what you like copy each of the fields into your Disco notebook.\\n\")\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Layout, Text\n",
        "\n",
        "layout = Layout(width='75%')\n",
        "\n",
        "angle_widget = Text(value=angle, description='angle:', layout=layout)\n",
        "zoom_widget = Text(value=zoom, description='zoom:', layout=layout)\n",
        "translation_x_widget = Text(value=translation_x, description='translation_x:', layout=layout)\n",
        "translation_y_widget = Text(value=translation_y, description='translation_y:', layout=layout)\n",
        "translation_z_widget = Text(value=translation_z, description='translation_z:', layout=layout)\n",
        "rotation_3d_x_widget = Text(value=rotation_3d_x, description='rot_3d_x:', layout=layout)\n",
        "rotation_3d_y_widget = Text(value=rotation_3d_y, description='rot_3d_y:', layout=layout)\n",
        "rotation_3d_z_widget = Text(value=rotation_3d_z, description='rot_3d_z:', layout=layout)\n",
        "\n",
        "\n",
        "code_widget = widgets.Textarea(\n",
        "    value=code_str,\n",
        "    description='cam_code:',\n",
        "    layout=Layout(width='75%', height='8em')\n",
        ")\n",
        "\n",
        "widgets.VBox([\n",
        "    angle_widget, zoom_widget, \n",
        "    translation_x_widget, translation_y_widget, translation_z_widget,\n",
        "    rotation_3d_x_widget, rotation_3d_y_widget, rotation_3d_z_widget,\n",
        "    code_widget\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzwO6qQNHA28"
      },
      "source": [
        "# $ BACKGROUND REMOVER $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWRnRhBvD5I4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!pip install rembg[gpu]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVBkDbhoGHJi",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!pip install --upgrade pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEPuRGhEEG0n",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from rembg import remove\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "input_path = '/content/drive/MyDrive/bokinator/ZT-D40900B-10PN675.png'\n",
        "output_path = '/content/output.png'\n",
        "\n",
        "input = Image.open(input_path)\n",
        "output = remove(input)\n",
        "output.save(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LWsNd3_M3MP"
      },
      "source": [
        "# 🐸 [Coqui-TTS](https://github.com/coqui-ai/TTS)  on CPU Real-Time Speech Synthesis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAqrSIWgLyP0"
      },
      "source": [
        "## Tacotron2 with Dynamic Convolutional Attention\n",
        "Paper: https://arxiv.org/abs/2005.11129\n",
        "\n",
        "Trained with **LJSpeech** for **200K steps** and reduction rate of 2.\n",
        "\n",
        "## Universal FullBand-MelGAN\n",
        "Paper: https://arxiv.org/abs/2005.05106 \n",
        "\n",
        "Trained with **LibriTTS** for **675K steps** with real spectrograms.\n",
        "\n",
        "This model is able to synthesize speech in different languages and voices.\n",
        "\n",
        "**Note that** TTS and vocoder models have different sampling rates. This is fixed by\n",
        "interpolating TTS output before Vocoder inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku-dA4DKoeXk"
      },
      "source": [
        "### Download Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGIgnWhGsxU1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!gdown --id 1CFoPDQBnhfBFu2Gc0TBSJn8o-TuNKQn7 -O tts_model.pth.tar\n",
        "!gdown --id 1lWSscNfKet1zZSJCNirOn7v9bigUZ8C1 -O config.json\n",
        "!gdown --id 1qevpGRVHPmzfiRBNuugLMX62x1k7B5vK -O scale_stats_vocoder.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dnpE0-kvTsu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!gdown --id 1i16_9_qLgtjdT9W5hfB74BlLHihReK87 -O vocoder_model.pth.tar\n",
        "!gdown --id 1uBRVNxsoCYJxNCqPoQedASm6EtSW3w04 -O config_vocoder.json\n",
        "!gdown --id 1JZugLTx8li1EMgptiXwh4AsOFYrJjobi -O scale_stats_vocoder.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gshXbbAgIdv3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!gdown --id 1qevpGRVHPmzfiRBNuugLMX62x1k7B5vK -O scale_stats.npy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZuDrj_ioqHE"
      },
      "source": [
        "### Setup Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2axt5BYq7gv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "! sudo apt-get install espeak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZduAf-qYYEIT",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!git clone https://github.com/coqui-ai/TTS TTS_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofPCvPyjZEcT",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "%cd TTS_repo\n",
        "!git checkout 4132240\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovWUC6ImlLYX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlgi8fPdpRF0"
      },
      "source": [
        "### Define TTS function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-Yc42nQZG5A",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "def interpolate_vocoder_input(scale_factor, spec):\n",
        "    \"\"\"Interpolation to tolarate the sampling rate difference\n",
        "    btw tts model and vocoder\"\"\"\n",
        "    print(\" > before interpolation :\", spec.shape)\n",
        "    spec = torch.tensor(spec).unsqueeze(0).unsqueeze(0)\n",
        "    spec = torch.nn.functional.interpolate(spec, scale_factor=scale_factor, mode='bilinear').squeeze(0)\n",
        "    print(\" > after interpolation :\", spec.shape)\n",
        "    return spec\n",
        "\n",
        "\n",
        "def tts(model, text, CONFIG, use_cuda, ap, use_gl, figures=True):\n",
        "    t_1 = time.time()\n",
        "    # run tts\n",
        "    target_sr = CONFIG.audio['sample_rate']\n",
        "    waveform, alignment, mel_spec, mel_postnet_spec, stop_tokens, inputs =\\\n",
        "     synthesis(model,\n",
        "               text,\n",
        "               CONFIG,\n",
        "               use_cuda,\n",
        "               ap,\n",
        "               speaker_id,\n",
        "               None,\n",
        "               False,\n",
        "               CONFIG.enable_eos_bos_chars,\n",
        "               use_gl)\n",
        "    # run vocoder\n",
        "    mel_postnet_spec = ap._denormalize(mel_postnet_spec.T).T\n",
        "    if not use_gl:\n",
        "        target_sr = VOCODER_CONFIG.audio['sample_rate']\n",
        "        vocoder_input = ap_vocoder._normalize(mel_postnet_spec.T)\n",
        "        if scale_factor[1] != 1:\n",
        "            vocoder_input = interpolate_vocoder_input(scale_factor, vocoder_input)\n",
        "        else:\n",
        "            vocoder_input = torch.tensor(vocoder_input).unsqueeze(0)\n",
        "        waveform = vocoder_model.inference(vocoder_input)\n",
        "    # format output\n",
        "    if use_cuda and not use_gl:\n",
        "        waveform = waveform.cpu()\n",
        "    if not use_gl:\n",
        "        waveform = waveform.numpy()\n",
        "    waveform = waveform.squeeze()\n",
        "    # compute run-time performance\n",
        "    rtf = (time.time() - t_1) / (len(waveform) / ap.sample_rate)\n",
        "    tps = (time.time() - t_1) / len(waveform)\n",
        "    print(waveform.shape)\n",
        "    print(\" > Run-time: {}\".format(time.time() - t_1))\n",
        "    print(\" > Real-time factor: {}\".format(rtf))\n",
        "    print(\" > Time per step: {}\".format(tps))\n",
        "    # display audio\n",
        "    IPython.display.display(IPython.display.Audio(waveform, rate=target_sr))  \n",
        "    return alignment, mel_postnet_spec, stop_tokens, waveform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZksegYQepkFg"
      },
      "source": [
        "### Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVa0kOamprgj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "import IPython\n",
        "\n",
        "# for some reason TTS installation does not work on Colab\n",
        "sys.path.append('TTS_repo')\n",
        "\n",
        "from TTS.utils.io import load_config\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "from TTS.tts.utils.generic_utils import setup_model\n",
        "from TTS.tts.utils.text.symbols import symbols, phonemes, make_symbols\n",
        "from TTS.tts.utils.synthesis import synthesis\n",
        "from TTS.tts.utils.io import load_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY-sHVO8IFSH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# runtime settings\n",
        "use_cuda = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1aIUp2FpxOQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# model paths\n",
        "TTS_MODEL = \"tts_model.pth.tar\"\n",
        "TTS_CONFIG = \"config.json\"\n",
        "VOCODER_MODEL = \"vocoder_model.pth.tar\"\n",
        "VOCODER_CONFIG = \"config_vocoder.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpgmdBVQplbv",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# load configs\n",
        "TTS_CONFIG = load_config(TTS_CONFIG)\n",
        "VOCODER_CONFIG = load_config(VOCODER_CONFIG)\n",
        "\n",
        "TTS_CONFIG.audio['stats_path'] = \"./scale_stats.npy\"\n",
        "VOCODER_CONFIG.audio['stats_path'] = \"./scale_stats_vocoder.npy\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmrQxiozIUVE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# load the audio processor\n",
        "ap = AudioProcessor(**TTS_CONFIG.audio)         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fLoI4ipqMeS",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# LOAD TTS MODEL\n",
        "# multi speaker \n",
        "speakers = []\n",
        "speaker_id = None\n",
        "    \n",
        "if 'characters' in TTS_CONFIG.keys():\n",
        "    symbols, phonemes = make_symbols(**TTS_CONFIG.characters)\n",
        "\n",
        "# load the model\n",
        "num_chars = len(phonemes) if TTS_CONFIG.use_phonemes else len(symbols)\n",
        "model = setup_model(num_chars, len(speakers), TTS_CONFIG)      \n",
        "\n",
        "# load model state\n",
        "model, _ =  load_checkpoint(model, TTS_MODEL, use_cuda=use_cuda)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKoq0GgzqzhQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from TTS.vocoder.utils.generic_utils import setup_generator\n",
        "\n",
        "# LOAD VOCODER MODEL\n",
        "vocoder_model = setup_generator(VOCODER_CONFIG)\n",
        "vocoder_model.load_state_dict(torch.load(VOCODER_MODEL, map_location=\"cuda\")[\"model\"])\n",
        "vocoder_model.remove_weight_norm()\n",
        "vocoder_model.inference_padding = 0\n",
        "\n",
        "# scale factor for sampling rate difference\n",
        "scale_factor = [1,  VOCODER_CONFIG['audio']['sample_rate'] / ap.sample_rate]\n",
        "print(f\"scale_factor: {scale_factor}\")\n",
        "\n",
        "ap_vocoder = AudioProcessor(**VOCODER_CONFIG['audio'])    \n",
        "if use_cuda:\n",
        "    vocoder_model.cuda()\n",
        "vocoder_model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws_YkPKsLgo-"
      },
      "source": [
        "## Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuWxZ9Ey5Puj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "sentence =  \"His palms are sweaty, knees weak, arms are heavy there's vomit on his sweater already, mom's spaghetti. He's nervous. But on the surface he looks calm and ready to drop bombs, but he keeps on forgetting what he wrote down the whole crowd goes so loud, he opens his mouth but the words won't come out, he's choking, how, everybody's choking now, the clock's run out, time's up! OVER! BLAOW! Snap back to reality.\"\n",
        "out_path = \"/content/test.wav\"\n",
        "align, spec, stop_tokedns, wav = tts(model, sentence, TTS_CONFIG, use_cuda, ap, use_gl=False, figures=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVTf7aSpdPmP"
      },
      "source": [
        "# DEEPFAKE "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXHj2IzkdOr0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!git clone https://github.com/chervonij/DFL-Colab.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cKdTCuv4tXh"
      },
      "source": [
        "# Welcome to DFL-Colab!\n",
        "\n",
        "This is an adapted version of the DFL for Google Colab.\n",
        "\n",
        "\n",
        "# Overview\n",
        "*   Extractor works in full functionality.\n",
        "*   Training can work without preview.\n",
        "*   Merger works in full functionality.\n",
        "*   You can import/export workspace with your Google Drive.\n",
        "*   Import/export and another manipulations with workspace you can do in \"Manage workspace\" block\n",
        "*   Google Colab machine active for 12 hours. DFL-Colab makes a backup of your workspace in training mode.\n",
        "*   Google does not like long-term heavy calculations. Therefore, for training more than two sessions in a row, use two Google accounts. It is recommended to split your training over 2 accounts, but you can use one Google Drive account to store your workspace.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYtWMzOvLQ3s"
      },
      "source": [
        "## Prevent random disconnects\n",
        "\n",
        "This cell runs JS code to automatic reconnect to runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtClEMAMLVHw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDg_jiQ9adQe"
      },
      "source": [
        "## Check GPU\n",
        "\n",
        "*   Google Colab can provide you with one of Tesla graphics cards: K80, T4, P4 or P100\n",
        "*   Here you can check the model of GPU before using DeepFaceLab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJe71S6gbzt3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVn21kt40Gw"
      },
      "source": [
        "## Install or update DeepFaceLab\n",
        "\n",
        "* Install or update DeepFAceLab directly from Github\n",
        "* Requirements install is automatically\n",
        "* Automatically sets timer to prevent random disconnects\n",
        "* \"Download FFHQ\" option means to download high quality FFHQ dataset instead of CelebA. FFHQ takes up more memory, so it will take longer to download than CelebA. It is recommended to enable this option if you are doing pretrain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JG-f2WqT4fLK"
      },
      "outputs": [],
      "source": [
        "#@title Install or update DeepFaceLab from Github\n",
        "\n",
        "Mode = \"install\" #@param [\"install\", \"update\"]\n",
        "Download_FFHQ = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "pretrain_link = \"https://github.com/chervonij/DFL-Colab/releases/download/\"\n",
        "pretrain_link = pretrain_link+\"pretrain_GenericFFHQ/pretrain_FFHQ.zip\" if Download_FFHQ else pretrain_link+\"pretrain-CelebA/pretrain_CelebA.zip\"\n",
        "\n",
        "from pathlib import Path\n",
        "if (Mode == \"install\"):\n",
        "  !git clone https://github.com/iperov/DeepFaceLab.git\n",
        "  %cd \"/content/DeepFaceLab\"\n",
        "  #!git checkout 9ad9728b4021d1dff62905cce03e2157d0c0868d\n",
        "  %cd \"/content\"\n",
        "\n",
        "  # fix linux warning\n",
        "  # /usr/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n",
        "  fin = open(\"/usr/lib/python3.6/multiprocessing/semaphore_tracker.py\", \"rt\")\n",
        "  data = fin.read()\n",
        "  data = data.replace('if cache:', 'if False:')\n",
        "  fin.close()\n",
        "\n",
        "  fin = open(\"/usr/lib/python3.6/multiprocessing/semaphore_tracker.py\", \"wt\")\n",
        "  fin.write(data)\n",
        "  fin.close()\n",
        "else:\n",
        "  %cd /content/DeepFaceLab\n",
        "  !git pull\n",
        "\n",
        "#!pip uninstall -y tensorflow\n",
        "#!pip install -r /content/DeepFaceLab/requirements-colab.txt\n",
        "!pip install --upgrade scikit-image\n",
        "#!apt-get install cuda-10-0\n",
        "\n",
        "!pip install tqdm\n",
        "#!pip install numpy==1.19.3\n",
        "!pip install numexpr\n",
        "!pip install h5py==2.10.0\n",
        "!pip install opencv-python==4.1.0.25\n",
        "!pip install ffmpeg-python==0.1.17\n",
        "!pip install scikit-image==0.14.2\n",
        "!pip install scipy==1.4.1\n",
        "!pip install colorama\n",
        "!pip install tf2onnx==1.9.3\n",
        "\n",
        "if not Path(\"/content/pretrain\").exists():\n",
        "  print(\"Downloading Pretrain faceset ... \")\n",
        "  !wget -q --no-check-certificate -r $pretrain_link -O /content/pretrain_faceset.zip\n",
        "  !mkdir /content/pretrain\n",
        "  !unzip -q /content/pretrain_faceset.zip -d /content/pretrain/\n",
        "  !rm /content/pretrain_faceset.zip\n",
        "\n",
        "if not Path(\"/content/pretrain_Q96\").exists():\n",
        "  print(\"Downloading Q96 pretrained model ...\")\n",
        "  !wget -q --no-check-certificate -r 'https://github.com/chervonij/DFL-Colab/releases/download/Q96_model_pretrained/Q96_model_pretrained.zip' -O /content/pretrain_Q96.zip\n",
        "  !mkdir /content/pretrain_Q96\n",
        "  !unzip -q /content/pretrain_Q96.zip -d /content/pretrain_Q96/\n",
        "  !rm /content/pretrain_Q96.zip\n",
        "\n",
        "if not Path(\"/content/workspace\").exists():\n",
        "  !mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model  \n",
        "\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqwOlJG4MdLC"
      },
      "source": [
        "## Manage workspace\n",
        "\n",
        "\n",
        "\n",
        "*   You can import/export workspace or individual data, like model files with Google Drive\n",
        "*   Also, you can use HFS (HTTP Fileserver) for directly import/export you workspace from your computer\n",
        "*   You can clear all workspace or delete part of it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z4w_sUzgOQmL"
      },
      "outputs": [],
      "source": [
        "#@title Import from Drive\n",
        "\n",
        "Mode = \"data_src\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"models\"]\n",
        "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  unzip_cmd=\" -q \"+Archive_name\n",
        "  \n",
        "  %cd $path\n",
        "  copy_cmd = \"/content/drive/My\\ Drive/\"+Archive_name+\" \"+path\n",
        "  !cp $copy_cmd\n",
        "  !unzip $unzip_cmd    \n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "  \n",
        "print(\"Done!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0Y3WfuwoNXqC"
      },
      "outputs": [],
      "source": [
        "#@title Export to Drive { form-width: \"30%\" }\n",
        "Mode = \"data_src\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"merged\", \"merged_mask\", \"models\", \"result video\", \"result_mask video\"]\n",
        "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  zip_cmd=\"-0 -r -q \"+Archive_name+\" \"\n",
        "  \n",
        "  %cd $path\n",
        "  zip_cmd+=mode\n",
        "  !zip $zip_cmd\n",
        "  copy_cmd = \" \"+Archive_name+\"  /content/drive/My\\ Drive/\"\n",
        "  !cp $copy_cmd\n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"merged\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged\")\n",
        "elif Mode == \"merged_mask\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged_mask\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "elif Mode == \"result video\":\n",
        "  !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
        "elif Mode == \"result_mask video\":\n",
        "  !cp /content/workspace/result_mask.mp4 /content/drive/My\\ Drive/\n",
        "  \n",
        "print(\"Done!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hIvJtxwTGcb"
      },
      "outputs": [],
      "source": [
        "#@title Import from URL{ form-width: \"30%\", display-mode: \"form\" }\n",
        "URL = \"http://\" #@param {type:\"string\"}\n",
        "Mode = \"unzip to content\" #@param [\"unzip to content\", \"unzip to content/workspace\", \"unzip to content/workspace/data_src\", \"unzip to content/workspace/data_src/aligned\", \"unzip to content/workspace/data_dst\", \"unzip to content/workspace/data_dst/aligned\", \"unzip to content/workspace/model\", \"download to content/workspace\"]\n",
        "\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "def unzip(zip_path, dest_path):\n",
        "\n",
        "    \n",
        "  unzip_cmd = \" unzip -q \" + zip_path + \" -d \"+dest_path\n",
        "  !$unzip_cmd  \n",
        "  rm_cmd = \"rm \"+dest_path + url_path.name\n",
        "  !$rm_cmd\n",
        "  print(\"Unziped!\")\n",
        "  \n",
        "\n",
        "if Mode == \"unzip to content\":\n",
        "  dest_path = \"/content/\"\n",
        "elif Mode == \"unzip to content/workspace\":\n",
        "  dest_path = \"/content/workspace/\"\n",
        "elif Mode == \"unzip to content/workspace/data_src\":\n",
        "  dest_path = \"/content/workspace/data_src/\"\n",
        "elif Mode == \"unzip to content/workspace/data_src/aligned\":\n",
        "  dest_path = \"/content/workspace/data_src/aligned/\"\n",
        "elif Mode == \"unzip to content/workspace/data_dst\":\n",
        "  dest_path = \"/content/workspace/data_dst/\"\n",
        "elif Mode == \"unzip to content/workspace/data_dst/aligned\":\n",
        "  dest_path = \"/content/workspace/data_dst/aligned/\"\n",
        "elif Mode == \"unzip to content/workspace/model\":\n",
        "  dest_path = \"/content/workspace/model/\"\n",
        "elif Mode == \"download to content/workspace\":\n",
        "  dest_path = \"/content/workspace/\"\n",
        "\n",
        "if not Path(\"/content/workspace\").exists():\n",
        "  cmd = \"mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"\n",
        "  !$cmd\n",
        "\n",
        "url_path = Path(URL)\n",
        "urllib.request.urlretrieve ( URL, dest_path + url_path.name )\n",
        "\n",
        "if (url_path.suffix == \".zip\") and (Mode!=\"download to content/workspace\"):\n",
        "  unzip(dest_path + url_path.name, dest_path)\n",
        "\n",
        "  \n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7V1sc7rxNKLO"
      },
      "outputs": [],
      "source": [
        "#@title Export to URL\n",
        "URL = \"http://\" #@param {type:\"string\"}\n",
        "Mode = \"upload workspace\" #@param [\"upload workspace\", \"upload data_src\", \"upload data_dst\", \"upload data_src aligned\", \"upload data_dst aligned\", \"upload merged\", \"upload model\", \"upload result video\"]\n",
        "\n",
        "cmd_zip = \"zip -0 -r -q \"\n",
        "\n",
        "def run_cmd(zip_path, curl_url):\n",
        "  cmd_zip = \"zip -0 -r -q \"+zip_path\n",
        "  cmd_curl = \"curl --silent -F \"+curl_url+\" -D out.txt > /dev/null\"\n",
        "  !$cmd_zip\n",
        "  !$cmd_curl\n",
        "\n",
        "\n",
        "if Mode == \"upload workspace\":\n",
        "  %cd \"/content\"\n",
        "  run_cmd(\"workspace.zip workspace/\",\"'data=@/content/workspace.zip' \"+URL)\n",
        "elif Mode == \"upload data_src\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_src.zip data_src/\", \"'data=@/content/workspace/data_src.zip' \"+URL)\n",
        "elif Mode == \"upload data_dst\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_dst.zip data_dst/\", \"'data=@/content/workspace/data_dst.zip' \"+URL)\n",
        "elif Mode == \"upload data_src aligned\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_src_aligned.zip data_src/aligned\", \"'data=@/content/workspace/data_src_aligned.zip' \"+URL )\n",
        "elif Mode == \"upload data_dst aligned\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_dst_aligned.zip data_dst/aligned/\", \"'data=@/content/workspace/data_dst_aligned.zip' \"+URL)\n",
        "elif Mode == \"upload merged\":\n",
        "  %cd \"/content/workspace/data_dst\"\n",
        "  run_cmd(\"merged.zip merged/\",\"'data=@/content/workspace/data_dst/merged.zip' \"+URL )\n",
        "elif Mode == \"upload model\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"model.zip model/\", \"'data=@/content/workspace/model.zip' \"+URL)\n",
        "elif Mode == \"upload result video\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"result.zip result.mp4\", \"'data=@/content/workspace/result.zip' \"+URL)\n",
        "  \n",
        "  \n",
        "!rm *.zip\n",
        "\n",
        "%cd \"/content\"\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ta6ue_UGMkki"
      },
      "outputs": [],
      "source": [
        "#@title Delete and recreate\n",
        "Mode = \"Delete and recreate workspace\" #@param [\"Delete and recreate workspace\", \"Delete models\", \"Delete data_src\", \"Delete data_src aligned\", \"Delete data_src video\", \"Delete data_dst\", \"Delete data_dst aligned\", \"Delete merged frames\"]\n",
        "\n",
        "%cd \"/content\" \n",
        "\n",
        "if Mode == \"Delete and recreate workspace\":\n",
        "  cmd = \"rm -r /content/workspace ; mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"  \n",
        "elif Mode == \"Delete models\":\n",
        "  cmd = \"rm -r /content/workspace/model/*\"\n",
        "elif Mode == \"Delete data_src\":\n",
        "  cmd = \"rm /content/workspace/data_src/*.png || rm -r /content/workspace/data_src/*.jpg\"\n",
        "elif Mode == \"Delete data_src aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_src/aligned/*\"\n",
        "elif Mode == \"Delete data_src video\":\n",
        "  cmd = \"rm -r /content/workspace/data_src.*\"\n",
        "elif Mode == \"Delete data_dst\":\n",
        "  cmd = \"rm /content/workspace/data_dst/*.png || rm /content/workspace/data_dst/*.jpg\"\n",
        "elif Mode == \"Delete data_dst aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/aligned/*\"\n",
        "elif Mode == \"Delete merged frames\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/merged; rm -r /content/workspace/data_dst/merged_mask\"\n",
        "  \n",
        "!$cmd\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUNVcbujhm00"
      },
      "source": [
        "## Extract, sorting and faceset tools\n",
        "* Extract frames for SRC or DST video.\n",
        "* Denoise SRC or DST video. \"Factor\" param set intesity of denoising\n",
        "* Detect and align faces. If you need, you can get frames with debug landmarks.\n",
        "* Export workspace to Google Drive after extract and sort it manually (In \"Manage Workspace\" block)\n",
        "* You can enhance your facesets with DFL FacesetEnhancer.\n",
        "* Resize faceset to your model resolution. Since Colab doesn't have a powerful CPU, resizing samples during training increases iteration time. Faceset resize reduces iteration time by about 2x times. Don't forget to keep save original faceset on your PC.\n",
        "* Pack or unpack facesets with DFL packing tool.\n",
        "* Apply or remove trained XSeg model to the extracted faces.\n",
        "* Recommended for use, Generic XSeg model for auto segmentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qwJEbz5Nhot0"
      },
      "outputs": [],
      "source": [
        "#@title Extract frames\n",
        "Video = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py videoed extract-video\"\n",
        "\n",
        "if Video == \"data_dst\":\n",
        "  cmd+= \" --input-file workspace/data_dst.* --output-dir workspace/data_dst/\"\n",
        "else:\n",
        "  cmd+= \" --input-file workspace/data_src.* --output-dir workspace/data_src/\"\n",
        "  \n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bFmPo0s2lTil"
      },
      "outputs": [],
      "source": [
        "#@title Denoise frames\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "Factor = 1 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py videoed denoise-image-sequence --input-dir workspace/\"+Data+\" --factor \"+str(Factor)\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nmq0Sj2bmq7d"
      },
      "outputs": [],
      "source": [
        "#@title Detect faces\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "Detector = \"S3FD\" #@param [\"S3FD\", \"S3FD (whole face)\"]\n",
        "Debug = False #@param {type:\"boolean\"}\n",
        "\n",
        "detect_type = \"s3fd\"\n",
        "dbg = \" --output-debug\" if Debug else \" --no-output-debug\"\n",
        "\n",
        "folder = \"workspace/\"+Data\n",
        "folder_aligned = folder+\"/aligned\"\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py extract --input-dir \"+folder+\" --output-dir \"+folder_aligned\n",
        "cmd+=\" --detector \"+detect_type+\" --force-gpu-idxs 0\"+dbg\n",
        "\n",
        "if \"whole face\" in Detector:\n",
        "  cmd+=\" --face-type whole_face\" \n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TRNxUFE6p6Eu"
      },
      "outputs": [],
      "source": [
        "#@title Sort aligned\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "sort_type = \"hist\" #@param [\"blur\", \"motion-blur\", \"face-yaw\", \"face-pitch\", \"face-source-rect-size\", \"hist\", \"hist-dissim\", \"brightness\", \"hue\", \"black\", \"origname\", \"oneface\", \"final-by-blur\", \"final-by-size\", \"absdiff\"]\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py sort --input-dir workspace/\"+Data+\"/aligned --by \"+sort_type\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O5MbnVDyXkP7"
      },
      "outputs": [],
      "source": [
        "#@title Faceset Enhancer\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "data_path = \"/content/workspace/\"+Data+\"/aligned\"\n",
        "cmd = \"/content/DeepFaceLab/main.py facesettool enhance --input-dir \"+data_path\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Hyg5SREuMx8Q"
      },
      "outputs": [],
      "source": [
        "#@title Resize faceset\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "cmd = \"/content/DeepFaceLab/main.py facesettool resize --input-dir /content/workspace/\" + \\\n",
        "      f\"{Data}/aligned\"\n",
        "\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ypLfPUNHZNEp"
      },
      "outputs": [],
      "source": [
        "#@title Pack/Unpack aligned faceset\n",
        "\n",
        "Folder = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "Mode = \"unpack\" #@param [\"pack\", \"unpack\"]\n",
        "\n",
        "cmd = \"/content/DeepFaceLab/main.py util --input-dir /content/workspace/\" + \\\n",
        "      f\"{Folder}/aligned --{Mode}-faceset\"\n",
        "\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-VVvtoBMGnrA"
      },
      "outputs": [],
      "source": [
        "#@title Apply or remove XSeg mask to the faces\n",
        "Mode = \"Apply mask\" #@param [\"Apply mask\", \"Remove mask\"]\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "GenericXSeg = True #@param {type:\"boolean\"}\n",
        "\n",
        "from pathlib import Path\n",
        "mode_arg = 'apply' if Mode == \"Apply mask\" else 'remove'\n",
        "\n",
        "if GenericXSeg and not Path('/content/GenericXSeg').exists():\n",
        "  print('Downloading Generic XSeg model ... ')\n",
        "  xseg_link = 'https://github.com/chervonij/DFL-Colab/releases/download/GenericXSeg/GenericXSeg.zip'\n",
        "  !mkdir /content/GenericXSeg\n",
        "  !wget -q --no-check-certificate -r $xseg_link -O /content/GenericXSeg.zip\n",
        "  !unzip -q /content/GenericXSeg.zip -d /content/GenericXSeg/\n",
        "  !rm /content/GenericXSeg.zip\n",
        "\n",
        "main_path = '/content/DeepFaceLab/main.py'\n",
        "data_path = f'/content/workspace/{Data}/aligned'\n",
        "model_path = '/content/workspace/model' if not GenericXSeg else '/content/GenericXSeg'\n",
        "\n",
        "cmd = f'{main_path} xseg {mode_arg} --input-dir {data_path} '\n",
        "cmd += f'--model-dir {model_path}' if mode_arg == 'apply' else ''\n",
        "\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTuyUxgdLA13"
      },
      "source": [
        "## Train model\n",
        "\n",
        "* Choose your model type, but SAEHD is recommend for everyone\n",
        "* Set model options on output field\n",
        "* You can see preview manually, if go to model folder in filemanager and double click on preview.jpg file\n",
        "* Your workspace will be archived and upload to mounted Drive after 11 hours from start session\n",
        "* If you select \"Backup_every_hour\" option, your workspace will be backed up every hour.\n",
        "* Also, you can export your workspace manually in \"Manage workspace\" block\n",
        "* \"Silent_Start\" option provides to automatically start with best GPU and last used model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Z0Kya-PJLDhv"
      },
      "outputs": [],
      "source": [
        "#@title Training\n",
        "Model = \"SAEHD\" #@param [\"SAEHD\", \"AMP\", \"Quick96\", \"XSeg\"]\n",
        "Backup_every_hour = True #@param {type:\"boolean\"}\n",
        "Silent_Start = True #@param {type:\"boolean\"}\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import psutil, os, time\n",
        "\n",
        "p = psutil.Process(os.getpid())\n",
        "uptime = time.time() - p.create_time()\n",
        "\n",
        "if (Backup_every_hour):\n",
        "  if not os.path.exists('workspace.zip'):\n",
        "    print(\"Creating workspace archive ...\")\n",
        "    !zip -0 -r -q workspace.zip workspace\n",
        "    print(\"Archive created!\")\n",
        "  else:\n",
        "    print(\"Archive exist!\")\n",
        "\n",
        "if (Backup_every_hour):\n",
        "  print(\"Time to end session: \"+str(round((43200-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(3600)\n",
        "  backup_cmd = \" --execute-program -\"+backup_time+\" \\\"import os; os.system('zip -0 -r -q workspace.zip workspace/model'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\" \n",
        "elif (round(39600-uptime) > 0):\n",
        "  print(\"Time to backup: \"+str(round((39600-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(round(39600-uptime))\n",
        "  backup_cmd = \" --execute-program \"+backup_time+\" \\\"import os; os.system('zip -0 -r -q workspace.zip workspace'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\" \n",
        "else:\n",
        "  print(\"Session expires in less than an hour.\")\n",
        "  backup_cmd = \"\"\n",
        "    \n",
        "cmd = \"DeepFaceLab/main.py train --training-data-src-dir workspace/data_src/aligned --training-data-dst-dir workspace/data_dst/aligned --pretraining-data-dir pretrain --model-dir workspace/model --model \"+Model\n",
        "\n",
        "if Model == \"Quick96\":\n",
        "  cmd+= \" --pretrained-model-dir pretrain_Q96\"\n",
        "\n",
        "if Silent_Start:\n",
        "  cmd+= \" --silent-start\"\n",
        "\n",
        "if (backup_cmd != \"\"):\n",
        "  train_cmd = (cmd+backup_cmd)\n",
        "else:\n",
        "  train_cmd = (cmd)\n",
        "\n",
        "!python $train_cmd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avAcSL_uvtq_"
      },
      "source": [
        "## Merge frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A3Y8K22Sv9Gn"
      },
      "outputs": [],
      "source": [
        "#@title Merge\n",
        "Model = \"SAEHD\" #@param [\"SAEHD\", \"AMP\", \"Quick96\" ]\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py merge --input-dir workspace/data_dst --output-dir workspace/data_dst/merged --output-mask-dir workspace/data_dst/merged_mask --aligned-dir workspace/data_dst/aligned --model-dir workspace/model --model \"+Model\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JNeGfiZpxlnz"
      },
      "outputs": [],
      "source": [
        "#@title Get result video \n",
        "Mode = \"result video\" #@param [\"result video\", \"result_mask video\"]\n",
        "Copy_to_Drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if Mode == \"result video\":\n",
        "  !python DeepFaceLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged --output-file workspace/result.mp4 --reference-file workspace/data_dst.mp4 --include-audio\n",
        "  if Copy_to_Drive:\n",
        "    !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
        "elif Mode == \"result_mask video\":\n",
        "  !python DeepFaceLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged_mask --output-file workspace/result_mask.mp4 --reference-file workspace/data_dst.mp4\n",
        "  if Copy_to_Drive:\n",
        "    !cp /content/workspace/result_mask.mp4 /content/drive/My\\ Drive/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0wWe_VO4I79"
      },
      "source": [
        "# **Deforum Stable Diffusion v0.5**\n",
        "\n",
        "Run Your Audio Reactive Keyframes through here and generate your frames!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y6I2k5o3u8Bz"
      },
      "outputs": [],
      "source": [
        "#@title SETUP RESTART\n",
        "#!pip install --upgrade tensorflow-datasets tensorflow-addons absl-py gin-config parameterized mediapy scikit-image apache-beam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI8VGHi6c4QK"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nmPF-gzac4QL"
      },
      "outputs": [],
      "source": [
        "#@markdown **NVIDIA GPU**\n",
        "import subprocess\n",
        "sub_p_res = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.free', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(sub_p_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UQn4YA4kc4QM"
      },
      "outputs": [],
      "source": [
        "#@markdown **Model and Output Paths**\n",
        "# ask for the link\n",
        "print(\"Local Path Variables:\\n\")\n",
        "\n",
        "models_path = \"/content/models\" #@param {type:\"string\"}\n",
        "output_path = \"/content/output\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Google Drive Path Variables (Optional)**\n",
        "mount_google_drive = True #@param {type:\"boolean\"}\n",
        "force_remount = False\n",
        "\n",
        "if mount_google_drive:\n",
        "    from google.colab import drive # type: ignore\n",
        "    try:\n",
        "        drive_path = \"/content/drive\"\n",
        "        drive.mount(drive_path,force_remount=force_remount)\n",
        "        models_path_gdrive = \"/content/drive/MyDrive/AI/models\" #@param {type:\"string\"}\n",
        "        output_path_gdrive = \"/content/drive/MyDrive/AI/StableDiffusion\" #@param {type:\"string\"}\n",
        "        models_path = models_path_gdrive\n",
        "        output_path = output_path_gdrive\n",
        "    except:\n",
        "        print(\"...error mounting drive or with drive path variables\")\n",
        "        print(\"...reverting to default path variables\")\n",
        "\n",
        "import os\n",
        "os.makedirs(models_path, exist_ok=True)\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "print(f\"models_path: {models_path}\")\n",
        "print(f\"output_path: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7--2hBtrc4QN"
      },
      "outputs": [],
      "source": [
        "#@markdown **Setup Environment**\n",
        "\n",
        "setup_environment = True #@param {type:\"boolean\"}\n",
        "print_subprocess = True #@param {type:\"boolean\"}\n",
        "\n",
        "if setup_environment:\n",
        "    import subprocess, time\n",
        "    print(\"Setting up environment...\")\n",
        "    start_time = time.time()\n",
        "    all_process = [\n",
        "        ['pip', 'install', 'torch==1.12.1+cu113', 'torchvision==0.13.1+cu113', '--extra-index-url', 'https://download.pytorch.org/whl/cu113'],\n",
        "        ['pip', 'install', 'omegaconf==2.2.3', 'einops==0.4.1', 'pytorch-lightning==1.7.4', 'torchmetrics==0.9.3', 'torchtext==0.13.1', 'transformers==4.21.2', 'kornia==0.6.7'],\n",
        "        ['git', 'clone',  'https://github.com/deforum/stable-diffusion'],\n",
        "        ['pip', 'install', '-e', 'git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers'],\n",
        "        ['pip', 'install', '-e', 'git+https://github.com/openai/CLIP.git@main#egg=clip'],\n",
        "        ['pip', 'install', 'accelerate', 'ftfy', 'jsonmerge', 'matplotlib', 'resize-right', 'timm', 'torchdiffeq'],\n",
        "        ['pip', 'install', '--upgrade', 'diffusers'],\n",
        "        ['git', 'clone', 'https://github.com/shariqfarooq123/AdaBins.git'],\n",
        "        ['git', 'clone', 'https://github.com/isl-org/MiDaS.git'],\n",
        "        ['git', 'clone', 'https://github.com/MSFTserver/pytorch3d-lite.git'],\n",
        "    ]\n",
        "    for process in all_process:\n",
        "        running = subprocess.run(process,stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        if print_subprocess:\n",
        "            print(running)\n",
        "    \n",
        "    print(subprocess.run(['git', 'clone', 'https://github.com/deforum/k-diffusion/'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "    with open('k-diffusion/k_diffusion/__init__.py', 'w') as f:\n",
        "        f.write('')\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Environment set up in {end_time-start_time:.0f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NYpAYbTec4QP"
      },
      "outputs": [],
      "source": [
        "#@markdown **Python Definitions**\n",
        "import json\n",
        "from IPython import display\n",
        "\n",
        "import gc, math, os, pathlib, subprocess, sys, time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "from contextlib import contextmanager, nullcontext\n",
        "from einops import rearrange, repeat\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from pytorch_lightning import seed_everything\n",
        "from skimage.exposure import match_histograms\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm import tqdm, trange\n",
        "from types import SimpleNamespace\n",
        "from torch import autocast\n",
        "import re\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "sys.path.extend([\n",
        "    'src/taming-transformers',\n",
        "    'src/clip',\n",
        "    'stable-diffusion/',\n",
        "    'k-diffusion',\n",
        "    'pytorch3d-lite',\n",
        "    'AdaBins',\n",
        "    'MiDaS',\n",
        "])\n",
        "\n",
        "import py3d_tools as p3d\n",
        "\n",
        "from helpers import DepthModel, sampler_fn\n",
        "from k_diffusion.external import CompVisDenoiser\n",
        "from ldm.util import instantiate_from_config\n",
        "from ldm.models.diffusion.ddim import DDIMSampler\n",
        "from ldm.models.diffusion.plms import PLMSSampler\n",
        "from diffusers.models import AutoencoderKL\n",
        "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
        "\n",
        "def sanitize(prompt):\n",
        "    whitelist = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "    tmp = ''.join(filter(whitelist.__contains__, prompt))\n",
        "    return tmp.replace(' ', '_')\n",
        "\n",
        "from functools import reduce\n",
        "def construct_RotationMatrixHomogenous(rotation_angles):\n",
        "    assert(type(rotation_angles)==list and len(rotation_angles)==3)\n",
        "    RH = np.eye(4,4)\n",
        "    cv2.Rodrigues(np.array(rotation_angles), RH[0:3, 0:3])\n",
        "    return RH\n",
        "\n",
        "# https://en.wikipedia.org/wiki/Rotation_matrix\n",
        "def getRotationMatrixManual(rotation_angles):\n",
        "\t\n",
        "    rotation_angles = [np.deg2rad(x) for x in rotation_angles]\n",
        "    \n",
        "    phi         = rotation_angles[0] # around x\n",
        "    gamma       = rotation_angles[1] # around y\n",
        "    theta       = rotation_angles[2] # around z\n",
        "    \n",
        "    # X rotation\n",
        "    Rphi        = np.eye(4,4)\n",
        "    sp          = np.sin(phi)\n",
        "    cp          = np.cos(phi)\n",
        "    Rphi[1,1]   = cp\n",
        "    Rphi[2,2]   = Rphi[1,1]\n",
        "    Rphi[1,2]   = -sp\n",
        "    Rphi[2,1]   = sp\n",
        "    \n",
        "    # Y rotation\n",
        "    Rgamma        = np.eye(4,4)\n",
        "    sg            = np.sin(gamma)\n",
        "    cg            = np.cos(gamma)\n",
        "    Rgamma[0,0]   = cg\n",
        "    Rgamma[2,2]   = Rgamma[0,0]\n",
        "    Rgamma[0,2]   = sg\n",
        "    Rgamma[2,0]   = -sg\n",
        "    \n",
        "    # Z rotation (in-image-plane)\n",
        "    Rtheta      = np.eye(4,4)\n",
        "    st          = np.sin(theta)\n",
        "    ct          = np.cos(theta)\n",
        "    Rtheta[0,0] = ct\n",
        "    Rtheta[1,1] = Rtheta[0,0]\n",
        "    Rtheta[0,1] = -st\n",
        "    Rtheta[1,0] = st\n",
        "    \n",
        "    R           = reduce(lambda x,y : np.matmul(x,y), [Rphi, Rgamma, Rtheta]) \n",
        "    \n",
        "    return R\n",
        "\n",
        "\n",
        "def getPoints_for_PerspectiveTranformEstimation(ptsIn, ptsOut, W, H, sidelength):\n",
        "    \n",
        "    ptsIn2D      =  ptsIn[0,:]\n",
        "    ptsOut2D     =  ptsOut[0,:]\n",
        "    ptsOut2Dlist =  []\n",
        "    ptsIn2Dlist  =  []\n",
        "    \n",
        "    for i in range(0,4):\n",
        "        ptsOut2Dlist.append([ptsOut2D[i,0], ptsOut2D[i,1]])\n",
        "        ptsIn2Dlist.append([ptsIn2D[i,0], ptsIn2D[i,1]])\n",
        "    \n",
        "    pin  =  np.array(ptsIn2Dlist)   +  [W/2.,H/2.]\n",
        "    pout = (np.array(ptsOut2Dlist)  +  [1.,1.]) * (0.5*sidelength)\n",
        "    pin  = pin.astype(np.float32)\n",
        "    pout = pout.astype(np.float32)\n",
        "    \n",
        "    return pin, pout\n",
        "\n",
        "def warpMatrix(W, H, theta, phi, gamma, scale, fV):\n",
        "    \n",
        "    # M is to be estimated\n",
        "    M          = np.eye(4, 4)\n",
        "    \n",
        "    fVhalf     = np.deg2rad(fV/2.)\n",
        "    d          = np.sqrt(W*W+H*H)\n",
        "    sideLength = scale*d/np.cos(fVhalf)\n",
        "    h          = d/(2.0*np.sin(fVhalf))\n",
        "    n          = h-(d/2.0);\n",
        "    f          = h+(d/2.0);\n",
        "    \n",
        "    # Translation along Z-axis by -h\n",
        "    T       = np.eye(4,4)\n",
        "    T[2,3]  = -h\n",
        "    \n",
        "    # Rotation matrices around x,y,z\n",
        "    R = getRotationMatrixManual([phi, gamma, theta])\n",
        "    \n",
        "    \n",
        "    # Projection Matrix \n",
        "    P       = np.eye(4,4)\n",
        "    P[0,0]  = 1.0/np.tan(fVhalf)\n",
        "    P[1,1]  = P[0,0]\n",
        "    P[2,2]  = -(f+n)/(f-n)\n",
        "    P[2,3]  = -(2.0*f*n)/(f-n)\n",
        "    P[3,2]  = -1.0\n",
        "    \n",
        "    # pythonic matrix multiplication\n",
        "    F       = reduce(lambda x,y : np.matmul(x,y), [P, T, R]) \n",
        "    \n",
        "    # shape should be 1,4,3 for ptsIn and ptsOut since perspectiveTransform() expects data in this way. \n",
        "    # In C++, this can be achieved by Mat ptsIn(1,4,CV_64FC3);\n",
        "    ptsIn = np.array([[\n",
        "                 [-W/2., H/2., 0.],[ W/2., H/2., 0.],[ W/2.,-H/2., 0.],[-W/2.,-H/2., 0.]\n",
        "                 ]])\n",
        "    ptsOut  = np.array(np.zeros((ptsIn.shape), dtype=ptsIn.dtype))\n",
        "    ptsOut  = cv2.perspectiveTransform(ptsIn, F)\n",
        "    \n",
        "    ptsInPt2f, ptsOutPt2f = getPoints_for_PerspectiveTranformEstimation(ptsIn, ptsOut, W, H, sideLength)\n",
        "    \n",
        "    # check float32 otherwise OpenCV throws an error\n",
        "    assert(ptsInPt2f.dtype  == np.float32)\n",
        "    assert(ptsOutPt2f.dtype == np.float32)\n",
        "    M33 = cv2.getPerspectiveTransform(ptsInPt2f,ptsOutPt2f)\n",
        "\n",
        "    return M33, sideLength\n",
        "\n",
        "def anim_frame_warp_2d(prev_img_cv2, args, anim_args, keys, frame_idx):\n",
        "    angle = keys.angle_series[frame_idx]\n",
        "    zoom = keys.zoom_series[frame_idx]\n",
        "    translation_x = keys.translation_x_series[frame_idx]\n",
        "    translation_y = keys.translation_y_series[frame_idx]\n",
        "\n",
        "    center = (args.W // 2, args.H // 2)\n",
        "    trans_mat = np.float32([[1, 0, translation_x], [0, 1, translation_y]])\n",
        "    rot_mat = cv2.getRotationMatrix2D(center, angle, zoom)\n",
        "    trans_mat = np.vstack([trans_mat, [0,0,1]])\n",
        "    rot_mat = np.vstack([rot_mat, [0,0,1]])\n",
        "    if anim_args.flip_2d_perspective:\n",
        "        perspective_flip_theta = keys.perspective_flip_theta_series[frame_idx]\n",
        "        perspective_flip_phi = keys.perspective_flip_phi_series[frame_idx]\n",
        "        perspective_flip_gamma = keys.perspective_flip_gamma_series[frame_idx]\n",
        "        perspective_flip_fv = keys.perspective_flip_fv_series[frame_idx]\n",
        "        M,sl = warpMatrix(args.W, args.H, perspective_flip_theta, perspective_flip_phi, perspective_flip_gamma, 1., perspective_flip_fv);\n",
        "        post_trans_mat = np.float32([[1, 0, (args.W-sl)/2], [0, 1, (args.H-sl)/2]])\n",
        "        post_trans_mat = np.vstack([post_trans_mat, [0,0,1]])\n",
        "        bM = np.matmul(M, post_trans_mat)\n",
        "        xform = np.matmul(bM, rot_mat, trans_mat)\n",
        "    else:\n",
        "        xform = np.matmul(rot_mat, trans_mat)\n",
        "\n",
        "    return cv2.warpPerspective(\n",
        "        prev_img_cv2,\n",
        "        xform,\n",
        "        (prev_img_cv2.shape[1], prev_img_cv2.shape[0]),\n",
        "        borderMode=cv2.BORDER_WRAP if anim_args.border == 'wrap' else cv2.BORDER_REPLICATE\n",
        "    )\n",
        "\n",
        "def anim_frame_warp_3d(prev_img_cv2, depth, anim_args, keys, frame_idx):\n",
        "    TRANSLATION_SCALE = 1.0/200.0 # matches Disco\n",
        "    translate_xyz = [\n",
        "        -keys.translation_x_series[frame_idx] * TRANSLATION_SCALE, \n",
        "        keys.translation_y_series[frame_idx] * TRANSLATION_SCALE, \n",
        "        -keys.translation_z_series[frame_idx] * TRANSLATION_SCALE\n",
        "    ]\n",
        "    rotate_xyz = [\n",
        "        math.radians(keys.rotation_3d_x_series[frame_idx]), \n",
        "        math.radians(keys.rotation_3d_y_series[frame_idx]), \n",
        "        math.radians(keys.rotation_3d_z_series[frame_idx])\n",
        "    ]\n",
        "    rot_mat = p3d.euler_angles_to_matrix(torch.tensor(rotate_xyz, device=device), \"XYZ\").unsqueeze(0)\n",
        "    result = transform_image_3d(prev_img_cv2, depth, rot_mat, translate_xyz, anim_args)\n",
        "    torch.cuda.empty_cache()\n",
        "    return result\n",
        "\n",
        "def add_noise(sample: torch.Tensor, noise_amt: float) -> torch.Tensor:\n",
        "    return sample + torch.randn(sample.shape, device=sample.device) * noise_amt\n",
        "\n",
        "def get_output_folder(output_path, batch_folder):\n",
        "    out_path = os.path.join(output_path,time.strftime('%Y-%m'))\n",
        "    if batch_folder != \"\":\n",
        "        out_path = os.path.join(out_path, batch_folder)\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "    return out_path\n",
        "\n",
        "def load_img(path, shape, use_alpha_as_mask=False):\n",
        "    # use_alpha_as_mask: Read the alpha channel of the image as the mask image\n",
        "    if path.startswith('http://') or path.startswith('https://'):\n",
        "        image = Image.open(requests.get(path, stream=True).raw)\n",
        "    else:\n",
        "        image = Image.open(path)\n",
        "\n",
        "    if use_alpha_as_mask:\n",
        "        image = image.convert('RGBA')\n",
        "    else:\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "    image = image.resize(shape, resample=Image.LANCZOS)\n",
        "\n",
        "    mask_image = None\n",
        "    if use_alpha_as_mask:\n",
        "      # Split alpha channel into a mask_image\n",
        "      red, green, blue, alpha = Image.Image.split(image)\n",
        "      mask_image = alpha.convert('L')\n",
        "      image = image.convert('RGB')\n",
        "\n",
        "    image = np.array(image).astype(np.float16) / 255.0\n",
        "    image = image[None].transpose(0, 3, 1, 2)\n",
        "    image = torch.from_numpy(image)\n",
        "    image = 2.*image - 1.\n",
        "\n",
        "    return image, mask_image\n",
        "\n",
        "def load_mask_latent(mask_input, shape):\n",
        "    # mask_input (str or PIL Image.Image): Path to the mask image or a PIL Image object\n",
        "    # shape (list-like len(4)): shape of the image to match, usually latent_image.shape\n",
        "    \n",
        "    if isinstance(mask_input, str): # mask input is probably a file name\n",
        "        if mask_input.startswith('http://') or mask_input.startswith('https://'):\n",
        "            mask_image = Image.open(requests.get(mask_input, stream=True).raw).convert('RGBA')\n",
        "        else:\n",
        "            mask_image = Image.open(mask_input).convert('RGBA')\n",
        "    elif isinstance(mask_input, Image.Image):\n",
        "        mask_image = mask_input\n",
        "    else:\n",
        "        raise Exception(\"mask_input must be a PIL image or a file name\")\n",
        "\n",
        "    mask_w_h = (shape[-1], shape[-2])\n",
        "    mask = mask_image.resize(mask_w_h, resample=Image.LANCZOS)\n",
        "    mask = mask.convert(\"L\")\n",
        "    return mask\n",
        "\n",
        "def prepare_mask(mask_input, mask_shape, mask_brightness_adjust=1.0, mask_contrast_adjust=1.0):\n",
        "    # mask_input (str or PIL Image.Image): Path to the mask image or a PIL Image object\n",
        "    # shape (list-like len(4)): shape of the image to match, usually latent_image.shape\n",
        "    # mask_brightness_adjust (non-negative float): amount to adjust brightness of the iamge, \n",
        "    #     0 is black, 1 is no adjustment, >1 is brighter\n",
        "    # mask_contrast_adjust (non-negative float): amount to adjust contrast of the image, \n",
        "    #     0 is a flat grey image, 1 is no adjustment, >1 is more contrast\n",
        "    \n",
        "    mask = load_mask_latent(mask_input, mask_shape)\n",
        "\n",
        "    # Mask brightness/contrast adjustments\n",
        "    if mask_brightness_adjust != 1:\n",
        "        mask = TF.adjust_brightness(mask, mask_brightness_adjust)\n",
        "    if mask_contrast_adjust != 1:\n",
        "        mask = TF.adjust_contrast(mask, mask_contrast_adjust)\n",
        "\n",
        "    # Mask image to array\n",
        "    mask = np.array(mask).astype(np.float32) / 255.0\n",
        "    mask = np.tile(mask,(4,1,1))\n",
        "    mask = np.expand_dims(mask,axis=0)\n",
        "    mask = torch.from_numpy(mask)\n",
        "\n",
        "    if args.invert_mask:\n",
        "        mask = ( (mask - 0.5) * -1) + 0.5\n",
        "    \n",
        "    mask = np.clip(mask,0,1)\n",
        "    return mask\n",
        "\n",
        "def maintain_colors(prev_img, color_match_sample, mode):\n",
        "    if mode == 'Match Frame 0 RGB':\n",
        "        return match_histograms(prev_img, color_match_sample, multichannel=True)\n",
        "    elif mode == 'Match Frame 0 HSV':\n",
        "        prev_img_hsv = cv2.cvtColor(prev_img, cv2.COLOR_RGB2HSV)\n",
        "        color_match_hsv = cv2.cvtColor(color_match_sample, cv2.COLOR_RGB2HSV)\n",
        "        matched_hsv = match_histograms(prev_img_hsv, color_match_hsv, multichannel=True)\n",
        "        return cv2.cvtColor(matched_hsv, cv2.COLOR_HSV2RGB)\n",
        "    else: # Match Frame 0 LAB\n",
        "        prev_img_lab = cv2.cvtColor(prev_img, cv2.COLOR_RGB2LAB)\n",
        "        color_match_lab = cv2.cvtColor(color_match_sample, cv2.COLOR_RGB2LAB)\n",
        "        matched_lab = match_histograms(prev_img_lab, color_match_lab, multichannel=True)\n",
        "        return cv2.cvtColor(matched_lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "\n",
        "#\n",
        "# Callback functions\n",
        "#\n",
        "class SamplerCallback(object):\n",
        "    # Creates the callback function to be passed into the samplers for each step\n",
        "    def __init__(self, args, mask=None, init_latent=None, sigmas=None, sampler=None,\n",
        "                  verbose=False):\n",
        "        self.sampler_name = args.sampler\n",
        "        self.dynamic_threshold = args.dynamic_threshold\n",
        "        self.static_threshold = args.static_threshold\n",
        "        self.mask = mask\n",
        "        self.init_latent = init_latent \n",
        "        self.sigmas = sigmas\n",
        "        self.sampler = sampler\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.batch_size = args.n_samples\n",
        "        self.save_sample_per_step = args.save_sample_per_step\n",
        "        self.show_sample_per_step = args.show_sample_per_step\n",
        "        self.paths_to_image_steps = [os.path.join( args.outdir, f\"{args.timestring}_{index:02}_{args.seed}\") for index in range(args.n_samples) ]\n",
        "\n",
        "        if self.save_sample_per_step:\n",
        "            for path in self.paths_to_image_steps:\n",
        "                os.makedirs(path, exist_ok=True)\n",
        "\n",
        "        self.step_index = 0\n",
        "\n",
        "        self.noise = None\n",
        "        if init_latent is not None:\n",
        "            self.noise = torch.randn_like(init_latent, device=device)\n",
        "\n",
        "        self.mask_schedule = None\n",
        "        if sigmas is not None and len(sigmas) > 0:\n",
        "            self.mask_schedule, _ = torch.sort(sigmas/torch.max(sigmas))\n",
        "        elif len(sigmas) == 0:\n",
        "            self.mask = None # no mask needed if no steps (usually happens because strength==1.0)\n",
        "\n",
        "        if self.sampler_name in [\"plms\",\"ddim\"]: \n",
        "            if mask is not None:\n",
        "                assert sampler is not None, \"Callback function for stable-diffusion samplers requires sampler variable\"\n",
        "\n",
        "        if self.sampler_name in [\"plms\",\"ddim\"]: \n",
        "            # Callback function formated for compvis latent diffusion samplers\n",
        "            self.callback = self.img_callback_\n",
        "        else: \n",
        "            # Default callback function uses k-diffusion sampler variables\n",
        "            self.callback = self.k_callback_\n",
        "\n",
        "        self.verbose_print = print if verbose else lambda *args, **kwargs: None\n",
        "\n",
        "    def view_sample_step(self, latents, path_name_modifier=''):\n",
        "        if self.save_sample_per_step or self.show_sample_per_step:\n",
        "            samples = model.decode_first_stage(latents)\n",
        "            if self.save_sample_per_step:\n",
        "                fname = f'{path_name_modifier}_{self.step_index:05}.png'\n",
        "                for i, sample in enumerate(samples):\n",
        "                    sample = sample.double().cpu().add(1).div(2).clamp(0, 1)\n",
        "                    sample = torch.tensor(np.array(sample))\n",
        "                    grid = make_grid(sample, 4).cpu()\n",
        "                    TF.to_pil_image(grid).save(os.path.join(self.paths_to_image_steps[i], fname))\n",
        "            if self.show_sample_per_step:\n",
        "                print(path_name_modifier)\n",
        "                self.display_images(samples)\n",
        "        return\n",
        "\n",
        "    def display_images(self, images):\n",
        "        images = images.double().cpu().add(1).div(2).clamp(0, 1)\n",
        "        images = torch.tensor(np.array(images))\n",
        "        grid = make_grid(images, 4).cpu()\n",
        "        display.display(TF.to_pil_image(grid))\n",
        "        return\n",
        "\n",
        "    # The callback function is applied to the image at each step\n",
        "    def dynamic_thresholding_(self, img, threshold):\n",
        "        # Dynamic thresholding from Imagen paper (May 2022)\n",
        "        s = np.percentile(np.abs(img.cpu()), threshold, axis=tuple(range(1,img.ndim)))\n",
        "        s = np.max(np.append(s,1.0))\n",
        "        torch.clamp_(img, -1*s, s)\n",
        "        torch.FloatTensor.div_(img, s)\n",
        "\n",
        "    # Callback for samplers in the k-diffusion repo, called thus:\n",
        "    #   callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigmas[i], 'denoised': denoised})\n",
        "    def k_callback_(self, args_dict):\n",
        "        self.step_index = args_dict['i']\n",
        "        if self.dynamic_threshold is not None:\n",
        "            self.dynamic_thresholding_(args_dict['x'], self.dynamic_threshold)\n",
        "        if self.static_threshold is not None:\n",
        "            torch.clamp_(args_dict['x'], -1*self.static_threshold, self.static_threshold)\n",
        "        if self.mask is not None:\n",
        "            init_noise = self.init_latent + self.noise * args_dict['sigma']\n",
        "            is_masked = torch.logical_and(self.mask >= self.mask_schedule[args_dict['i']], self.mask != 0 )\n",
        "            new_img = init_noise * torch.where(is_masked,1,0) + args_dict['x'] * torch.where(is_masked,0,1)\n",
        "            args_dict['x'].copy_(new_img)\n",
        "\n",
        "        self.view_sample_step(args_dict['denoised'], \"x0_pred\")\n",
        "\n",
        "    # Callback for Compvis samplers\n",
        "    # Function that is called on the image (img) and step (i) at each step\n",
        "    def img_callback_(self, img, i):\n",
        "        self.step_index = i\n",
        "        # Thresholding functions\n",
        "        if self.dynamic_threshold is not None:\n",
        "            self.dynamic_thresholding_(img, self.dynamic_threshold)\n",
        "        if self.static_threshold is not None:\n",
        "            torch.clamp_(img, -1*self.static_threshold, self.static_threshold)\n",
        "        if self.mask is not None:\n",
        "            i_inv = len(self.sigmas) - i - 1\n",
        "            init_noise = self.sampler.stochastic_encode(self.init_latent, torch.tensor([i_inv]*self.batch_size).to(device), noise=self.noise)\n",
        "            is_masked = torch.logical_and(self.mask >= self.mask_schedule[i], self.mask != 0 )\n",
        "            new_img = init_noise * torch.where(is_masked,1,0) + img * torch.where(is_masked,0,1)\n",
        "            img.copy_(new_img)\n",
        "\n",
        "        self.view_sample_step(img, \"x\")\n",
        "\n",
        "def sample_from_cv2(sample: np.ndarray) -> torch.Tensor:\n",
        "    sample = ((sample.astype(float) / 255.0) * 2) - 1\n",
        "    sample = sample[None].transpose(0, 3, 1, 2).astype(np.float16)\n",
        "    sample = torch.from_numpy(sample)\n",
        "    return sample\n",
        "\n",
        "def sample_to_cv2(sample: torch.Tensor, type=np.uint8) -> np.ndarray:\n",
        "    sample_f32 = rearrange(sample.squeeze().cpu().numpy(), \"c h w -> h w c\").astype(np.float32)\n",
        "    sample_f32 = ((sample_f32 * 0.5) + 0.5).clip(0, 1)\n",
        "    sample_int8 = (sample_f32 * 255)\n",
        "    return sample_int8.astype(type)\n",
        "\n",
        "def transform_image_3d(prev_img_cv2, depth_tensor, rot_mat, translate, anim_args):\n",
        "    # adapted and optimized version of transform_image_3d from Disco Diffusion https://github.com/alembics/disco-diffusion \n",
        "    w, h = prev_img_cv2.shape[1], prev_img_cv2.shape[0]\n",
        "\n",
        "    aspect_ratio = float(w)/float(h)\n",
        "    near, far, fov_deg = anim_args.near_plane, anim_args.far_plane, anim_args.fov\n",
        "    persp_cam_old = p3d.FoVPerspectiveCameras(near, far, aspect_ratio, fov=fov_deg, degrees=True, device=device)\n",
        "    persp_cam_new = p3d.FoVPerspectiveCameras(near, far, aspect_ratio, fov=fov_deg, degrees=True, R=rot_mat, T=torch.tensor([translate]), device=device)\n",
        "\n",
        "    # range of [-1,1] is important to torch grid_sample's padding handling\n",
        "    y,x = torch.meshgrid(torch.linspace(-1.,1.,h,dtype=torch.float32,device=device),torch.linspace(-1.,1.,w,dtype=torch.float32,device=device))\n",
        "    z = torch.as_tensor(depth_tensor, dtype=torch.float32, device=device)\n",
        "    xyz_old_world = torch.stack((x.flatten(), y.flatten(), z.flatten()), dim=1)\n",
        "\n",
        "    xyz_old_cam_xy = persp_cam_old.get_full_projection_transform().transform_points(xyz_old_world)[:,0:2]\n",
        "    xyz_new_cam_xy = persp_cam_new.get_full_projection_transform().transform_points(xyz_old_world)[:,0:2]\n",
        "\n",
        "    offset_xy = xyz_new_cam_xy - xyz_old_cam_xy\n",
        "    # affine_grid theta param expects a batch of 2D mats. Each is 2x3 to do rotation+translation.\n",
        "    identity_2d_batch = torch.tensor([[1.,0.,0.],[0.,1.,0.]], device=device).unsqueeze(0)\n",
        "    # coords_2d will have shape (N,H,W,2).. which is also what grid_sample needs.\n",
        "    coords_2d = torch.nn.functional.affine_grid(identity_2d_batch, [1,1,h,w], align_corners=False)\n",
        "    offset_coords_2d = coords_2d - torch.reshape(offset_xy, (h,w,2)).unsqueeze(0)\n",
        "\n",
        "    image_tensor = rearrange(torch.from_numpy(prev_img_cv2.astype(np.float32)), 'h w c -> c h w').to(device)\n",
        "    new_image = torch.nn.functional.grid_sample(\n",
        "        image_tensor.add(1/512 - 0.0001).unsqueeze(0), \n",
        "        offset_coords_2d, \n",
        "        mode=anim_args.sampling_mode, \n",
        "        padding_mode=anim_args.padding_mode, \n",
        "        align_corners=False\n",
        "    )\n",
        "\n",
        "    # convert back to cv2 style numpy array\n",
        "    result = rearrange(\n",
        "        new_image.squeeze().clamp(0,255), \n",
        "        'c h w -> h w c'\n",
        "    ).cpu().numpy().astype(prev_img_cv2.dtype)\n",
        "    return result\n",
        "\n",
        "def check_is_number(value):\n",
        "    float_pattern = r'^(?=.)([+-]?([0-9]*)(\\.([0-9]+))?)$'\n",
        "    return re.match(float_pattern, value)\n",
        "\n",
        "# prompt weighting with colons and number coefficients (like 'bacon:0.75 eggs:0.25')\n",
        "# borrowed from https://github.com/kylewlacy/stable-diffusion/blob/0a4397094eb6e875f98f9d71193e350d859c4220/ldm/dream/conditioning.py\n",
        "# and https://github.com/raefu/stable-diffusion-automatic/blob/unstablediffusion/modules/processing.py\n",
        "def get_uc_and_c(prompts, model, args, frame = 0):\n",
        "    prompt = prompts[0] # they are the same in a batch anyway\n",
        "\n",
        "    # get weighted sub-prompts\n",
        "    negative_subprompts, positive_subprompts = split_weighted_subprompts(\n",
        "        prompt, frame, not args.normalize_prompt_weights\n",
        "    )\n",
        "\n",
        "    uc = get_learned_conditioning(model, negative_subprompts, \"\", args, -1)\n",
        "    c = get_learned_conditioning(model, positive_subprompts, prompt, args, 1)\n",
        "\n",
        "    return (uc, c)\n",
        "\n",
        "def get_learned_conditioning(model, weighted_subprompts, text, args, sign = 1):\n",
        "    if len(weighted_subprompts) < 1:\n",
        "        log_tokenization(text, model, args.log_weighted_subprompts, sign)\n",
        "        c = model.get_learned_conditioning(args.n_samples * [text])\n",
        "    else:\n",
        "        c = None\n",
        "        for subtext, subweight in weighted_subprompts:\n",
        "            log_tokenization(subtext, model, args.log_weighted_subprompts, sign * subweight)\n",
        "            if c is None:\n",
        "                c = model.get_learned_conditioning(args.n_samples * [subtext])\n",
        "                c *= subweight\n",
        "            else:\n",
        "                c.add_(model.get_learned_conditioning(args.n_samples * [subtext]), alpha=subweight)\n",
        "        \n",
        "    return c\n",
        "\n",
        "def parse_weight(match, frame = 0)->float:\n",
        "    import numexpr\n",
        "    w_raw = match.group(\"weight\")\n",
        "    if w_raw == None:\n",
        "        return 1\n",
        "    if check_is_number(w_raw):\n",
        "        return float(w_raw)\n",
        "    else:\n",
        "        t = frame\n",
        "        if len(w_raw) < 3:\n",
        "            print('the value inside `-characters cannot represent a math function')\n",
        "            return 1\n",
        "        return float(numexpr.evaluate(w_raw[1:-1]))\n",
        "\n",
        "def normalize_prompt_weights(parsed_prompts):\n",
        "    if len(parsed_prompts) == 0:\n",
        "        return parsed_prompts\n",
        "    weight_sum = sum(map(lambda x: x[1], parsed_prompts))\n",
        "    if weight_sum == 0:\n",
        "        print(\n",
        "            \"Warning: Subprompt weights add up to zero. Discarding and using even weights instead.\")\n",
        "        equal_weight = 1 / max(len(parsed_prompts), 1)\n",
        "        return [(x[0], equal_weight) for x in parsed_prompts]\n",
        "    return [(x[0], x[1] / weight_sum) for x in parsed_prompts]\n",
        "\n",
        "def split_weighted_subprompts(text, frame = 0, skip_normalize=False):\n",
        "    \"\"\"\n",
        "    grabs all text up to the first occurrence of ':'\n",
        "    uses the grabbed text as a sub-prompt, and takes the value following ':' as weight\n",
        "    if ':' has no value defined, defaults to 1.0\n",
        "    repeats until no text remaining\n",
        "    \"\"\"\n",
        "    prompt_parser = re.compile(\"\"\"\n",
        "            (?P<prompt>         # capture group for 'prompt'\n",
        "            (?:\\\\\\:|[^:])+      # match one or more non ':' characters or escaped colons '\\:'\n",
        "            )                   # end 'prompt'\n",
        "            (?:                 # non-capture group\n",
        "            :+                  # match one or more ':' characters\n",
        "            (?P<weight>((        # capture group for 'weight'\n",
        "            -?\\d+(?:\\.\\d+)?     # match positive or negative integer or decimal number\n",
        "            )|(                 # or\n",
        "            `[\\S\\s]*?`# a math function\n",
        "            )))?                 # end weight capture group, make optional\n",
        "            \\s*                 # strip spaces after weight\n",
        "            |                   # OR\n",
        "            $                   # else, if no ':' then match end of line\n",
        "            )                   # end non-capture group\n",
        "            \"\"\", re.VERBOSE)\n",
        "    negative_prompts = []\n",
        "    positive_prompts = []\n",
        "    for match in re.finditer(prompt_parser, text):\n",
        "        w = parse_weight(match, frame)\n",
        "        if w < 0:\n",
        "            # negating the sign as we'll feed this to uc\n",
        "            negative_prompts.append((match.group(\"prompt\").replace(\"\\\\:\", \":\"), -w))\n",
        "        elif w > 0:\n",
        "            positive_prompts.append((match.group(\"prompt\").replace(\"\\\\:\", \":\"), w))\n",
        "\n",
        "    if skip_normalize:\n",
        "        return (negative_prompts, positive_prompts)\n",
        "    return (normalize_prompt_weights(negative_prompts), normalize_prompt_weights(positive_prompts))\n",
        "\n",
        "# shows how the prompt is tokenized\n",
        "# usually tokens have '</w>' to indicate end-of-word,\n",
        "# but for readability it has been replaced with ' '\n",
        "def log_tokenization(text, model, log=False, weight=1):\n",
        "    if not log:\n",
        "        return\n",
        "    tokens    = model.cond_stage_model.tokenizer._tokenize(text)\n",
        "    tokenized = \"\"\n",
        "    discarded = \"\"\n",
        "    usedTokens = 0\n",
        "    totalTokens = len(tokens)\n",
        "    for i in range(0, totalTokens):\n",
        "        token = tokens[i].replace('</w>', ' ')\n",
        "        # alternate color\n",
        "        s = (usedTokens % 6) + 1\n",
        "        if i < model.cond_stage_model.max_length:\n",
        "            tokenized = tokenized + f\"\\x1b[0;3{s};40m{token}\"\n",
        "            usedTokens += 1\n",
        "        else:  # over max token length\n",
        "            discarded = discarded + f\"\\x1b[0;3{s};40m{token}\"\n",
        "    print(f\"\\n>> Tokens ({usedTokens}), Weight ({weight:.2f}):\\n{tokenized}\\x1b[0m\")\n",
        "    if discarded != \"\":\n",
        "        print(\n",
        "            f\">> Tokens Discarded ({totalTokens-usedTokens}):\\n{discarded}\\x1b[0m\"\n",
        "        )\n",
        "\n",
        "def generate(args, frame = 0, return_latent=False, return_sample=False, return_c=False):\n",
        "    seed_everything(args.seed)\n",
        "    os.makedirs(args.outdir, exist_ok=True)\n",
        "\n",
        "    sampler = PLMSSampler(model) if args.sampler == 'plms' else DDIMSampler(model)\n",
        "    model_wrap = CompVisDenoiser(model)\n",
        "    batch_size = args.n_samples\n",
        "    prompt = args.prompt\n",
        "    assert prompt is not None\n",
        "    data = [batch_size * [prompt]]\n",
        "    precision_scope = autocast if args.precision == \"autocast\" else nullcontext\n",
        "\n",
        "    init_latent = None\n",
        "    mask_image = None\n",
        "    init_image = None\n",
        "    if args.init_latent is not None:\n",
        "        init_latent = args.init_latent\n",
        "    elif args.init_sample is not None:\n",
        "        with precision_scope(\"cuda\"):\n",
        "            init_latent = model.get_first_stage_encoding(model.encode_first_stage(args.init_sample))\n",
        "    elif args.use_init and args.init_image != None and args.init_image != '':\n",
        "        init_image, mask_image = load_img(args.init_image, \n",
        "                                          shape=(args.W, args.H),  \n",
        "                                          use_alpha_as_mask=args.use_alpha_as_mask)\n",
        "        init_image = init_image.to(device)\n",
        "        init_image = repeat(init_image, '1 ... -> b ...', b=batch_size)\n",
        "        with precision_scope(\"cuda\"):\n",
        "            init_latent = model.get_first_stage_encoding(model.encode_first_stage(init_image))  # move to latent space        \n",
        "\n",
        "    if not args.use_init and args.strength > 0 and args.strength_0_no_init:\n",
        "        print(\"\\nNo init image, but strength > 0. Strength has been auto set to 0, since use_init is False.\")\n",
        "        print(\"If you want to force strength > 0 with no init, please set strength_0_no_init to False.\\n\")\n",
        "        args.strength = 0\n",
        "\n",
        "    # Mask functions\n",
        "    if args.use_mask:\n",
        "        assert args.mask_file is not None or mask_image is not None, \"use_mask==True: An mask image is required for a mask. Please enter a mask_file or use an init image with an alpha channel\"\n",
        "        assert args.use_init, \"use_mask==True: use_init is required for a mask\"\n",
        "        assert init_latent is not None, \"use_mask==True: An latent init image is required for a mask\"\n",
        "\n",
        "\n",
        "        mask = prepare_mask(args.mask_file if mask_image is None else mask_image, \n",
        "                            init_latent.shape, \n",
        "                            args.mask_contrast_adjust, \n",
        "                            args.mask_brightness_adjust)\n",
        "        \n",
        "        if (torch.all(mask == 0) or torch.all(mask == 1)) and args.use_alpha_as_mask:\n",
        "            raise Warning(\"use_alpha_as_mask==True: Using the alpha channel from the init image as a mask, but the alpha channel is blank.\")\n",
        "        \n",
        "        mask = mask.to(device)\n",
        "        mask = repeat(mask, '1 ... -> b ...', b=batch_size)\n",
        "    else:\n",
        "        mask = None\n",
        "\n",
        "    assert not ( (args.use_mask and args.overlay_mask) and (args.init_sample is None and init_image is None)), \"Need an init image when use_mask == True and overlay_mask == True\"\n",
        "        \n",
        "    t_enc = int((1.0-args.strength) * args.steps)\n",
        "\n",
        "    # Noise schedule for the k-diffusion samplers (used for masking)\n",
        "    k_sigmas = model_wrap.get_sigmas(args.steps)\n",
        "    k_sigmas = k_sigmas[len(k_sigmas)-t_enc-1:]\n",
        "\n",
        "    if args.sampler in ['plms','ddim']:\n",
        "        sampler.make_schedule(ddim_num_steps=args.steps, ddim_eta=args.ddim_eta, ddim_discretize='fill', verbose=False)\n",
        "\n",
        "    callback = SamplerCallback(args=args,\n",
        "                            mask=mask, \n",
        "                            init_latent=init_latent,\n",
        "                            sigmas=k_sigmas,\n",
        "                            sampler=sampler,\n",
        "                            verbose=False).callback  \n",
        "\n",
        "    results = []\n",
        "    with torch.no_grad():\n",
        "        with precision_scope(\"cuda\"):\n",
        "            with model.ema_scope():\n",
        "                for prompts in data:\n",
        "                    if isinstance(prompts, tuple):\n",
        "                        prompts = list(prompts)\n",
        "                    if args.prompt_weighting:\n",
        "                        uc, c = get_uc_and_c(prompts, model, args, frame)\n",
        "                    else:\n",
        "                        uc = model.get_learned_conditioning(batch_size * [\"\"])\n",
        "                        c = model.get_learned_conditioning(prompts)\n",
        "\n",
        "\n",
        "                    if args.scale == 1.0:\n",
        "                        uc = None\n",
        "                    if args.init_c != None:\n",
        "                        c = args.init_c\n",
        "\n",
        "                    if args.sampler in [\"klms\",\"dpm2\",\"dpm2_ancestral\",\"heun\",\"euler\",\"euler_ancestral\"]:\n",
        "                        samples = sampler_fn(\n",
        "                            c=c, \n",
        "                            uc=uc, \n",
        "                            args=args, \n",
        "                            model_wrap=model_wrap, \n",
        "                            init_latent=init_latent, \n",
        "                            t_enc=t_enc, \n",
        "                            device=device, \n",
        "                            cb=callback)\n",
        "                    else:\n",
        "                        # args.sampler == 'plms' or args.sampler == 'ddim':\n",
        "                        if init_latent is not None and args.strength > 0:\n",
        "                            z_enc = sampler.stochastic_encode(init_latent, torch.tensor([t_enc]*batch_size).to(device))\n",
        "                        else:\n",
        "                            z_enc = torch.randn([args.n_samples, args.C, args.H // args.f, args.W // args.f], device=device)\n",
        "                        if args.sampler == 'ddim':\n",
        "                            samples = sampler.decode(z_enc, \n",
        "                                                     c, \n",
        "                                                     t_enc, \n",
        "                                                     unconditional_guidance_scale=args.scale,\n",
        "                                                     unconditional_conditioning=uc,\n",
        "                                                     img_callback=callback)\n",
        "                        elif args.sampler == 'plms': # no \"decode\" function in plms, so use \"sample\"\n",
        "                            shape = [args.C, args.H // args.f, args.W // args.f]\n",
        "                            samples, _ = sampler.sample(S=args.steps,\n",
        "                                                            conditioning=c,\n",
        "                                                            batch_size=args.n_samples,\n",
        "                                                            shape=shape,\n",
        "                                                            verbose=False,\n",
        "                                                            unconditional_guidance_scale=args.scale,\n",
        "                                                            unconditional_conditioning=uc,\n",
        "                                                            eta=args.ddim_eta,\n",
        "                                                            x_T=z_enc,\n",
        "                                                            img_callback=callback)\n",
        "                        else:\n",
        "                            raise Exception(f\"Sampler {args.sampler} not recognised.\")\n",
        "\n",
        "                    \n",
        "                    if return_latent:\n",
        "                        results.append(samples.clone())\n",
        "\n",
        "                    x_samples = model.decode_first_stage(samples)\n",
        "\n",
        "                    if args.use_mask and args.overlay_mask:\n",
        "                        # Overlay the masked image after the image is generated\n",
        "                        if args.init_sample is not None:\n",
        "                            img_original = args.init_sample\n",
        "                        elif init_image is not None:\n",
        "                            img_original = init_image\n",
        "                        else:\n",
        "                            raise Exception(\"Cannot overlay the masked image without an init image to overlay\")\n",
        "\n",
        "                        mask_fullres = prepare_mask(args.mask_file if mask_image is None else mask_image, \n",
        "                                                    img_original.shape, \n",
        "                                                    args.mask_contrast_adjust, \n",
        "                                                    args.mask_brightness_adjust)\n",
        "                        mask_fullres = mask_fullres[:,:3,:,:]\n",
        "                        mask_fullres = repeat(mask_fullres, '1 ... -> b ...', b=batch_size)\n",
        "\n",
        "                        mask_fullres[mask_fullres < mask_fullres.max()] = 0\n",
        "                        mask_fullres = gaussian_filter(mask_fullres, args.mask_overlay_blur)\n",
        "                        mask_fullres = torch.Tensor(mask_fullres).to(device)\n",
        "\n",
        "                        x_samples = img_original * mask_fullres + x_samples * ((mask_fullres * -1.0) + 1)\n",
        "\n",
        "\n",
        "                    if return_sample:\n",
        "                        results.append(x_samples.clone())\n",
        "\n",
        "                    x_samples = torch.clamp((x_samples + 1.0) / 2.0, min=0.0, max=1.0)\n",
        "\n",
        "                    if return_c:\n",
        "                        results.append(c.clone())\n",
        "\n",
        "                    for x_sample in x_samples:\n",
        "                        x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n",
        "                        image = Image.fromarray(x_sample.astype(np.uint8))\n",
        "                        results.append(image)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oYfNMu9Sc4QS"
      },
      "outputs": [],
      "source": [
        "#@markdown **ORIGINAL Select and Load Model**\n",
        "\n",
        "model_config = \"v1-inference.yaml\" #@param [\"custom\",\"v1-inference.yaml\"]\n",
        "model_checkpoint =  \"custom\" #@param [\"custom\",\"v1-5-pruned\",\"sd-v1-4-full-ema.ckpt\",\"sd-v1-4.ckpt\",\"sd-v1-3-full-ema.ckpt\",\"sd-v1-3.ckpt\",\"sd-v1-2-full-ema.ckpt\",\"sd-v1-2.ckpt\",\"sd-v1-1-full-ema.ckpt\",\"sd-v1-1.ckpt\", \"robo-diffusion-v1.ckpt\",\"waifu-diffusion-v1-3.ckpt\"]\n",
        "if model_checkpoint == \"waifu-diffusion-v1-3.ckpt\":\n",
        "    model_checkpoint = \"model-epoch05-float16.ckpt\"\n",
        "custom_config_path = \"/content/drive/MyDrive/AI/models/vae-ft-mse-840000-ema-pruned.pt\" #@param {type:\"string\"}\n",
        "custom_checkpoint_path = \"/content/drive/MyDrive/AI/models/v1-5-pruned.ckpt\" #@param {type:\"string\"}\n",
        "custom_vae_path = \"/content/drive/MyDrive/AI/models/vae-ft-mse-840000-ema-pruned.ckpt\" #@param {type:\"string\"}\n",
        "\n",
        "load_on_run_all = True #@param {type: 'boolean'}\n",
        "half_precision = True # check\n",
        "check_sha256 = True #@param {type:\"boolean\"}\n",
        "\n",
        "model_map = {\n",
        "    \"sd-v1-4-full-ema.ckpt\": {\n",
        "        'sha256': '14749efc0ae8ef0329391ad4436feb781b402f4fece4883c7ad8d10556d8a36a',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-2-original/blob/main/sd-v1-4-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-4.ckpt\": {\n",
        "        'sha256': 'fe4efff1e174c627256e44ec2991ba279b3816e364b49f9be2abc0b3ff3f8556',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-3-full-ema.ckpt\": {\n",
        "        'sha256': '54632c6e8a36eecae65e36cb0595fab314e1a1545a65209f24fde221a8d4b2ca',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-3-original/blob/main/sd-v1-3-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-3.ckpt\": {\n",
        "        'sha256': '2cff93af4dcc07c3e03110205988ff98481e86539c51a8098d4f2236e41f7f2f',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-3-original/resolve/main/sd-v1-3.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-2-full-ema.ckpt\": {\n",
        "        'sha256': 'bc5086a904d7b9d13d2a7bccf38f089824755be7261c7399d92e555e1e9ac69a',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-2-original/blob/main/sd-v1-2-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-2.ckpt\": {\n",
        "        'sha256': '3b87d30facd5bafca1cbed71cfb86648aad75d1c264663c0cc78c7aea8daec0d',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-2-original/resolve/main/sd-v1-2.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-1-full-ema.ckpt\": {\n",
        "        'sha256': 'efdeb5dc418a025d9a8cc0a8617e106c69044bc2925abecc8a254b2910d69829',\n",
        "        'url':'https://huggingface.co/CompVis/stable-diffusion-v-1-1-original/resolve/main/sd-v1-1-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-1.ckpt\": {\n",
        "        'sha256': '86cd1d3ccb044d7ba8db743d717c9bac603c4043508ad2571383f954390f3cea',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-1-original/resolve/main/sd-v1-1.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"vae-ft-mse-840000-ema-pruned.ckpt\": {\n",
        "        'sha256': 'c6a580b13a5bc05a5e16e4dbb80608ff2ec251a162311590c1f34c013d7f3dab',\n",
        "        'url': 'https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt',\n",
        "        'requires_login': False,\n",
        "        },    \n",
        "    \"robo-diffusion-v1.ckpt\": {\n",
        "        'sha256': '244dbe0dcb55c761bde9c2ac0e9b46cc9705ebfe5f1f3a7cc46251573ea14e16',\n",
        "        'url': 'https://huggingface.co/nousr/robo-diffusion/resolve/main/models/robo-diffusion-v1.ckpt',\n",
        "        'requires_login': False,\n",
        "        },\n",
        "    \"model-epoch05-float16.ckpt\": {\n",
        "        'sha256': '26cf2a2e30095926bb9fd9de0c83f47adc0b442dbfdc3d667d43778e8b70bece',\n",
        "        'url': 'https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/model-epoch05-float16.ckpt',\n",
        "        'requires_login': False,\n",
        "        },\n",
        "}\n",
        "\n",
        "# config path\n",
        "ckpt_config_path = custom_config_path if model_config == \"custom\" else os.path.join(models_path, model_config)\n",
        "if os.path.exists(ckpt_config_path):\n",
        "    print(f\"{ckpt_config_path} exists\")\n",
        "else:\n",
        "    ckpt_config_path = \"./stable-diffusion/configs/stable-diffusion/v1-inference.yaml\"\n",
        "print(f\"Using config: {ckpt_config_path}\")\n",
        "\n",
        "# checkpoint path or download\n",
        "ckpt_path = custom_checkpoint_path if model_checkpoint == \"custom\" else os.path.join(models_path, model_checkpoint)\n",
        "ckpt_valid = True\n",
        "if os.path.exists(ckpt_path):\n",
        "    print(f\"{ckpt_path} exists\")\n",
        "elif 'url' in model_map[model_checkpoint]:\n",
        "    url = model_map[model_checkpoint]['url']\n",
        "\n",
        "vae_path = custom_vae_path if model_checkpoint == \"custom\" else os.path.join(models_path, model_checkpoint)\n",
        "ckpt_valid = True\n",
        "if os.path.exists(vae_path):\n",
        "    print(f\"{vae_path} exists\")\n",
        "elif 'url' in model_map[model_checkpoint]:\n",
        "    url = model_map[model_checkpoint]['url']\n",
        "\n",
        "    # CLI dialogue to authenticate download\n",
        "    if model_map[model_checkpoint]['requires_login']:\n",
        "        print(\"This model requires an authentication token\")\n",
        "        print(\"Please ensure you have accepted its terms of service before continuing.\")\n",
        "\n",
        "        username = input(\"What is your huggingface username?:\")\n",
        "        token = input(\"What is your huggingface token?:\")\n",
        "\n",
        "        _, path = url.split(\"https://\")\n",
        "\n",
        "        url = f\"https://{username}:{token}@{path}\"\n",
        "\n",
        "    # contact server for model\n",
        "    print(f\"Attempting to download {model_checkpoint}...this may take a while\")\n",
        "    ckpt_request = requests.get(url)\n",
        "    request_status = ckpt_request.status_code\n",
        "\n",
        "    # inform user of errors\n",
        "    if request_status == 403:\n",
        "      raise ConnectionRefusedError(\"You have not accepted the license for this model.\")\n",
        "    elif request_status == 404:\n",
        "      raise ConnectionError(\"Could not make contact with server\")\n",
        "    elif request_status != 200:\n",
        "      raise ConnectionError(f\"Some other error has ocurred - response code: {request_status}\")\n",
        "\n",
        "    # write to model path\n",
        "    with open(os.path.join(models_path, model_checkpoint), 'wb') as model_file:\n",
        "        model_file.write(ckpt_request.content)\n",
        "else:\n",
        "    print(f\"Please download model checkpoint and place in {os.path.join(models_path, model_checkpoint)}\")\n",
        "    ckpt_valid = False\n",
        "\n",
        "if check_sha256 and model_checkpoint != \"custom\" and ckpt_valid:\n",
        "    import hashlib\n",
        "    print(\"\\n...checking sha256\")\n",
        "    with open(ckpt_path, \"rb\") as f:\n",
        "        bytes = f.read() \n",
        "        hash = hashlib.sha256(bytes).hexdigest()\n",
        "        del bytes\n",
        "    if model_map[model_checkpoint][\"sha256\"] == hash:\n",
        "        print(\"hash is correct\\n\")\n",
        "    else:\n",
        "        print(\"hash in not correct\\n\")\n",
        "        ckpt_valid = False\n",
        "\n",
        "if ckpt_valid:\n",
        "    print(f\"Using ckpt: {ckpt_path}\")\n",
        "\n",
        "def load_model_from_config(config, ckpt, verbose=False, device='cuda', half_precision=True):\n",
        "    map_location = \"cuda\" #@param [\"cpu\", \"cuda\"]\n",
        "    print(f\"Loading model from {ckpt}\")\n",
        "    pl_sd = torch.load(ckpt, map_location=map_location)\n",
        "    if \"global_step\" in pl_sd:\n",
        "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
        "    sd = pl_sd[\"state_dict\"]\n",
        "    model = instantiate_from_config(config.model)\n",
        "    m, u = model.load_state_dict(sd, strict=False)\n",
        "    if len(m) > 0 and verbose:\n",
        "        print(\"missing keys:\")\n",
        "        print(m)\n",
        "    if len(u) > 0 and verbose:\n",
        "        print(\"unexpected keys:\")\n",
        "        print(u)\n",
        "\n",
        "    if half_precision:\n",
        "        model = model.half().to(device)\n",
        "    else:\n",
        "        model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def load_vae_from_config(config, vae, verbose=False, device='cuda'):\n",
        "    map_location = \"cuda\" #@param [\"cpu\", \"cuda\"]\n",
        "    print(f\"Loading vae from {vae}\")\n",
        "    pl_sd = torch.load(vae, map_location=map_location)\n",
        "    if \"global_step\" in pl_sd:\n",
        "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
        "    sd = pl_sd[\"state_dict\"]\n",
        "    vae = instantiate_from_config(config.model)\n",
        "    m, u = vae.load_state_dict(sd, strict=False)\n",
        "    if len(m) > 0 and verbose:\n",
        "        print(\"missing keys:\")\n",
        "        print(m)\n",
        "    if len(u) > 0 and verbose:\n",
        "        print(\"unexpected keys:\")\n",
        "        print(u)\n",
        "        vae = vae.to(device)\n",
        "    vae.eval()\n",
        "    return vae\n",
        "\n",
        "if load_on_run_all and ckpt_valid:\n",
        "    local_config = OmegaConf.load(f\"{ckpt_config_path}\")\n",
        "    vae = load_vae_from_config(local_config, f\"{vae_path}\")\n",
        "    vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\")\n",
        "    model = load_model_from_config(local_config, f\"{ckpt_path}\", f\"{vae}\", half_precision=half_precision)\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "#if ckpt_valid:\n",
        "    #local_config = OmegaConf.load(f\"{ckpt_config_path}\")\n",
        "    #vae = AutoencoderKL.from_pretrained(\"/content/drive/MyDrive/AI/models/vae-ft-mse-840000-ema-pruned.ckpt\")\n",
        "    #model = load_model_from_config(local_config, f\"{ckpt_path}\", half_precision=half_precision)\n",
        "    #device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    #model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOf2K0Qec4QT"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtuXdJi6c4QU"
      },
      "source": [
        "### Animation Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HgItBbLUc4QV"
      },
      "outputs": [],
      "source": [
        "def DeforumAnimArgs():\n",
        "\n",
        "    #@markdown ####**Animation:**\n",
        "    animation_mode = '3D' #@param ['None', '2D', '3D', 'Video Input', 'Interpolation'] {type:'string'}\n",
        "    max_frames = 4500 #@param {type:\"number\"}\n",
        "    border = 'wrap' #@param ['wrap', 'replicate'] {type:'string'}\n",
        "\n",
        "    #@markdown ####**Motion Parameters:**\n",
        "    angle = \"0:(0)\"#@param {type:\"string\"}\n",
        "    zoom = \"0:(1.04)\"#@param {type:\"string\"}\n",
        "    translation_x = \"0:(2*sin(2*3.14*t/216))\"#@param {type:\"string\"}\n",
        "    translation_y = \"0:(0)\"#@param {type:\"string\"}\n",
        "    translation_z = \"0: (1.00), 1: (10.02), 2: (10.69), 3: (10.73), 4: (10.95), 5: (10.20), 6: (10.46), 7: (10.17), 8: (10.48), 9: (10.55), 10: (10.99), 11: (11.00), 12: (10.39), 13: (10.12), 14: (10.37), 15: (10.52), 16: (10.78), 17: (10.34), 18: (10.30), 19: (10.16), 20: (10.44), 21: (10.22), 22: (10.47), 23: (10.63), 24: (10.38), 25: (10.21), 26: (10.47), 27: (10.39), 28: (10.59), 29: (10.17), 30: (10.33), 31: (10.09), 32: (10.53), 33: (10.30), 34: (10.73), 35: (10.35), 36: (10.51), 37: (10.10), 38: (10.33), 39: (10.08), 40: (10.74), 41: (10.73), 42: (10.52), 43: (10.31), 44: (10.11), 45: (10.07), 46: (10.49), 47: (10.37), 48: (10.64), 49: (10.24), 50: (10.31), 51: (10.15), 52: (10.34), 53: (10.35), 54: (10.77), 55: (10.31), 56: (10.19), 57: (10.03), 58: (10.40), 59: (10.34), 60: (10.68), 61: (10.23), 62: (10.58), 63: (10.22), 64: (10.51), 65: (10.33), 66: (10.53), 67: (10.22), 68: (10.45), 69: (10.15), 70: (10.36), 71: (10.13), 72: (10.20), 73: (10.26), 74: (10.49), 75: (10.29), 76: (10.24), 77: (10.08), 78: (10.44), 79: (10.48), 80: (10.79), 81: (10.29), 82: (10.45), 83: (10.40), 84: (10.47), 85: (10.29), 86: (10.64), 87: (10.44), 88: (10.18), 89: (10.06), 90: (10.39), 91: (10.42), 92: (10.45), 93: (10.27), 94: (10.50), 95: (10.24), 96: (10.51), 97: (10.35), 98: (10.89), 99: (10.76), 100: (10.45), 101: (10.19), 102: (10.40), 103: (10.25), 104: (10.28), 105: (10.16), 106: (10.66), 107: (10.56), 108: (10.28), 109: (10.09), 110: (10.52), 111: (10.55), 112: (10.63), 113: (10.24), 114: (10.46), 115: (10.43), 116: (10.43), 117: (10.29), 118: (10.79), 119: (10.40), 120: (10.15), 121: (10.04), 122: (10.41), 123: (10.35), 124: (10.53), 125: (10.25), 126: (10.35), 127: (10.24), 128: (10.44), 129: (10.22), 130: (10.56), 131: (10.36), 132: (10.49), 133: (10.23), 134: (10.30), 135: (10.20), 136: (10.39), 137: (10.56), 138: (10.60), 139: (10.23), 140: (10.08), 141: (10.05), 142: (10.33), 143: (10.28), 144: (10.49), 145: (10.26), 146: (10.31), 147: (10.17), 148: (10.35), 149: (10.18), 150: (10.53), 151: (10.33), 152: (10.14), 153: (10.09), 154: (10.37), 155: (10.34), 156: (10.39), 157: (10.26), 158: (10.37), 159: (10.19), 160: (10.16), 161: (10.09), 162: (10.43), 163: (10.34), 164: (10.39), 165: (10.09), 166: (10.21), 167: (10.47), 168: (10.42), 169: (10.12), 170: (10.33), 171: (10.21), 172: (10.13), 173: (10.06), 174: (10.36), 175: (10.34), 176: (10.31), 177: (10.24), 178: (10.13), 179: (10.27), 180: (10.34), 181: (10.18), 182: (10.33), 183: (10.25), 184: (10.09), 185: (10.08), 186: (10.38), 187: (10.25), 188: (10.55), 189: (10.16), 190: (10.36), 191: (10.17), 192: (10.15), 193: (10.12), 194: (10.32), 195: (10.47), 196: (10.46), 197: (10.19), 198: (10.28), 199: (10.09), 200: (10.48), 201: (10.18), 202: (10.28), 203: (10.38), 204: (10.17), 205: (10.03), 206: (10.30), 207: (10.43), 208: (10.41), 209: (10.13), 210: (10.17), 211: (10.18), 212: (10.29), 213: (10.26), 214: (10.38), 215: (10.20), 216: (10.13), 217: (10.15), 218: (10.36), 219: (10.24), 220: (10.38), 221: (10.17), 222: (10.39), 223: (10.07), 224: (10.13), 225: (10.12), 226: (10.34), 227: (10.24), 228: (10.32), 229: (10.10), 230: (10.16), 231: (10.16), 232: (10.25), 233: (10.10), 234: (10.28), 235: (10.48), 236: (10.11), 237: (10.02), 238: (10.23), 239: (10.27), 240: (10.26), 241: (10.19), 242: (10.07), 243: (10.26), 244: (10.33), 245: (10.20), 246: (10.26), 247: (10.27), 248: (10.12), 249: (10.06), 250: (10.46), 251: (10.22), 252: (10.52), 253: (10.23), 254: (10.45), 255: (10.27), 256: (10.39), 257: (10.32), 258: (10.22), 259: (10.14), 260: (10.27), 261: (10.20), 262: (10.18), 263: (10.05), 264: (10.14), 265: (10.06), 266: (10.18), 267: (10.15), 268: (10.05), 269: (10.01), 270: (10.18), 271: (10.23), 272: (10.35), 273: (10.18), 274: (10.09), 275: (10.05), 276: (10.09), 277: (10.08), 278: (10.12), 279: (10.13), 280: (10.05), 281: (10.01), 282: (10.32), 283: (10.33), 284: (10.17), 285: (10.17), 286: (10.25), 287: (10.09), 288: (10.40), 289: (10.10), 290: (10.43), 291: (10.41), 292: (10.74), 293: (10.14), 294: (10.20), 295: (10.15), 296: (10.19), 297: (10.09), 298: (10.25), 299: (10.29), 300: (10.11), 301: (10.05), 302: (10.16), 303: (10.21), 304: (10.40), 305: (10.23), 306: (10.16), 307: (10.07), 308: (10.22), 309: (10.37), 310: (10.76), 311: (10.18), 312: (10.22), 313: (10.13), 314: (10.34), 315: (10.25), 316: (10.20), 317: (10.05), 318: (10.17), 319: (10.07), 320: (10.20), 321: (10.10), 322: (10.38), 323: (10.55), 324: (10.52), 325: (10.06), 326: (10.13), 327: (10.18), 328: (10.22), 329: (10.05), 330: (10.22), 331: (10.07), 332: (10.03), 333: (10.01), 334: (10.17), 335: (10.33), 336: (10.32), 337: (10.07), 338: (10.11), 339: (10.11), 340: (10.22), 341: (10.17), 342: (10.20), 343: (10.15), 344: (10.06), 345: (10.10), 346: (10.37), 347: (10.17), 348: (10.14), 349: (10.09), 350: (10.13), 351: (10.06), 352: (10.15), 353: (10.11), 354: (10.38), 355: (10.53), 356: (10.75), 357: (10.17), 358: (10.29), 359: (10.14), 360: (10.22), 361: (10.21), 362: (10.14), 363: (10.29), 364: (10.19), 365: (10.09), 366: (10.35), 367: (10.36), 368: (10.50), 369: (10.84), 370: (10.62), 371: (10.33), 372: (10.20), 373: (10.23), 374: (10.31), 375: (10.08), 376: (10.04), 377: (10.02), 378: (10.01), 379: (1.00), 380: (10.01), 381: (1.00), 382: (10.01), 383: (1.00), 384: (10.01), 385: (1.00), 386: (10.10), 387: (10.11), 388: (10.22), 389: (10.14), 390: (10.20), 391: (10.15), 392: (10.34), 393: (10.05), 394: (10.11), 395: (10.04), 396: (10.04), 397: (10.08), 398: (10.18), 399: (10.16), 400: (10.17), 401: (10.02), 402: (10.25), 403: (10.10), 404: (10.20), 405: (10.08), 406: (10.22), 407: (10.11), 408: (10.07), 409: (10.02), 410: (10.19), 411: (10.25), 412: (10.24), 413: (10.06), 414: (10.19), 415: (10.12), 416: (10.10), 417: (10.03), 418: (10.21), 419: (10.08), 420: (10.26), 421: (10.10), 422: (10.16), 423: (10.16), 424: (10.18), 425: (10.12), 426: (10.11), 427: (10.08), 428: (10.02), 429: (1.00), 430: (10.25), 431: (10.20), 432: (10.18), 433: (10.05), 434: (10.19), 435: (10.19), 436: (10.18), 437: (10.07), 438: (10.15), 439: (10.18), 440: (10.03), 441: (10.01), 442: (10.13), 443: (10.22), 444: (10.29), 445: (10.05), 446: (10.23), 447: (10.13), 448: (10.14), 449: (10.04), 450: (10.17), 451: (10.18), 452: (10.32), 453: (10.04), 454: (10.15), 455: (10.25), 456: (10.23), 457: (10.08), 458: (10.12), 459: (10.04), 460: (10.02), 461: (10.01), 462: (10.15), 463: (10.18), 464: (10.23), 465: (10.06), 466: (10.24), 467: (10.14), 468: (10.18), 469: (10.06), 470: (10.21), 471: (10.12), 472: (10.03), 473: (10.04), 474: (10.19), 475: (10.09), 476: (10.21), 477: (10.09), 478: (10.21), 479: (10.11), 480: (10.10), 481: (10.03), 482: (10.14), 483: (10.09), 484: (10.15), 485: (10.02), 486: (10.11), 487: (10.11), 488: (10.09), 489: (10.04), 490: (10.10), 491: (10.05), 492: (10.02), 493: (10.06), 494: (10.17), 495: (10.11), 496: (10.18), 497: (10.04), 498: (10.18), 499: (10.19), 500: (10.21), 501: (10.05), 502: (10.13), 503: (10.06), 504: (10.09), 505: (10.04), 506: (10.08), 507: (10.04), 508: (10.08), 509: (10.02), 510: (10.05), 511: (10.01), 512: (10.07), 513: (10.01), 514: (10.26), 515: (10.10), 516: (10.27), 517: (10.05), 518: (10.28), 519: (10.09), 520: (10.24), 521: (10.03), 522: (10.14), 523: (10.05), 524: (10.04), 525: (10.05), 526: (10.22), 527: (10.13), 528: (10.18), 529: (10.04), 530: (10.16), 531: (10.08), 532: (10.13), 533: (10.06), 534: (10.20), 535: (10.19), 536: (10.02), 537: (10.01), 538: (10.12), 539: (10.09), 540: (10.15), 541: (10.06), 542: (10.18), 543: (10.21), 544: (10.03), 545: (10.03), 546: (10.10), 547: (10.19), 548: (10.09), 549: (10.04), 550: (10.14), 551: (10.13), 552: (10.03), 553: (10.23), 554: (10.09), 555: (10.05), 556: (10.01), 557: (1.00), 558: (10.17), 559: (10.12), 560: (10.20), 561: (10.02), 562: (10.15), 563: (10.15), 564: (10.18), 565: (10.07), 566: (10.18), 567: (10.16), 568: (10.05), 569: (10.05), 570: (10.18), 571: (10.14), 572: (10.12), 573: (10.07), 574: (10.11), 575: (10.10), 576: (10.06), 577: (10.05), 578: (10.12), 579: (10.14), 580: (10.13), 581: (10.03), 582: (10.14), 583: (10.24), 584: (10.13), 585: (10.11), 586: (10.12), 587: (10.08), 588: (10.02), 589: (10.02), 590: (10.12), 591: (10.31), 592: (10.14), 593: (10.11), 594: (10.15), 595: (10.35), 596: (10.23), 597: (10.08), 598: (10.19), 599: (10.11), 600: (10.01), 601: (1.00), 602: (10.10), 603: (10.15), 604: (10.17), 605: (10.11), 606: (10.26), 607: (10.10), 608: (10.08), 609: (10.03), 610: (10.12), 611: (10.12), 612: (10.24), 613: (10.01), 614: (10.17), 615: (10.06), 616: (10.11), 617: (10.06), 618: (10.11), 619: (10.06), 620: (10.01), 621: (1.00), 622: (10.23), 623: (10.07), 624: (10.10), 625: (10.01), 626: (10.21), 627: (10.05), 628: (10.13), 629: (10.05), 630: (10.15), 631: (10.04), 632: (10.11), 633: (10.03), 634: (10.10), 635: (10.04), 636: (10.09), 637: (10.03), 638: (10.09), 639: (10.04), 640: (10.09), 641: (10.03), 642: (10.11), 643: (10.11), 644: (10.04), 645: (10.03), 646: (10.02), 647: (10.02), 648: (10.01), 649: (10.01), 650: (10.11), 651: (10.07), 652: (10.01), 653: (1.00), 654: (1.00), 655: (10.01), 656: (1.00), 657: (1.00), 658: (10.17), 659: (10.05), 660: (10.01), 661: (1.00), 662: (1.00), 663: (1.00), 664: (1.00), 665: (1.00), 666: (10.15), 667: (10.07), 668: (10.01), 669: (1.00), 670: (1.00), 671: (1.00), 672: (10.01), 673: (1.00), 674: (10.06), 675: (10.14), 676: (10.01), 677: (1.00), 678: (1.00), 679: (1.00), 680: (1.00), 681: (1.00), 682: (10.09), 683: (10.07), 684: (10.01), 685: (1.00), 686: (1.00), 687: (1.00), 688: (1.00), 689: (1.00), 690: (10.01), 691: (10.11), 692: (1.00), 693: (1.00), 694: (1.00), 695: (1.00), 696: (1.00), 697: (1.00), 698: (10.08), 699: (10.09), 700: (10.01), 701: (1.00), 702: (1.00), 703: (1.00), 704: (1.00), 705: (1.00), 706: (10.14), 707: (10.08), 708: (10.01), 709: (10.01), 710: (1.00), 711: (1.00), 712: (1.00), 713: (10.01), 714: (10.09), 715: (10.06), 716: (10.01), 717: (1.00), 718: (1.00), 719: (1.00), 720: (1.00), 721: (1.00), 722: (10.12), 723: (10.08), 724: (1.00), 725: (1.00), 726: (1.00), 727: (1.00), 728: (1.00), 729: (1.00), 730: (10.14), 731: (10.10), 732: (10.01), 733: (1.00), 734: (1.00), 735: (1.00), 736: (1.00), 737: (1.00), 738: (10.03), 739: (10.14), 740: (10.01), 741: (1.00), 742: (1.00), 743: (1.00), 744: (1.00), 745: (1.00), 746: (10.08), 747: (10.09), 748: (10.01), 749: (1.00), 750: (1.00), 751: (1.00), 752: (1.00), 753: (1.00), 754: (10.05), 755: (10.11), 756: (1.00), 757: (1.00), 758: (10.01), 759: (10.04), 760: (10.01), 761: (1.00), 762: (10.06), 763: (10.10), 764: (10.01), 765: (1.00), 766: (10.01), 767: (10.01), 768: (1.00), 769: (1.00), 770: (10.11), 771: (10.09), 772: (10.04), 773: (10.03), 774: (10.02), 775: (10.03), 776: (10.01), 777: (1.00), 778: (10.04), 779: (10.05), 780: (10.01), 781: (1.00), 782: (1.00), 783: (1.00), 784: (1.00), 785: (1.00), 786: (10.08), 787: (10.05), 788: (1.00), 789: (1.00), 790: (1.00), 791: (1.00), 792: (1.00), 793: (1.00), 794: (10.09), 795: (10.10), 796: (10.01), 797: (1.00), 798: (1.00), 799: (1.00), 800: (10.01), 801: (10.01), 802: (10.13), 803: (10.06), 804: (10.01), 805: (10.01), 806: (10.01), 807: (10.01), 808: (1.00), 809: (1.00), 810: (10.04), 811: (10.11), 812: (10.01), 813: (1.00), 814: (1.00), 815: (1.00), 816: (10.01), 817: (10.01), 818: (10.06), 819: (10.13), 820: (10.01), 821: (10.01), 822: (1.00), 823: (10.01), 824: (1.00), 825: (1.00), 826: (10.04), 827: (10.10), 828: (10.02), 829: (1.00), 830: (1.00), 831: (1.00), 832: (1.00), 833: (1.00), 834: (10.02), 835: (10.16), 836: (1.00), 837: (1.00), 838: (1.00), 839: (1.00), 840: (10.01), 841: (10.02), 842: (10.03), 843: (10.15), 844: (10.01), 845: (1.00), 846: (1.00), 847: (1.00), 848: (10.01), 849: (1.00), 850: (10.04), 851: (10.13), 852: (1.00), 853: (1.00), 854: (1.00), 855: (10.01), 856: (1.00), 857: (1.00), 858: (10.05), 859: (10.14), 860: (10.02), 861: (1.00), 862: (1.00), 863: (1.00), 864: (1.00), 865: (1.00), 866: (10.07), 867: (10.08), 868: (10.01), 869: (1.00), 870: (1.00), 871: (1.00), 872: (1.00), 873: (1.00), 874: (10.05), 875: (10.15), 876: (10.02), 877: (1.00), 878: (1.00), 879: (1.00), 880: (10.01), 881: (1.00), 882: (10.02), 883: (10.12), 884: (10.01), 885: (10.01), 886: (10.04), 887: (10.10), 888: (10.03), 889: (10.02), 890: (10.12), 891: (10.08), 892: (10.10), 893: (10.05), 894: (10.11), 895: (10.05), 896: (10.09), 897: (10.03), 898: (10.09), 899: (10.14), 900: (10.07), 901: (10.06), 902: (10.04), 903: (10.04), 904: (10.03), 905: (10.02), 906: (10.10), 907: (10.10), 908: (10.03), 909: (10.01), 910: (10.01), 911: (10.01), 912: (1.00), 913: (1.00), 914: (10.13), 915: (10.03), 916: (10.01), 917: (1.00), 918: (1.00), 919: (10.01), 920: (1.00), 921: (1.00), 922: (10.04), 923: (10.11), 924: (10.02), 925: (10.01), 926: (10.01), 927: (10.01), 928: (10.01), 929: (1.00), 930: (10.04), 931: (10.10), 932: (10.01), 933: (1.00), 934: (1.00), 935: (1.00), 936: (1.00), 937: (1.00), 938: (10.05), 939: (10.07), 940: (10.04), 941: (10.05), 942: (10.01), 943: (10.01), 944: (1.00), 945: (10.01), 946: (10.05), 947: (10.10), 948: (10.01), 949: (1.00), 950: (1.00), 951: (10.01), 952: (1.00), 953: (1.00), 954: (10.03), 955: (10.11), 956: (10.02), 957: (10.01), 958: (1.00), 959: (10.01), 960: (1.00), 961: (1.00), 962: (10.02), 963: (10.13), 964: (10.02), 965: (10.01), 966: (1.00), 967: (1.00), 968: (1.00), 969: (1.00), 970: (10.01), 971: (10.11), 972: (10.02), 973: (1.00), 974: (1.00), 975: (10.01), 976: (10.01), 977: (10.01), 978: (10.02), 979: (10.23), 980: (10.02), 981: (10.01), 982: (10.01), 983: (10.01), 984: (10.02), 985: (10.04), 986: (10.05), 987: (10.08), 988: (10.02), 989: (10.01), 990: (10.01), 991: (10.01), 992: (10.01), 993: (1.00), 994: (10.04), 995: (10.12), 996: (10.01), 997: (10.01), 998: (10.02), 999: (1.00), 1000: (1.00), 1001: (1.00), 1002: (10.01), 1003: (10.12), 1004: (10.02), 1005: (10.01), 1006: (1.00), 1007: (10.02), 1008: (10.02), 1009: (10.01), 1010: (10.01), 1011: (10.37), 1012: (10.02), 1013: (10.02), 1014: (10.01), 1015: (10.02), 1016: (10.08), 1017: (10.19), 1018: (10.03), 1019: (10.18), 1020: (10.04), 1021: (10.02), 1022: (10.01), 1023: (10.14), 1024: (10.03), 1025: (10.14), 1026: (10.04), 1027: (10.17), 1028: (10.06), 1029: (10.05), 1030: (10.03), 1031: (10.02), 1032: (10.02), 1033: (10.01), 1034: (10.02), 1035: (10.15), 1036: (10.03), 1037: (10.01), 1038: (1.00), 1039: (10.01), 1040: (1.00), 1041: (1.00), 1042: (10.01), 1043: (10.21), 1044: (10.01), 1045: (1.00), 1046: (1.00), 1047: (10.01), 1048: (1.00), 1049: (1.00), 1050: (10.02), 1051: (10.17), 1052: (10.02), 1053: (10.01), 1054: (1.00), 1055: (10.01), 1056: (1.00), 1057: (1.00), 1058: (10.03), 1059: (10.17), 1060: (10.01), 1061: (1.00), 1062: (10.01), 1063: (10.01), 1064: (10.01), 1065: (1.00), 1066: (10.01), 1067: (10.15), 1068: (10.04), 1069: (10.01), 1070: (10.01), 1071: (10.01), 1072: (10.01), 1073: (1.00), 1074: (10.01), 1075: (10.17), 1076: (10.01), 1077: (1.00), 1078: (1.00), 1079: (10.01), 1080: (10.01), 1081: (10.01), 1082: (10.03), 1083: (10.09), 1084: (10.02), 1085: (10.01), 1086: (10.01), 1087: (10.01), 1088: (1.00), 1089: (1.00), 1090: (10.01), 1091: (10.13), 1092: (10.01), 1093: (1.00), 1094: (1.00), 1095: (1.00), 1096: (1.00), 1097: (1.00), 1098: (10.01), 1099: (10.15), 1100: (10.04), 1101: (10.01), 1102: (10.01), 1103: (10.01), 1104: (1.00), 1105: (1.00), 1106: (10.01), 1107: (10.18), 1108: (10.01), 1109: (1.00), 1110: (1.00), 1111: (10.01), 1112: (10.01), 1113: (1.00), 1114: (10.01), 1115: (10.15), 1116: (10.04), 1117: (10.03), 1118: (10.01), 1119: (10.01), 1120: (1.00), 1121: (1.00), 1122: (10.01), 1123: (10.18), 1124: (10.01), 1125: (10.01), 1126: (10.01), 1127: (10.01), 1128: (1.00), 1129: (1.00), 1130: (10.01), 1131: (10.08), 1132: (10.01), 1133: (1.00), 1134: (1.00), 1135: (10.01), 1136: (10.01), 1137: (10.01), 1138: (10.01), 1139: (10.25), 1140: (10.02), 1141: (10.02), 1142: (10.02), 1143: (10.03), 1144: (10.03), 1145: (10.21), 1146: (10.04), 1147: (10.18), 1148: (10.12), 1149: (10.13), 1150: (10.07), 1151: (10.10), 1152: (10.02), 1153: (10.10), 1154: (10.02), 1155: (10.19), 1156: (10.08), 1157: (10.06), 1158: (10.04), 1159: (10.04), 1160: (10.05), 1161: (10.15), 1162: (10.02), 1163: (10.16), 1164: (10.04), 1165: (10.12), 1166: (10.01), 1167: (10.16), 1168: (10.01), 1169: (1.00), 1170: (10.02), 1171: (10.10), 1172: (10.03), 1173: (10.03), 1174: (10.01), 1175: (10.25), 1176: (10.02), 1177: (1.00), 1178: (10.02), 1179: (10.14), 1180: (10.03), 1181: (10.20), 1182: (10.01), 1183: (10.35), 1184: (10.02), 1185: (10.01), 1186: (10.01), 1187: (10.28), 1188: (10.01), 1189: (1.00), 1190: (1.00), 1191: (10.01), 1192: (10.01), 1193: (10.18), 1194: (10.01), 1195: (10.18), 1196: (10.03), 1197: (10.21), 1198: (10.01), 1199: (10.27), 1200: (10.01), 1201: (10.01), 1202: (10.06), 1203: (10.11), 1204: (10.03), 1205: (10.04), 1206: (1.00), 1207: (10.31), 1208: (10.02), 1209: (1.00), 1210: (1.00), 1211: (10.25), 1212: (10.04), 1213: (10.16), 1214: (10.02), 1215: (10.14), 1216: (10.02), 1217: (10.04), 1218: (10.01), 1219: (10.30), 1220: (10.01), 1221: (1.00), 1222: (1.00), 1223: (10.03), 1224: (10.02), 1225: (10.17), 1226: (10.02), 1227: (10.21), 1228: (10.03), 1229: (10.18), 1230: (10.01), 1231: (10.28), 1232: (10.02), 1233: (10.01), 1234: (10.01), 1235: (10.14), 1236: (10.03), 1237: (10.02), 1238: (10.01), 1239: (10.13), 1240: (10.01), 1241: (10.07), 1242: (10.01), 1243: (10.14), 1244: (10.02), 1245: (10.14), 1246: (10.01), 1247: (10.09), 1248: (10.01), 1249: (10.02), 1250: (10.01), 1251: (10.30), 1252: (10.01), 1253: (1.00), 1254: (1.00), 1255: (10.01), 1256: (10.06), 1257: (10.12), 1258: (10.01), 1259: (10.15), 1260: (10.02), 1261: (10.13), 1262: (10.02), 1263: (10.24), 1264: (10.01), 1265: (10.02), 1266: (10.02), 1267: (10.24), 1268: (10.04), 1269: (10.06), 1270: (10.02), 1271: (10.16), 1272: (10.01), 1273: (10.01), 1274: (10.02), 1275: (10.12), 1276: (10.03), 1277: (10.16), 1278: (10.02), 1279: (10.19), 1280: (10.01), 1281: (10.01), 1282: (10.01), 1283: (10.15), 1284: (10.05), 1285: (10.03), 1286: (10.02), 1287: (10.02), 1288: (10.01), 1289: (10.21), 1290: (10.02), 1291: (10.14), 1292: (10.03), 1293: (10.21), 1294: (10.03), 1295: (10.25), 1296: (10.02), 1297: (1.00), 1298: (1.00), 1299: (10.11), 1300: (10.10), 1301: (10.05), 1302: (10.06), 1303: (10.24), 1304: (10.03), 1305: (10.01), 1306: (10.01), 1307: (10.18), 1308: (10.06), 1309: (10.16), 1310: (10.01), 1311: (10.33), 1312: (10.02), 1313: (10.01), 1314: (1.00), 1315: (10.30), 1316: (10.02), 1317: (10.01), 1318: (1.00), 1319: (10.01), 1320: (10.01), 1321: (10.28), 1322: (10.01), 1323: (10.18), 1324: (10.02), 1325: (10.18), 1326: (10.01), 1327: (10.19), 1328: (10.01), 1329: (10.01), 1330: (10.02), 1331: (10.20), 1332: (10.05), 1333: (10.06), 1334: (10.02), 1335: (10.35), 1336: (10.02), 1337: (10.01), 1338: (10.01), 1339: (10.15), 1340: (10.03), 1341: (10.14), 1342: (10.02), 1343: (10.22), 1344: (10.04), 1345: (10.01), 1346: (10.01), 1347: (10.21), 1348: (10.02), 1349: (10.02), 1350: (1.00), 1351: (10.02), 1352: (10.01), 1353: (10.17), 1354: (10.01), 1355: (10.13), 1356: (10.03), 1357: (10.16), 1358: (10.01), 1359: (10.14), 1360: (10.01), 1361: (1.00), 1362: (10.03), 1363: (10.13), 1364: (10.03), 1365: (10.06), 1366: (10.02), 1367: (10.26), 1368: (10.04), 1369: (10.01), 1370: (10.01), 1371: (10.18), 1372: (10.05), 1373: (10.14), 1374: (10.02), 1375: (10.32), 1376: (10.02), 1377: (10.02), 1378: (10.01), 1379: (10.15), 1380: (10.02), 1381: (1.00), 1382: (1.00), 1383: (10.01), 1384: (10.01), 1385: (10.16), 1386: (10.01), 1387: (10.12), 1388: (10.02), 1389: (10.12), 1390: (10.02), 1391: (10.30), 1392: (10.02), 1393: (10.02), 1394: (10.10), 1395: (10.11), 1396: (10.04), 1397: (10.06), 1398: (10.03), 1399: (10.30), 1400: (10.02), 1401: (10.01), 1402: (1.00), 1403: (10.15), 1404: (10.04), 1405: (10.14), 1406: (10.03), 1407: (10.24), 1408: (10.06), 1409: (10.04), 1410: (10.02), 1411: (10.54), 1412: (10.22), 1413: (10.30), 1414: (10.05), 1415: (10.26), 1416: (10.11), 1417: (10.42), 1418: (10.52), 1419: (10.35), 1420: (10.09), 1421: (10.03), 1422: (10.02), 1423: (10.52), 1424: (10.37), 1425: (10.33), 1426: (10.21), 1427: (10.20), 1428: (10.05), 1429: (10.30), 1430: (10.30), 1431: (10.39), 1432: (10.24), 1433: (10.07), 1434: (10.02), 1435: (10.62), 1436: (10.26), 1437: (10.14), 1438: (10.07), 1439: (10.36), 1440: (10.06), 1441: (10.12), 1442: (10.17), 1443: (10.41), 1444: (10.18), 1445: (10.39), 1446: (10.10), 1447: (10.13), 1448: (10.09), 1449: (10.12), 1450: (10.20), 1451: (10.36), 1452: (10.17), 1453: (10.09), 1454: (10.01), 1455: (10.22), 1456: (10.24), 1457: (10.17), 1458: (10.09), 1459: (10.27), 1460: (10.06), 1461: (10.08), 1462: (10.10), 1463: (10.19), 1464: (10.04), 1465: (10.02), 1466: (10.05), 1467: (10.18), 1468: (10.06), 1469: (10.12), 1470: (10.01), 1471: (10.10), 1472: (10.04), 1473: (10.03), 1474: (10.01), 1475: (10.08), 1476: (10.08), 1477: (10.06), 1478: (10.05), 1479: (10.06), 1480: (10.03), 1481: (10.02), 1482: (10.01), 1483: (10.15), 1484: (10.01), 1485: (10.01), 1486: (1.00), 1487: (1.00), 1488: (1.00), 1489: (10.01), 1490: (1.00), 1491: (10.10), 1492: (1.00), 1493: (1.00), 1494: (1.00), 1495: (10.01), 1496: (1.00), 1497: (1.00), 1498: (10.01), 1499: (10.21), 1500: (10.02), 1501: (10.01), 1502: (1.00), 1503: (10.01), 1504: (1.00), 1505: (1.00), 1506: (1.00), 1507: (10.11), 1508: (10.01), 1509: (10.01), 1510: (1.00), 1511: (10.01), 1512: (1.00), 1513: (10.01), 1514: (1.00), 1515: (10.18), 1516: (10.02), 1517: (1.00), 1518: (1.00), 1519: (10.01), 1520: (1.00), 1521: (1.00), 1522: (1.00), 1523: (10.08), 1524: (10.01), 1525: (1.00), 1526: (1.00), 1527: (1.00), 1528: (1.00), 1529: (1.00), 1530: (1.00), 1531: (10.25), 1532: (10.03), 1533: (10.01), 1534: (1.00), 1535: (10.01), 1536: (1.00), 1537: (10.01), 1538: (1.00), 1539: (10.15), 1540: (10.02), 1541: (1.00), 1542: (1.00), 1543: (10.01), 1544: (1.00), 1545: (10.01), 1546: (1.00), 1547: (10.25), 1548: (10.03), 1549: (1.00), 1550: (1.00), 1551: (1.00), 1552: (1.00), 1553: (1.00), 1554: (1.00), 1555: (10.18), 1556: (10.01), 1557: (1.00), 1558: (1.00), 1559: (1.00), 1560: (1.00), 1561: (1.00), 1562: (1.00), 1563: (10.20), 1564: (10.03), 1565: (10.01), 1566: (1.00), 1567: (1.00), 1568: (1.00), 1569: (10.01), 1570: (1.00), 1571: (10.19), 1572: (10.02), 1573: (1.00), 1574: (1.00), 1575: (10.01), 1576: (1.00), 1577: (1.00), 1578: (1.00), 1579: (10.19), 1580: (10.02), 1581: (1.00), 1582: (1.00), 1583: (1.00), 1584: (1.00), 1585: (1.00), 1586: (1.00), 1587: (10.12), 1588: (10.01), 1589: (10.01), 1590: (1.00), 1591: (10.03), 1592: (1.00), 1593: (1.00), 1594: (1.00), 1595: (10.26), 1596: (10.02), 1597: (10.01), 1598: (1.00), 1599: (10.01), 1600: (1.00), 1601: (1.00), 1602: (1.00), 1603: (10.32), 1604: (10.05), 1605: (10.03), 1606: (10.01), 1607: (10.01), 1608: (1.00), 1609: (1.00), 1610: (10.01), 1611: (10.15), 1612: (10.02), 1613: (1.00), 1614: (1.00), 1615: (1.00), 1616: (1.00), 1617: (1.00), 1618: (10.01), 1619: (10.12), 1620: (10.01), 1621: (1.00), 1622: (1.00), 1623: (1.00), 1624: (1.00), 1625: (1.00), 1626: (1.00), 1627: (10.24), 1628: (10.03), 1629: (10.01), 1630: (1.00), 1631: (1.00), 1632: (1.00), 1633: (10.01), 1634: (1.00), 1635: (10.16), 1636: (10.03), 1637: (10.01), 1638: (1.00), 1639: (1.00), 1640: (1.00), 1641: (1.00), 1642: (1.00), 1643: (10.20), 1644: (10.03), 1645: (1.00), 1646: (1.00), 1647: (1.00), 1648: (1.00), 1649: (10.01), 1650: (10.01), 1651: (10.23), 1652: (10.02), 1653: (10.01), 1654: (1.00), 1655: (1.00), 1656: (1.00), 1657: (1.00), 1658: (1.00), 1659: (10.24), 1660: (10.03), 1661: (10.01), 1662: (1.00), 1663: (1.00), 1664: (1.00), 1665: (1.00), 1666: (1.00), 1667: (10.12), 1668: (10.02), 1669: (10.01), 1670: (1.00), 1671: (1.00), 1672: (1.00), 1673: (1.00), 1674: (1.00), 1675: (10.21), 1676: (10.03), 1677: (1.00), 1678: (1.00), 1679: (1.00), 1680: (1.00), 1681: (1.00), 1682: (1.00), 1683: (10.09), 1684: (10.01), 1685: (1.00), 1686: (1.00), 1687: (10.01), 1688: (1.00), 1689: (1.00), 1690: (1.00), 1691: (10.16), 1692: (10.05), 1693: (10.01), 1694: (1.00), 1695: (1.00), 1696: (1.00), 1697: (1.00), 1698: (1.00), 1699: (10.14), 1700: (10.01), 1701: (10.01), 1702: (1.00), 1703: (10.01), 1704: (1.00), 1705: (1.00), 1706: (1.00), 1707: (10.18), 1708: (10.05), 1709: (1.00), 1710: (1.00), 1711: (10.01), 1712: (10.01), 1713: (10.02), 1714: (10.01), 1715: (10.25), 1716: (10.11), 1717: (10.06), 1718: (10.03), 1719: (10.26), 1720: (10.12), 1721: (10.05), 1722: (10.04), 1723: (10.21), 1724: (10.04), 1725: (10.13), 1726: (10.06), 1727: (10.17), 1728: (10.03), 1729: (10.13), 1730: (10.03), 1731: (10.34), 1732: (10.11), 1733: (10.08), 1734: (10.05), 1735: (10.05), 1736: (10.02), 1737: (10.01), 1738: (10.02), 1739: (10.24), 1740: (10.06), 1741: (10.02), 1742: (10.01), 1743: (10.03), 1744: (10.03), 1745: (10.01), 1746: (10.01), 1747: (10.23), 1748: (10.01), 1749: (10.01), 1750: (1.00), 1751: (10.01), 1752: (10.01), 1753: (10.01), 1754: (1.00), 1755: (10.16), 1756: (10.03), 1757: (1.00), 1758: (1.00), 1759: (10.01), 1760: (1.00), 1761: (1.00), 1762: (1.00), 1763: (10.16), 1764: (10.03), 1765: (10.02), 1766: (10.01), 1767: (10.02), 1768: (10.01), 1769: (1.00), 1770: (10.01), 1771: (10.19), 1772: (10.03), 1773: (10.01), 1774: (1.00), 1775: (10.01), 1776: (10.01), 1777: (1.00), 1778: (10.02), 1779: (10.15), 1780: (10.02), 1781: (10.01), 1782: (10.01), 1783: (10.01), 1784: (10.01), 1785: (10.01), 1786: (10.01), 1787: (10.11), 1788: (10.03), 1789: (10.01), 1790: (10.01), 1791: (10.01), 1792: (1.00), 1793: (1.00), 1794: (1.00), 1795: (10.16), 1796: (10.01), 1797: (10.01), 1798: (10.01), 1799: (10.01), 1800: (1.00), 1801: (1.00), 1802: (10.01), 1803: (10.11), 1804: (10.01), 1805: (10.01), 1806: (1.00), 1807: (10.01), 1808: (1.00), 1809: (10.01), 1810: (10.01), 1811: (10.24), 1812: (10.03), 1813: (10.01), 1814: (10.01), 1815: (10.01), 1816: (10.01), 1817: (10.01), 1818: (1.00), 1819: (10.11), 1820: (10.04), 1821: (10.01), 1822: (10.01), 1823: (10.01), 1824: (10.01), 1825: (1.00), 1826: (10.01), 1827: (10.09), 1828: (10.02), 1829: (10.01), 1830: (10.01), 1831: (10.01), 1832: (10.02), 1833: (10.24), 1834: (10.05), 1835: (10.12), 1836: (10.04), 1837: (10.03), 1838: (10.02), 1839: (10.18), 1840: (10.10), 1841: (10.24), 1842: (10.06), 1843: (10.04), 1844: (10.05), 1845: (10.16), 1846: (10.05), 1847: (10.04), 1848: (10.04), 1849: (10.36), 1850: (10.03), 1851: (10.24), 1852: (10.07), 1853: (10.23), 1854: (10.03), 1855: (10.06), 1856: (10.02), 1857: (10.13), 1858: (10.01), 1859: (10.29), 1860: (10.06), 1861: (10.05), 1862: (10.04), 1863: (10.03), 1864: (10.02), 1865: (10.01), 1866: (10.01), 1867: (10.15), 1868: (10.03), 1869: (10.01), 1870: (10.01), 1871: (10.01), 1872: (1.00), 1873: (1.00), 1874: (1.00), 1875: (10.17), 1876: (10.02), 1877: (10.01), 1878: (1.00), 1879: (10.01), 1880: (10.01), 1881: (1.00), 1882: (1.00), 1883: (10.19), 1884: (10.03), 1885: (10.01), 1886: (10.01), 1887: (10.01), 1888: (10.01), 1889: (10.01), 1890: (1.00), 1891: (10.19), 1892: (10.02), 1893: (10.01), 1894: (10.01), 1895: (10.01), 1896: (1.00), 1897: (1.00), 1898: (1.00), 1899: (10.13), 1900: (10.04), 1901: (10.01), 1902: (1.00), 1903: (10.01), 1904: (10.01), 1905: (10.01), 1906: (10.01), 1907: (10.20), 1908: (10.02), 1909: (10.01), 1910: (1.00), 1911: (10.01), 1912: (10.01), 1913: (10.01), 1914: (1.00), 1915: (10.16), 1916: (10.05), 1917: (10.02), 1918: (1.00), 1919: (10.01), 1920: (10.01), 1921: (1.00), 1922: (1.00), 1923: (10.18), 1924: (10.04), 1925: (10.02), 1926: (10.01), 1927: (10.01), 1928: (10.01), 1929: (1.00), 1930: (1.00), 1931: (10.16), 1932: (10.04), 1933: (10.01), 1934: (10.01), 1935: (10.01), 1936: (1.00), 1937: (1.00), 1938: (1.00), 1939: (10.12), 1940: (10.02), 1941: (10.01), 1942: (10.01), 1943: (10.01), 1944: (10.01), 1945: (1.00), 1946: (1.00), 1947: (10.15), 1948: (10.04), 1949: (10.01), 1950: (10.01), 1951: (10.01), 1952: (10.01), 1953: (1.00), 1954: (1.00), 1955: (10.13), 1956: (10.03), 1957: (10.01), 1958: (10.01), 1959: (10.01), 1960: (10.01), 1961: (1.00), 1962: (1.00), 1963: (10.17), 1964: (10.03), 1965: (10.01), 1966: (1.00), 1967: (10.06), 1968: (10.03), 1969: (10.02), 1970: (10.01), 1971: (10.20), 1972: (10.07), 1973: (10.03), 1974: (10.01), 1975: (10.02), 1976: (10.03), 1977: (10.18), 1978: (10.02), 1979: (10.10), 1980: (10.07), 1981: (10.09), 1982: (10.05), 1983: (10.07), 1984: (10.02), 1985: (10.11), 1986: (10.03), 1987: (10.19), 1988: (10.09), 1989: (10.06), 1990: (10.04), 1991: (10.05), 1992: (10.03), 1993: (10.21), 1994: (10.04), 1995: (10.18), 1996: (10.06), 1997: (10.18), 1998: (10.04), 1999: (10.20), 2000: (10.06), 2001: (10.01), 2002: (10.05), 2003: (10.11), 2004: (10.08), 2005: (10.03), 2006: (10.06), 2007: (10.17), 2008: (10.07), 2009: (10.05), 2010: (10.03), 2011: (10.08), 2012: (10.04), 2013: (10.19), 2014: (10.04), 2015: (10.17), 2016: (10.06), 2017: (10.01), 2018: (1.00), 2019: (10.17), 2020: (10.03), 2021: (1.00), 2022: (1.00), 2023: (10.01), 2024: (10.01), 2025: (10.23), 2026: (10.03), 2027: (10.13), 2028: (10.05), 2029: (10.16), 2030: (10.03), 2031: (10.08), 2032: (10.03), 2033: (10.01), 2034: (10.06), 2035: (10.08), 2036: (10.10), 2037: (10.02), 2038: (10.06), 2039: (10.14), 2040: (10.03), 2041: (10.01), 2042: (10.01), 2043: (10.12), 2044: (10.02), 2045: (10.07), 2046: (10.03), 2047: (10.09), 2048: (10.03), 2049: (10.01), 2050: (10.01), 2051: (10.17), 2052: (10.03), 2053: (10.01), 2054: (1.00), 2055: (10.02), 2056: (10.01), 2057: (10.19), 2058: (10.02), 2059: (10.14), 2060: (10.03), 2061: (10.12), 2062: (10.02), 2063: (10.11), 2064: (10.04), 2065: (10.01), 2066: (10.09), 2067: (10.09), 2068: (10.03), 2069: (10.03), 2070: (10.02), 2071: (10.11), 2072: (10.01), 2073: (10.03), 2074: (1.00), 2075: (10.08), 2076: (10.03), 2077: (10.09), 2078: (10.03), 2079: (10.13), 2080: (10.02), 2081: (1.00), 2082: (1.00), 2083: (10.16), 2084: (10.05), 2085: (1.00), 2086: (1.00), 2087: (10.01), 2088: (1.00), 2089: (10.17), 2090: (10.01), 2091: (10.12), 2092: (10.03), 2093: (10.18), 2094: (10.02), 2095: (10.14), 2096: (10.01), 2097: (1.00), 2098: (10.07), 2099: (10.09), 2100: (10.06), 2101: (10.01), 2102: (1.00), 2103: (10.18), 2104: (10.02), 2105: (10.01), 2106: (1.00), 2107: (10.15), 2108: (10.03), 2109: (10.10), 2110: (10.02), 2111: (10.14), 2112: (10.02), 2113: (1.00), 2114: (1.00), 2115: (10.19), 2116: (10.07), 2117: (10.05), 2118: (10.04), 2119: (10.04), 2120: (10.02), 2121: (10.24), 2122: (10.02), 2123: (10.13), 2124: (10.04), 2125: (10.12), 2126: (10.05), 2127: (10.14), 2128: (10.04), 2129: (10.01), 2130: (10.02), 2131: (10.06), 2132: (10.11), 2133: (10.02), 2134: (10.04), 2135: (10.21), 2136: (10.08), 2137: (10.01), 2138: (1.00), 2139: (10.15), 2140: (10.05), 2141: (10.17), 2142: (10.03), 2143: (10.14), 2144: (10.02), 2145: (10.01), 2146: (1.00), 2147: (10.29), 2148: (10.05), 2149: (10.01), 2150: (1.00), 2151: (10.01), 2152: (1.00), 2153: (10.19), 2154: (10.02), 2155: (10.15), 2156: (10.05), 2157: (10.22), 2158: (10.03), 2159: (10.12), 2160: (10.01), 2161: (1.00), 2162: (1.00), 2163: (10.04), 2164: (10.07), 2165: (10.02), 2166: (10.03), 2167: (10.14), 2168: (10.06), 2169: (10.03), 2170: (10.09), 2171: (10.09), 2172: (10.04), 2173: (10.17), 2174: (10.03), 2175: (10.13), 2176: (10.03), 2177: (10.01), 2178: (1.00), 2179: (10.18), 2180: (10.05), 2181: (10.02), 2182: (10.01), 2183: (10.01), 2184: (10.01), 2185: (10.08), 2186: (10.02), 2187: (10.10), 2188: (10.04), 2189: (10.09), 2190: (10.05), 2191: (10.10), 2192: (10.08), 2193: (10.01), 2194: (1.00), 2195: (10.03), 2196: (10.10), 2197: (10.05), 2198: (10.06), 2199: (10.11), 2200: (10.11), 2201: (10.01), 2202: (1.00), 2203: (10.11), 2204: (10.03), 2205: (10.12), 2206: (10.02), 2207: (10.11), 2208: (10.06), 2209: (10.04), 2210: (10.03), 2211: (10.11), 2212: (10.07), 2213: (10.01), 2214: (1.00), 2215: (10.01), 2216: (10.01), 2217: (10.14), 2218: (10.03), 2219: (10.09), 2220: (10.04), 2221: (10.12), 2222: (10.07), 2223: (10.10), 2224: (10.04), 2225: (10.01), 2226: (10.04), 2227: (10.08), 2228: (10.13), 2229: (10.01), 2230: (10.01), 2231: (10.13), 2232: (10.05), 2233: (10.02), 2234: (1.00), 2235: (10.12), 2236: (10.09), 2237: (10.15), 2238: (10.04), 2239: (10.12), 2240: (10.06), 2241: (10.01), 2242: (1.00), 2243: (10.20), 2244: (10.14), 2245: (10.08), 2246: (10.05), 2247: (10.20), 2248: (10.09), 2249: (10.02), 2250: (10.01), 2251: (10.10), 2252: (10.04), 2253: (10.07), 2254: (10.02), 2255: (10.01), 2256: (1.00), 2257: (1.00), 2258: (1.00), 2259: (1.00), 2260: (10.03), 2261: (10.03), 2262: (10.01), 2263: (10.12), 2264: (10.03), 2265: (1.00), 2266: (1.00), 2267: (10.07), 2268: (10.02), 2269: (10.11), 2270: (10.03), 2271: (10.01), 2272: (1.00), 2273: (1.00), 2274: (1.00), 2275: (10.31), 2276: (10.11), 2277: (10.02), 2278: (10.01), 2279: (10.19), 2280: (10.06), 2281: (10.01), 2282: (10.01), 2283: (10.14), 2284: (10.05), 2285: (10.16), 2286: (10.05), 2287: (10.02), 2288: (1.00), 2289: (1.00), 2290: (1.00), 2291: (10.01), 2292: (10.02), 2293: (10.01), 2294: (10.01), 2295: (10.12), 2296: (10.01), 2297: (1.00), 2298: (1.00), 2299: (10.13), 2300: (10.05), 2301: (10.17), 2302: (10.03), 2303: (10.01), 2304: (10.01), 2305: (1.00), 2306: (1.00), 2307: (10.20), 2308: (10.12), 2309: (10.01), 2310: (10.01), 2311: (10.19), 2312: (10.12), 2313: (10.01), 2314: (1.00), 2315: (10.13), 2316: (10.05), 2317: (10.14), 2318: (10.02), 2319: (10.01), 2320: (1.00), 2321: (1.00), 2322: (1.00), 2323: (10.01), 2324: (10.01), 2325: (10.01), 2326: (1.00), 2327: (10.06), 2328: (10.02), 2329: (1.00), 2330: (1.00), 2331: (10.07), 2332: (10.05), 2333: (10.06), 2334: (10.03), 2335: (10.01), 2336: (1.00), 2337: (1.00), 2338: (1.00), 2339: (10.14), 2340: (10.13), 2341: (10.04), 2342: (10.02), 2343: (10.19), 2344: (10.12), 2345: (10.01), 2346: (1.00), 2347: (10.14), 2348: (10.05), 2349: (10.15), 2350: (10.02), 2351: (10.01), 2352: (1.00), 2353: (1.00), 2354: (1.00), 2355: (10.01), 2356: (10.02), 2357: (10.01), 2358: (1.00), 2359: (10.03), 2360: (10.01), 2361: (10.01), 2362: (10.01), 2363: (10.14), 2364: (10.07), 2365: (10.12), 2366: (10.03), 2367: (10.02), 2368: (1.00), 2369: (1.00), 2370: (1.00), 2371: (10.19), 2372: (10.13), 2373: (10.01), 2374: (10.01), 2375: (10.19), 2376: (10.10), 2377: (10.01), 2378: (1.00), 2379: (10.16), 2380: (10.04), 2381: (10.15), 2382: (10.02), 2383: (10.01), 2384: (1.00), 2385: (1.00), 2386: (1.00), 2387: (10.01), 2388: (10.02), 2389: (10.01), 2390: (1.00), 2391: (10.05), 2392: (10.01), 2393: (1.00), 2394: (1.00), 2395: (10.12), 2396: (10.03), 2397: (10.09), 2398: (10.04), 2399: (10.02), 2400: (1.00), 2401: (1.00), 2402: (1.00), 2403: (10.24), 2404: (10.08), 2405: (10.02), 2406: (10.01), 2407: (10.24), 2408: (10.06), 2409: (10.01), 2410: (1.00), 2411: (10.18), 2412: (10.04), 2413: (10.20), 2414: (10.04), 2415: (10.01), 2416: (1.00), 2417: (1.00), 2418: (1.00), 2419: (10.01), 2420: (10.01), 2421: (1.00), 2422: (1.00), 2423: (10.01), 2424: (10.01), 2425: (10.01), 2426: (1.00), 2427: (10.11), 2428: (10.05), 2429: (10.11), 2430: (10.04), 2431: (10.03), 2432: (10.01), 2433: (1.00), 2434: (1.00), 2435: (10.17), 2436: (10.10), 2437: (10.02), 2438: (10.01), 2439: (10.16), 2440: (10.17), 2441: (10.01), 2442: (1.00), 2443: (10.14), 2444: (10.04), 2445: (10.11), 2446: (10.07), 2447: (10.01), 2448: (1.00), 2449: (1.00), 2450: (1.00), 2451: (10.01), 2452: (10.01), 2453: (1.00), 2454: (1.00), 2455: (10.11), 2456: (10.01), 2457: (1.00), 2458: (1.00), 2459: (10.11), 2460: (10.03), 2461: (10.13), 2462: (10.03), 2463: (10.01), 2464: (1.00), 2465: (1.00), 2466: (1.00), 2467: (10.14), 2468: (10.12), 2469: (10.02), 2470: (10.01), 2471: (10.14), 2472: (10.15), 2473: (10.02), 2474: (10.01), 2475: (10.16), 2476: (10.10), 2477: (10.13), 2478: (10.04), 2479: (10.22), 2480: (10.16), 2481: (10.08), 2482: (10.05), 2483: (10.06), 2484: (10.09), 2485: (10.07), 2486: (10.03), 2487: (10.19), 2488: (10.11), 2489: (10.08), 2490: (10.04), 2491: (10.09), 2492: (10.07), 2493: (10.10), 2494: (10.09), 2495: (10.27), 2496: (10.10), 2497: (10.07), 2498: (10.05), 2499: (10.18), 2500: (10.20), 2501: (10.18), 2502: (10.13), 2503: (10.11), 2504: (10.08), 2505: (10.06), 2506: (10.04), 2507: (10.15), 2508: (10.07), 2509: (10.04), 2510: (10.02), 2511: (10.16), 2512: (10.08), 2513: (10.03), 2514: (10.01), 2515: (10.01), 2516: (10.03), 2517: (10.05), 2518: (10.03), 2519: (10.08), 2520: (10.10), 2521: (10.04), 2522: (10.01), 2523: (10.09), 2524: (10.08), 2525: (10.04), 2526: (10.02), 2527: (10.10), 2528: (10.14), 2529: (10.01), 2530: (10.01), 2531: (10.05), 2532: (10.31), 2533: (10.05), 2534: (10.03), 2535: (10.02), 2536: (10.02), 2537: (10.01), 2538: (10.01), 2539: (10.08), 2540: (10.07), 2541: (10.04), 2542: (10.02), 2543: (10.16), 2544: (10.16), 2545: (10.02), 2546: (10.01), 2547: (10.01), 2548: (10.09), 2549: (10.05), 2550: (10.02), 2551: (10.10), 2552: (10.06), 2553: (10.01), 2554: (10.01), 2555: (10.18), 2556: (10.17), 2557: (10.10), 2558: (10.07), 2559: (10.07), 2560: (10.04), 2561: (10.03), 2562: (10.01), 2563: (10.08), 2564: (10.15), 2565: (10.15), 2566: (10.04), 2567: (10.21), 2568: (10.29), 2569: (10.02), 2570: (1.00), 2571: (1.00), 2572: (10.04), 2573: (10.03), 2574: (10.02), 2575: (10.07), 2576: (10.22), 2577: (10.02), 2578: (10.01), 2579: (10.11), 2580: (10.09), 2581: (10.05), 2582: (10.01), 2583: (10.07), 2584: (10.28), 2585: (10.01), 2586: (10.01), 2587: (10.12), 2588: (10.15), 2589: (10.03), 2590: (10.01), 2591: (10.01), 2592: (10.01), 2593: (10.02), 2594: (10.01), 2595: (10.13), 2596: (10.08), 2597: (10.03), 2598: (10.02), 2599: (10.16), 2600: (10.07), 2601: (10.02), 2602: (1.00), 2603: (10.02), 2604: (10.06), 2605: (10.03), 2606: (10.02), 2607: (10.09), 2608: (10.10), 2609: (10.03), 2610: (10.01), 2611: (10.10), 2612: (10.25), 2613: (10.16), 2614: (10.11), 2615: (10.10), 2616: (10.06), 2617: (10.04), 2618: (10.04), 2619: (10.14), 2620: (10.09), 2621: (10.04), 2622: (10.03), 2623: (10.06), 2624: (10.29), 2625: (10.03), 2626: (10.01), 2627: (10.01), 2628: (10.05), 2629: (10.03), 2630: (10.02), 2631: (10.06), 2632: (10.27), 2633: (10.03), 2634: (10.01), 2635: (10.08), 2636: (10.08), 2637: (10.05), 2638: (10.03), 2639: (10.05), 2640: (10.27), 2641: (10.02), 2642: (10.02), 2643: (10.06), 2644: (10.24), 2645: (10.04), 2646: (10.03), 2647: (10.02), 2648: (10.01), 2649: (10.01), 2650: (10.01), 2651: (10.09), 2652: (10.07), 2653: (10.04), 2654: (10.02), 2655: (10.08), 2656: (10.16), 2657: (10.02), 2658: (10.02), 2659: (10.01), 2660: (10.08), 2661: (10.07), 2662: (10.05), 2663: (10.13), 2664: (10.09), 2665: (10.03), 2666: (10.06), 2667: (10.26), 2668: (10.17), 2669: (10.11), 2670: (10.08), 2671: (10.06), 2672: (10.04), 2673: (10.02), 2674: (10.02), 2675: (10.12), 2676: (10.08), 2677: (10.04), 2678: (10.02), 2679: (10.09), 2680: (10.19), 2681: (10.02), 2682: (10.01), 2683: (10.01), 2684: (10.04), 2685: (10.02), 2686: (1.00), 2687: (10.04), 2688: (10.17), 2689: (10.02), 2690: (1.00), 2691: (10.08), 2692: (10.09), 2693: (10.06), 2694: (10.02), 2695: (10.09), 2696: (10.23), 2697: (10.01), 2698: (10.02), 2699: (10.05), 2700: (10.34), 2701: (10.03), 2702: (10.02), 2703: (1.00), 2704: (10.01), 2705: (10.01), 2706: (10.01), 2707: (10.07), 2708: (10.11), 2709: (10.04), 2710: (10.04), 2711: (10.10), 2712: (10.11), 2713: (10.04), 2714: (10.01), 2715: (10.03), 2716: (10.08), 2717: (10.08), 2718: (10.04), 2719: (10.16), 2720: (10.07), 2721: (10.02), 2722: (10.01), 2723: (10.27), 2724: (10.21), 2725: (10.11), 2726: (10.06), 2727: (10.05), 2728: (10.04), 2729: (10.03), 2730: (10.02), 2731: (10.13), 2732: (10.09), 2733: (10.06), 2734: (10.02), 2735: (10.38), 2736: (10.07), 2737: (10.02), 2738: (10.01), 2739: (10.03), 2740: (10.04), 2741: (10.03), 2742: (10.01), 2743: (10.12), 2744: (10.07), 2745: (10.01), 2746: (1.00), 2747: (10.06), 2748: (10.33), 2749: (10.18), 2750: (10.11), 2751: (10.08), 2752: (10.07), 2753: (10.06), 2754: (10.04), 2755: (10.11), 2756: (10.14), 2757: (10.06), 2758: (10.02), 2759: (10.05), 2760: (10.36), 2761: (10.04), 2762: (10.01), 2763: (10.01), 2764: (10.05), 2765: (10.04), 2766: (10.01), 2767: (10.06), 2768: (10.08), 2769: (10.01), 2770: (1.00), 2771: (10.09), 2772: (10.16), 2773: (10.09), 2774: (10.06), 2775: (10.05), 2776: (10.04), 2777: (10.02), 2778: (10.01), 2779: (10.14), 2780: (10.09), 2781: (10.03), 2782: (10.01), 2783: (10.05), 2784: (10.16), 2785: (10.02), 2786: (10.01), 2787: (10.01), 2788: (10.03), 2789: (10.02), 2790: (10.01), 2791: (10.04), 2792: (10.14), 2793: (10.01), 2794: (1.00), 2795: (10.03), 2796: (10.08), 2797: (10.04), 2798: (10.02), 2799: (10.06), 2800: (10.29), 2801: (10.02), 2802: (1.00), 2803: (10.05), 2804: (10.30), 2805: (10.03), 2806: (10.01), 2807: (10.02), 2808: (10.01), 2809: (10.01), 2810: (10.01), 2811: (10.04), 2812: (10.07), 2813: (10.03), 2814: (10.02), 2815: (10.05), 2816: (10.26), 2817: (10.03), 2818: (10.01), 2819: (10.01), 2820: (10.04), 2821: (10.02), 2822: (10.02), 2823: (10.11), 2824: (10.07), 2825: (10.02), 2826: (10.01), 2827: (10.13), 2828: (10.15), 2829: (10.10), 2830: (10.07), 2831: (10.06), 2832: (10.06), 2833: (10.04), 2834: (10.02), 2835: (10.07), 2836: (10.12), 2837: (10.07), 2838: (10.04), 2839: (10.08), 2840: (10.18), 2841: (10.02), 2842: (10.01), 2843: (10.01), 2844: (10.01), 2845: (10.02), 2846: (10.01), 2847: (10.04), 2848: (10.29), 2849: (10.02), 2850: (10.01), 2851: (10.07), 2852: (10.06), 2853: (10.04), 2854: (10.03), 2855: (10.05), 2856: (10.35), 2857: (10.01), 2858: (1.00), 2859: (10.09), 2860: (10.30), 2861: (10.03), 2862: (10.03), 2863: (10.02), 2864: (10.01), 2865: (10.01), 2866: (10.01), 2867: (10.04), 2868: (10.10), 2869: (10.04), 2870: (10.03), 2871: (10.06), 2872: (10.26), 2873: (10.04), 2874: (10.01), 2875: (10.02), 2876: (10.07), 2877: (10.05), 2878: (10.03), 2879: (10.15), 2880: (10.07), 2881: (10.02), 2882: (10.01), 2883: (10.10), 2884: (10.19), 2885: (10.10), 2886: (10.07), 2887: (10.07), 2888: (10.05), 2889: (10.03), 2890: (10.03), 2891: (10.09), 2892: (10.07), 2893: (10.03), 2894: (10.01), 2895: (10.05), 2896: (10.26), 2897: (10.02), 2898: (10.01), 2899: (10.01), 2900: (10.01), 2901: (10.02), 2902: (10.02), 2903: (10.04), 2904: (10.26), 2905: (10.02), 2906: (10.01), 2907: (10.02), 2908: (10.19), 2909: (10.06), 2910: (10.02), 2911: (10.03), 2912: (10.36), 2913: (10.03), 2914: (10.26), 2915: (10.02), 2916: (10.26), 2917: (10.05), 2918: (10.01), 2919: (10.01), 2920: (10.01), 2921: (10.01), 2922: (10.01), 2923: (10.02), 2924: (10.10), 2925: (10.05), 2926: (10.03), 2927: (10.02), 2928: (10.24), 2929: (10.02), 2930: (10.02), 2931: (10.01), 2932: (10.06), 2933: (10.05), 2934: (10.03), 2935: (10.09), 2936: (10.13), 2937: (10.09), 2938: (10.05), 2939: (10.10), 2940: (10.16), 2941: (10.09), 2942: (10.05), 2943: (10.01), 2944: (1.00), 2945: (1.00), 2946: (1.00), 2947: (1.00), 2948: (1.00), 2949: (1.00), 2950: (1.00), 2951: (1.00), 2952: (1.00), 2953: (1.00), 2954: (1.00), 2955: (1.00), 2956: (1.00), 2957: (1.00), 2958: (1.00), 2959: (1.00), 2960: (1.00), 2961: (1.00), 2962: (1.00), 2963: (1.00), 2964: (1.00), 2965: (1.00), 2966: (1.00), 2967: (1.00), 2968: (1.00), 2969: (1.00), 2970: (1.00), 2971: (1.00), 2972: (1.00), 2973: (1.00), 2974: (1.00), 2975: (1.00), 2976: (1.00), 2977: (1.00), 2978: (1.00), 2979: (1.00), 2980: (1.00), 2981: (1.00), 2982: (1.00), 2983: (1.00), 2984: (1.00), 2985: (1.00), 2986: (1.00), 2987: (1.00), 2988: (1.00), 2989: (1.00), 2990: (1.00), 2991: (1.00), 2992: (1.00), 2993: (1.00), 2994: (1.00), 2995: (1.00), 2996: (1.00), 2997: (1.00), 2998: (1.00), 2999: (1.00), 3000: (1.00), 3001: (1.00), 3002: (1.00), 3003: (10.01), 3004: (10.02), 3005: (10.01), 3006: (10.01), 3007: (1.00), 3008: (10.01), 3009: (10.02), 3010: (10.05), 3011: (10.05), 3012: (10.03), 3013: (1.00), 3014: (1.00), 3015: (10.01), 3016: (10.03), 3017: (10.01), 3018: (10.02), 3019: (1.00), 3020: (10.02), 3021: (10.01), 3022: (10.04), 3023: (10.02), 3024: (10.04), 3025: (1.00), 3026: (1.00), 3027: (10.01), 3028: (10.05), 3029: (1.00), 3030: (10.01), 3031: (1.00), 3032: (10.02), 3033: (10.02), 3034: (10.05), 3035: (10.03), 3036: (10.05), 3037: (10.01), 3038: (10.01), 3039: (1.00), 3040: (10.02), 3041: (10.01), 3042: (10.07), 3043: (10.03), 3044: (10.05), 3045: (1.00), 3046: (1.00), 3047: (1.00), 3048: (10.02), 3049: (10.01), 3050: (1.00), 3051: (1.00), 3052: (10.02), 3053: (1.00), 3054: (10.04), 3055: (10.04), 3056: (10.04), 3057: (1.00), 3058: (1.00), 3059: (1.00), 3060: (1.00), 3061: (1.00), 3062: (1.00), 3063: (1.00), 3064: (10.01), 3065: (10.01), 3066: (1.00), 3067: (1.00), 3068: (10.33), 3069: (10.19), 3070: (10.34), 3071: (10.09), 3072: (10.25), 3073: (10.09), 3074: (10.23), 3075: (10.02), 3076: (10.10), 3077: (10.02), 3078: (10.01), 3079: (10.01), 3080: (10.21), 3081: (10.04), 3082: (10.19), 3083: (10.02), 3084: (10.16), 3085: (10.03), 3086: (10.17), 3087: (10.03), 3088: (10.22), 3089: (10.03), 3090: (10.01), 3091: (10.01), 3092: (10.21), 3093: (10.04), 3094: (10.26), 3095: (10.06), 3096: (10.18), 3097: (10.03), 3098: (10.07), 3099: (10.03), 3100: (10.25), 3101: (10.06), 3102: (10.10), 3103: (10.06), 3104: (10.24), 3105: (10.08), 3106: (10.09), 3107: (10.03), 3108: (10.08), 3109: (10.02), 3110: (10.01), 3111: (10.01), 3112: (10.27), 3113: (10.05), 3114: (10.08), 3115: (10.04), 3116: (10.18), 3117: (10.02), 3118: (10.18), 3119: (10.01), 3120: (10.21), 3121: (10.02), 3122: (10.01), 3123: (10.02), 3124: (10.23), 3125: (10.03), 3126: (10.19), 3127: (10.05), 3128: (10.17), 3129: (10.03), 3130: (10.04), 3131: (10.02), 3132: (10.32), 3133: (10.08), 3134: (10.10), 3135: (10.02), 3136: (10.15), 3137: (10.02), 3138: (10.26), 3139: (10.06), 3140: (10.13), 3141: (10.03), 3142: (10.04), 3143: (10.02), 3144: (10.23), 3145: (10.05), 3146: (10.13), 3147: (10.05), 3148: (10.26), 3149: (10.03), 3150: (10.19), 3151: (10.02), 3152: (10.31), 3153: (10.03), 3154: (10.01), 3155: (10.01), 3156: (10.27), 3157: (10.04), 3158: (10.30), 3159: (10.04), 3160: (10.27), 3161: (10.02), 3162: (10.09), 3163: (10.02), 3164: (10.26), 3165: (10.03), 3166: (10.16), 3167: (10.02), 3168: (10.25), 3169: (10.04), 3170: (10.14), 3171: (10.02), 3172: (10.18), 3173: (10.02), 3174: (10.03), 3175: (10.01), 3176: (10.32), 3177: (10.03), 3178: (10.15), 3179: (10.01), 3180: (10.23), 3181: (10.08), 3182: (10.15), 3183: (10.05), 3184: (10.26), 3185: (10.02), 3186: (10.01), 3187: (10.01), 3188: (10.13), 3189: (10.04), 3190: (10.14), 3191: (10.03), 3192: (10.14), 3193: (10.03), 3194: (10.16), 3195: (10.05), 3196: (10.29), 3197: (10.15), 3198: (10.20), 3199: (10.05), 3200: (10.34), 3201: (10.12), 3202: (10.06), 3203: (10.07), 3204: (10.13), 3205: (10.08), 3206: (10.06), 3207: (10.05), 3208: (10.27), 3209: (10.07), 3210: (10.09), 3211: (10.04), 3212: (10.25), 3213: (10.09), 3214: (10.17), 3215: (10.06), 3216: (10.23), 3217: (10.05), 3218: (10.02), 3219: (10.04), 3220: (10.32), 3221: (10.14), 3222: (10.18), 3223: (10.04), 3224: (10.28), 3225: (10.07), 3226: (10.07), 3227: (10.04), 3228: (10.22), 3229: (10.14), 3230: (10.16), 3231: (10.06), 3232: (10.33), 3233: (10.09), 3234: (10.09), 3235: (10.05), 3236: (10.17), 3237: (10.09), 3238: (10.06), 3239: (10.05), 3240: (10.37), 3241: (10.04), 3242: (10.21), 3243: (10.07), 3244: (10.26), 3245: (10.13), 3246: (10.16), 3247: (10.07), 3248: (10.24), 3249: (10.04), 3250: (10.01), 3251: (10.03), 3252: (10.35), 3253: (10.16), 3254: (10.10), 3255: (10.05), 3256: (10.23), 3257: (10.08), 3258: (10.07), 3259: (10.12), 3260: (10.18), 3261: (10.21), 3262: (10.09), 3263: (10.11), 3264: (10.18), 3265: (10.12), 3266: (10.05), 3267: (10.04), 3268: (10.20), 3269: (10.08), 3270: (10.05), 3271: (10.04), 3272: (10.31), 3273: (10.06), 3274: (10.13), 3275: (10.04), 3276: (10.25), 3277: (10.12), 3278: (10.22), 3279: (10.06), 3280: (10.28), 3281: (10.04), 3282: (10.04), 3283: (10.02), 3284: (10.41), 3285: (10.11), 3286: (10.23), 3287: (10.07), 3288: (10.14), 3289: (10.03), 3290: (10.13), 3291: (10.03), 3292: (10.28), 3293: (10.08), 3294: (10.16), 3295: (10.05), 3296: (10.27), 3297: (10.06), 3298: (10.12), 3299: (10.02), 3300: (10.26), 3301: (10.11), 3302: (10.06), 3303: (10.04), 3304: (10.30), 3305: (10.03), 3306: (10.17), 3307: (10.01), 3308: (10.29), 3309: (10.11), 3310: (10.19), 3311: (10.06), 3312: (10.23), 3313: (10.11), 3314: (10.08), 3315: (10.03), 3316: (10.01), 3317: (1.00), 3318: (1.00), 3319: (1.00), 3320: (1.00), 3321: (1.00), 3322: (1.00), 3323: (1.00), 3324: (1.00), 3325: (1.00), 3326: (1.00), 3327: (1.00), 3328: (1.00), 3329: (1.00), 3330: (1.00), 3331: (1.00), 3332: (1.00), 3333: (1.00), 3334: (1.00), 3335: (1.00), 3336: (1.00), 3337: (1.00), 3338: (1.00), 3339: (1.00), 3340: (1.00), 3341: (1.00), 3342: (1.00), 3343: (1.00), 3344: (1.00), 3345: (1.00)\"#@param {type:\"string\"}\n",
        "    rotation_3d_x = \"0:(0)\"#@param {type:\"string\"}\n",
        "    rotation_3d_y = \"0: (0.05), 360: (-0.05), 416: (0.05), 632: (-0.05), 648: (0.05), 659: (-0.05), 677: (0.05), 1050: (0.05), 1146: (-0.05), 1218: (0.05), 1314: (-0.05), 1410: (0.05), 1770: (-0.05), 1986: (0.05), 2154: (-0.05), 2346: (0.05), 2490: (-0.05), 2850: (0.05), 3090: (-0.05), 3258: (0.05), 3450: (-0.05), 3642: (0.05), 3930: (-0.05), 3966: (0.05), 4098: (-0.05), 4194: (0.05), 4218: (-0.05), 4278: (0.05), 4314: (-0.05), 4362: (0.05), 4398: (-0.05), 4422: (0.05), 4446: (-0.05),\"#@param {type:\"string\"}\n",
        "    rotation_3d_z = \"0: (0.00)\"#@param {type:\"string\"}\n",
        "    flip_2d_perspective = False #@param {type:\"boolean\"}\n",
        "    perspective_flip_theta = \"0:(0)\"#@param {type:\"string\"}\n",
        "    perspective_flip_phi = \"0:(t%15)\"#@param {type:\"string\"}\n",
        "    perspective_flip_gamma = \"0:(0)\"#@param {type:\"string\"}\n",
        "    perspective_flip_fv = \"0:(53)\"#@param {type:\"string\"}\n",
        "    noise_schedule = \"0: (0.03)\"#@param {type:\"string\"}\n",
        "    strength_schedule = \"0: (0.450)\"#@param {type:\"string\"}\n",
        "    contrast_schedule = \"0: (1.0)\"#@param {type:\"string\"}\n",
        "\n",
        "    #@markdown ####**Coherence:**\n",
        "    color_coherence = 'Match Frame 0 LAB' #@param ['None', 'Match Frame 0 HSV', 'Match Frame 0 LAB', 'Match Frame 0 RGB'] {type:'string'}\n",
        "    diffusion_cadence = '8' #@param ['1','2','3','4','5','6','7','8'] {type:'string'}\n",
        "\n",
        "    #@markdown ####**3D Depth Warping:**\n",
        "    use_depth_warping = True #@param {type:\"boolean\"}\n",
        "    midas_weight = 0.35#@param {type:\"number\"}\n",
        "    near_plane = 200\n",
        "    far_plane = 10000\n",
        "    fov = 40#@param {type:\"number\"}\n",
        "    padding_mode = 'border'#@param ['border', 'reflection', 'zeros'] {type:'string'}\n",
        "    sampling_mode = 'bicubic'#@param ['bicubic', 'bilinear', 'nearest'] {type:'string'}\n",
        "    save_depth_maps = False #@param {type:\"boolean\"}\n",
        "\n",
        "    #@markdown ####**Video Input:**\n",
        "    video_init_path ='/content/video_in.mp4'#@param {type:\"string\"}\n",
        "    extract_nth_frame = 1#@param {type:\"number\"}\n",
        "    overwrite_extracted_frames = True #@param {type:\"boolean\"}\n",
        "    use_mask_video = False #@param {type:\"boolean\"}\n",
        "    video_mask_path ='/content/video_in.mp4'#@param {type:\"string\"}\n",
        "\n",
        "    #@markdown ####**Interpolation:**\n",
        "    interpolate_key_frames = False #@param {type:\"boolean\"}\n",
        "    interpolate_x_frames = 4 #@param {type:\"number\"}\n",
        "    \n",
        "    #@markdown ####**Resume Animation:**\n",
        "    resume_from_timestring = False #@param {type:\"boolean\"}\n",
        "    resume_timestring = \"20221119111304\" #@param {type:\"string\"}\n",
        "\n",
        "    return locals()\n",
        "\n",
        "class DeformAnimKeys():\n",
        "    def __init__(self, anim_args):\n",
        "        self.angle_series = get_inbetweens(parse_key_frames(anim_args.angle), anim_args.max_frames)\n",
        "        self.zoom_series = get_inbetweens(parse_key_frames(anim_args.zoom), anim_args.max_frames)\n",
        "        self.translation_x_series = get_inbetweens(parse_key_frames(anim_args.translation_x), anim_args.max_frames)\n",
        "        self.translation_y_series = get_inbetweens(parse_key_frames(anim_args.translation_y), anim_args.max_frames)\n",
        "        self.translation_z_series = get_inbetweens(parse_key_frames(anim_args.translation_z), anim_args.max_frames)\n",
        "        self.rotation_3d_x_series = get_inbetweens(parse_key_frames(anim_args.rotation_3d_x), anim_args.max_frames)\n",
        "        self.rotation_3d_y_series = get_inbetweens(parse_key_frames(anim_args.rotation_3d_y), anim_args.max_frames)\n",
        "        self.rotation_3d_z_series = get_inbetweens(parse_key_frames(anim_args.rotation_3d_z), anim_args.max_frames)\n",
        "        self.perspective_flip_theta_series = get_inbetweens(parse_key_frames(anim_args.perspective_flip_theta), anim_args.max_frames)\n",
        "        self.perspective_flip_phi_series = get_inbetweens(parse_key_frames(anim_args.perspective_flip_phi), anim_args.max_frames)\n",
        "        self.perspective_flip_gamma_series = get_inbetweens(parse_key_frames(anim_args.perspective_flip_gamma), anim_args.max_frames)\n",
        "        self.perspective_flip_fv_series = get_inbetweens(parse_key_frames(anim_args.perspective_flip_fv), anim_args.max_frames)\n",
        "        self.noise_schedule_series = get_inbetweens(parse_key_frames(anim_args.noise_schedule), anim_args.max_frames)\n",
        "        self.strength_schedule_series = get_inbetweens(parse_key_frames(anim_args.strength_schedule), anim_args.max_frames)\n",
        "        self.contrast_schedule_series = get_inbetweens(parse_key_frames(anim_args.contrast_schedule), anim_args.max_frames)\n",
        "\n",
        "\n",
        "def get_inbetweens(key_frames, max_frames, integer=False, interp_method='Linear'):\n",
        "    import numexpr\n",
        "    key_frame_series = pd.Series([np.nan for a in range(max_frames)])\n",
        "    \n",
        "    for i in range(0, max_frames):\n",
        "        if i in key_frames:\n",
        "            value = key_frames[i]\n",
        "            value_is_number = check_is_number(value)\n",
        "            # if it's only a number, leave the rest for the default interpolation\n",
        "            if value_is_number:\n",
        "                t = i\n",
        "                key_frame_series[i] = value\n",
        "        if not value_is_number:\n",
        "            t = i\n",
        "            key_frame_series[i] = numexpr.evaluate(value)\n",
        "    key_frame_series = key_frame_series.astype(float)\n",
        "    \n",
        "    if interp_method == 'Cubic' and len(key_frames.items()) <= 3:\n",
        "      interp_method = 'Quadratic'    \n",
        "    if interp_method == 'Quadratic' and len(key_frames.items()) <= 2:\n",
        "      interp_method = 'Linear'\n",
        "          \n",
        "    key_frame_series[0] = key_frame_series[key_frame_series.first_valid_index()]\n",
        "    key_frame_series[max_frames-1] = key_frame_series[key_frame_series.last_valid_index()]\n",
        "    key_frame_series = key_frame_series.interpolate(method=interp_method.lower(), limit_direction='both')\n",
        "    if integer:\n",
        "        return key_frame_series.astype(int)\n",
        "    return key_frame_series\n",
        "\n",
        "def parse_key_frames(string, prompt_parser=None):\n",
        "    # because math functions (i.e. sin(t)) can utilize brackets \n",
        "    # it extracts the value in form of some stuff\n",
        "    # which has previously been enclosed with brackets and\n",
        "    # with a comma or end of line existing after the closing one\n",
        "    pattern = r'((?P<frame>[0-9]+):[\\s]*\\((?P<param>[\\S\\s]*?)\\)([,][\\s]?|[\\s]?$))'\n",
        "    frames = dict()\n",
        "    for match_object in re.finditer(pattern, string):\n",
        "        frame = int(match_object.groupdict()['frame'])\n",
        "        param = match_object.groupdict()['param']\n",
        "        if prompt_parser:\n",
        "            frames[frame] = prompt_parser(param)\n",
        "        else:\n",
        "            frames[frame] = param\n",
        "    if frames == {} and len(string) != 0:\n",
        "        raise RuntimeError('Key Frame string not correctly formatted')\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIH-fYcoc4QW"
      },
      "source": [
        "### Prompts\n",
        "`animation_mode: None` batches on list of *prompts*. `animation_mode: 2D` uses *animation_prompts* key frame sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PkC22V9c4QW",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "prompts = [\n",
        "    \"a beautiful forest by Asher Brown Durand, trending on Artstation\", # the first prompt I want\n",
        "    \"a beautiful portrait of a woman by Artgerm, trending on Artstation\", # the second prompt I want\n",
        "    #\"this prompt I don't want it I commented it out\",\n",
        "    #\"a nousr robot, trending on Artstation\", # use \"nousr robot\" with the robot diffusion model (see model_checkpoint setting)\n",
        "    #\"touhou 1girl komeiji_koishi portrait, green hair\", # waifu diffusion prompts can use danbooru tag groups (see model_checkpoint)\n",
        "    #\"this prompt has weights if prompt weighting enabled:2 can also do negative:-2\", # (see prompt_weighting)\n",
        "]\n",
        "\n",
        "animation_prompts = {\n",
        "0:\t\"aenema\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "360:\t\"Some say the end is near Some say well see all of yet and soon Some say well see\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "416:\t\"all of yet and soon Soon they hope we will Should we use a vacation from this old\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "632:\t\"shit Three ring\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "648:\t\"circus Inside you Free chair in this\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "659:\t\"hopeless fucking holy collie\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "677:\t\"lane The only way to live soon\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "1050:\t\"is to brush it all away Any fucking time any fucking day Learn to swim see you down in Arizona Bay InFread for your figure InFread for your latte InFread for your\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "1146:\t\"lawsuit InFread for your hair piece InFread for your groZak InFread\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "1218:\t\"for your pilot InFread for your contract InFread for your car Four shit Three rain Circus Side shit\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "1314:\t\"Freaks are in this hopeless fucking hole we call LA The only way to fix it is to mush it all away\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "1410:\t\"Any fucking time any fucking day Were gonna swim see you down in Arizona Bay\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "1770:\t\"Some say a comet will fall from the sky Followed by media showers and tidal waves Followed by\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "1986:\t\"fault lines that cannot sit still Followed by millions of dumbfounded dipshits And some say the end is near Some say well see Armageddon soon Certainly hope we\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "2154:\t\"will Certainly hope we will I sure could use a vacation from this Stupid shit silly shit Stupid shit\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "2346:\t\"One great big festering beyond destruction Ive a suggestion to keep you all occupied Then well swim then well\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "2490:\t\"swim Then well swim Moms thatll fix it all soon Well put it back the way it\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "2850:\t\"ought to be Lets swim lets swim Fuck\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "3090:\t\"your life Harvard fuck all these clothes Fuck all these guntoting hip gangsta wannabes Lets\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "3258:\t\"swim lets swim Fuck retro anything fuck your tattoos Fuck all you junkies and fuck your short memory Lets swim lets swim\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "3450:\t\"Fuck smiley gladhounds with hidden engenders Fuck these dysfunctional intraday atmospheres\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "3642:\t\"Lets swim lets swim Im praying for rain Im praying the tidal wave I wanna see the ground give way I wanna watch it all go down My please flush it all away\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "3930:\t\"I wanna see it go rotten down I wanna watch it go rotten\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "3966:\t\"Watch you flush it all away disturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "4098:\t\"Yeah time to bring it down again\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "4194:\t\"Just call your nephew disturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "4218:\t\"try and agree between the lines disturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "4278:\t\"I cant imagine what you would disturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "4314:\t\"have willed That many chains\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "4362:\t\"right there I wanna see it come down\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "4398:\t\"Bring it down fuck\tdisturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "4422:\t\"it down flush disturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "4446:\t\"it down Hey hey hey hey hey hey disturbing, heavy metal, apocalyptic, post-apocalyptic, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, ultra high quality\",\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdIFOSyAc4QW"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-CbReahGc4QW"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import pandas as pd\n",
        "plt.style.use('bmh')\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.width = 175\n",
        "\n",
        "#@markdown **Load Settings**\n",
        "override_settings_with_file = False #@param {type:\"boolean\"}\n",
        "custom_settings_file = \"/content/drive/MyDrive/Settings.txt\"#@param {type:\"string\"}\n",
        "\n",
        "def DeforumArgs():\n",
        "    #@markdown **Image Settings**\n",
        "    W = 896 #@param\n",
        "    H = 512 #@param\n",
        "    W, H = map(lambda x: x - x % 64, (W, H))  # resize to integer multiple of 64\n",
        "\n",
        "    #@markdown **Sampling Settings**\n",
        "    seed = -1 #@param\n",
        "    sampler = 'klms' #@param [\"klms\",\"dpm2\",\"dpm2_ancestral\",\"heun\",\"euler\",\"euler_ancestral\",\"plms\", \"ddim\"]\n",
        "    steps = 120 #@param\n",
        "    scale = 9.5 #@param\n",
        "    ddim_eta = 0 #@param\n",
        "    dynamic_threshold = None\n",
        "    static_threshold = None   \n",
        "\n",
        "    #@markdown **Save & Display Settings**\n",
        "    save_samples = True #@param {type:\"boolean\"}\n",
        "    save_settings = True #@param {type:\"boolean\"}\n",
        "    display_samples = True #@param {type:\"boolean\"}\n",
        "    save_sample_per_step = False #@param {type:\"boolean\"}\n",
        "    show_sample_per_step = False #@param {type:\"boolean\"}\n",
        "\n",
        "    #@markdown **Prompt Settings**\n",
        "    prompt_weighting = False #@param {type:\"boolean\"}\n",
        "    normalize_prompt_weights = False #@param {type:\"boolean\"}\n",
        "    log_weighted_subprompts = False #@param {type:\"boolean\"}\n",
        "\n",
        "    #@markdown **Batch Settings**\n",
        "    n_batch = 1 #@param\n",
        "    batch_name = \"aenema\" #@param {type:\"string\"}\n",
        "    filename_format = \"{timestring}_{index}_{prompt}.png\" #@param [\"{timestring}_{index}_{seed}.png\",\"{timestring}_{index}_{prompt}.png\"]\n",
        "    seed_behavior = \"iter\" #@param [\"iter\",\"fixed\",\"random\"]\n",
        "    make_grid = False #@param {type:\"boolean\"}\n",
        "    grid_rows = 2 #@param \n",
        "    outdir = get_output_folder(output_path, batch_name)\n",
        "\n",
        "    #@markdown **Init Settings**\n",
        "    use_init = False #@param {type:\"boolean\"}\n",
        "    strength = 0 #@param {type:\"number\"}\n",
        "    strength_0_no_init = True # Set the strength to 0 automatically when no init image is used\n",
        "    init_image = \"/content/drive/MyDrive/Copy of Digital Planet 2(0)_0000.png\" #@param {type:\"string\"}\n",
        "    # Whiter areas of the mask are areas that change more\n",
        "    use_mask = False #@param {type:\"boolean\"}\n",
        "    use_alpha_as_mask = False # use the alpha channel of the init image as the mask\n",
        "    mask_file = \"/content/drive/MyDrive/bokinator/[ZT-D40900B-10P(N675)]-1.png\" #@param {type:\"string\"}\n",
        "    invert_mask = False #@param {type:\"boolean\"}\n",
        "    # Adjust mask image, 1.0 is no adjustment. Should be positive numbers.\n",
        "    mask_brightness_adjust = 1.0  #@param {type:\"number\"}\n",
        "    mask_contrast_adjust = 1.0  #@param {type:\"number\"}\n",
        "    # Overlay the masked image at the end of the generation so it does not get degraded by encoding and decoding\n",
        "    overlay_mask = True  # {type:\"boolean\"}\n",
        "    # Blur edges of final overlay mask, if used. Minimum = 0 (no blur)\n",
        "    mask_overlay_blur = 5 # {type:\"number\"}\n",
        "\n",
        "    n_samples = 1 # doesnt do anything\n",
        "    precision = 'autocast' \n",
        "    C = 4\n",
        "    f = 8\n",
        "\n",
        "    prompt = \"\"\n",
        "    timestring = \"\"\n",
        "    init_latent = None\n",
        "    init_sample = None\n",
        "    init_c = None\n",
        "\n",
        "    return locals()\n",
        "\n",
        "\n",
        "\n",
        "def next_seed(args):\n",
        "    if args.seed_behavior == 'iter':\n",
        "        args.seed += 1\n",
        "    elif args.seed_behavior == 'fixed':\n",
        "        pass # always keep seed the same\n",
        "    else:\n",
        "        args.seed = random.randint(0, 2**32 - 1)\n",
        "    return args.seed\n",
        "\n",
        "def render_image_batch(args):\n",
        "    args.prompts = {k: f\"{v:05d}\" for v, k in enumerate(prompts)}\n",
        "    \n",
        "    # create output folder for the batch\n",
        "    os.makedirs(args.outdir, exist_ok=True)\n",
        "    if args.save_settings or args.save_samples:\n",
        "        print(f\"Saving to {os.path.join(args.outdir, args.timestring)}_*\")\n",
        "\n",
        "    # save settings for the batch\n",
        "    if args.save_settings:\n",
        "        filename = os.path.join(args.outdir, f\"{args.timestring}_settings.txt\")\n",
        "        with open(filename, \"w+\", encoding=\"utf-8\") as f:\n",
        "            json.dump(dict(args.__dict__), f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    index = 0\n",
        "    \n",
        "    # function for init image batching\n",
        "    init_array = []\n",
        "    if args.use_init:\n",
        "        if args.init_image == \"\":\n",
        "            raise FileNotFoundError(\"No path was given for init_image\")\n",
        "        if args.init_image.startswith('http://') or args.init_image.startswith('https://'):\n",
        "            init_array.append(args.init_image)\n",
        "        elif not os.path.isfile(args.init_image):\n",
        "            if args.init_image[-1] != \"/\": # avoids path error by adding / to end if not there\n",
        "                args.init_image += \"/\" \n",
        "            for image in sorted(os.listdir(args.init_image)): # iterates dir and appends images to init_array\n",
        "                if image.split(\".\")[-1] in (\"png\", \"jpg\", \"jpeg\"):\n",
        "                    init_array.append(args.init_image + image)\n",
        "        else:\n",
        "            init_array.append(args.init_image)\n",
        "    else:\n",
        "        init_array = [\"\"]\n",
        "\n",
        "    # when doing large batches don't flood browser with images\n",
        "    clear_between_batches = args.n_batch >= 32\n",
        "\n",
        "    for iprompt, prompt in enumerate(prompts):  \n",
        "        args.prompt = prompt\n",
        "        print(f\"Prompt {iprompt+1} of {len(prompts)}\")\n",
        "        print(f\"{args.prompt}\")\n",
        "\n",
        "        all_images = []\n",
        "\n",
        "        for batch_index in range(args.n_batch):\n",
        "            if clear_between_batches and batch_index % 32 == 0: \n",
        "                display.clear_output(wait=True)            \n",
        "            print(f\"Batch {batch_index+1} of {args.n_batch}\")\n",
        "            \n",
        "            for image in init_array: # iterates the init images\n",
        "                args.init_image = image\n",
        "                results = generate(args)\n",
        "                for image in results:\n",
        "                    if args.make_grid:\n",
        "                        all_images.append(T.functional.pil_to_tensor(image))\n",
        "                    if args.save_samples:\n",
        "                        if args.filename_format == \"{timestring}_{index}_{prompt}.png\":\n",
        "                            filename = f\"{args.timestring}_{index:05}_{sanitize(prompt)[:160]}.png\"\n",
        "                        else:\n",
        "                            filename = f\"{args.timestring}_{index:05}_{args.seed}.png\"\n",
        "                        image.save(os.path.join(args.outdir, filename))\n",
        "                    if args.display_samples:\n",
        "                        display.display(image)\n",
        "                    index += 1\n",
        "                args.seed = next_seed(args)\n",
        "\n",
        "        #print(len(all_images))\n",
        "        if args.make_grid:\n",
        "            grid = make_grid(all_images, nrow=int(len(all_images)/args.grid_rows))\n",
        "            grid = rearrange(grid, 'c h w -> h w c').cpu().numpy()\n",
        "            filename = f\"{args.timestring}_{iprompt:05d}_grid_{args.seed}.png\"\n",
        "            grid_image = Image.fromarray(grid.astype(np.uint8))\n",
        "            grid_image.save(os.path.join(args.outdir, filename))\n",
        "            display.clear_output(wait=True)            \n",
        "            display.display(grid_image)\n",
        "\n",
        "\n",
        "def render_animation(args, anim_args):\n",
        "    # animations use key framed prompts\n",
        "    args.prompts = animation_prompts\n",
        "\n",
        "    # expand key frame strings to values\n",
        "    keys = DeformAnimKeys(anim_args)\n",
        "\n",
        "    # resume animation\n",
        "    start_frame = 0\n",
        "    if anim_args.resume_from_timestring:\n",
        "        for tmp in os.listdir(args.outdir):\n",
        "            if tmp.split(\"_\")[0] == anim_args.resume_timestring:\n",
        "                start_frame += 1\n",
        "        start_frame = start_frame - 1\n",
        "\n",
        "    # create output folder for the batch\n",
        "    os.makedirs(args.outdir, exist_ok=True)\n",
        "    print(f\"Saving animation frames to {args.outdir}, Timestring: {args.timestring}\")\n",
        "\n",
        "    # save settings for the batch\n",
        "    settings_filename = os.path.join(args.outdir, f\"{args.timestring}_settings.txt\")\n",
        "    with open(settings_filename, \"w+\", encoding=\"utf-8\") as f:\n",
        "        s = {**dict(args.__dict__), **dict(anim_args.__dict__)}\n",
        "        json.dump(s, f, ensure_ascii=False, indent=4)\n",
        "        \n",
        "    # resume from timestring\n",
        "    if anim_args.resume_from_timestring:\n",
        "        args.timestring = anim_args.resume_timestring\n",
        "\n",
        "    # expand prompts out to per-frame\n",
        "    prompt_series = pd.Series([np.nan for a in range(anim_args.max_frames)])\n",
        "    for i, prompt in animation_prompts.items():\n",
        "        prompt_series[i] = prompt\n",
        "    prompt_series = prompt_series.ffill().bfill()\n",
        "\n",
        "    # check for video inits\n",
        "    using_vid_init = anim_args.animation_mode == 'Video Input'\n",
        "\n",
        "    # load depth model for 3D\n",
        "    predict_depths = (anim_args.animation_mode == '3D' and anim_args.use_depth_warping) or anim_args.save_depth_maps\n",
        "    if predict_depths:\n",
        "        depth_model = DepthModel(device)\n",
        "        depth_model.load_midas(models_path)\n",
        "        if anim_args.midas_weight < 1.0:\n",
        "            depth_model.load_adabins()\n",
        "    else:\n",
        "        depth_model = None\n",
        "        anim_args.save_depth_maps = False\n",
        "\n",
        "    # state for interpolating between diffusion steps\n",
        "    turbo_steps = 1 if using_vid_init else int(anim_args.diffusion_cadence)\n",
        "    turbo_prev_image, turbo_prev_frame_idx = None, 0\n",
        "    turbo_next_image, turbo_next_frame_idx = None, 0\n",
        "\n",
        "    # resume animation\n",
        "    prev_sample = None\n",
        "    color_match_sample = None\n",
        "    if anim_args.resume_from_timestring:\n",
        "        last_frame = start_frame-1\n",
        "        if turbo_steps > 1:\n",
        "            last_frame -= last_frame%turbo_steps\n",
        "        path = os.path.join(args.outdir,f\"{args.timestring}_{last_frame:05}.png\")\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        prev_sample = sample_from_cv2(img)\n",
        "        if anim_args.color_coherence != 'None':\n",
        "            color_match_sample = img\n",
        "        if turbo_steps > 1:\n",
        "            turbo_next_image, turbo_next_frame_idx = sample_to_cv2(prev_sample, type=np.float32), last_frame\n",
        "            turbo_prev_image, turbo_prev_frame_idx = turbo_next_image, turbo_next_frame_idx\n",
        "            start_frame = last_frame+turbo_steps\n",
        "\n",
        "    args.n_samples = 1\n",
        "    frame_idx = start_frame\n",
        "    while frame_idx < anim_args.max_frames:\n",
        "        print(f\"Rendering animation frame {frame_idx} of {anim_args.max_frames}, Timestring: {args.timestring}\")\n",
        "        noise = keys.noise_schedule_series[frame_idx]\n",
        "        strength = keys.strength_schedule_series[frame_idx]\n",
        "        contrast = keys.contrast_schedule_series[frame_idx]\n",
        "        depth = None\n",
        "        \n",
        "        # emit in-between frames\n",
        "        if turbo_steps > 1:\n",
        "            tween_frame_start_idx = max(0, frame_idx-turbo_steps)\n",
        "            for tween_frame_idx in range(tween_frame_start_idx, frame_idx):\n",
        "                tween = float(tween_frame_idx - tween_frame_start_idx + 1) / float(frame_idx - tween_frame_start_idx)\n",
        "                print(f\"  creating in between frame {tween_frame_idx} tween:{tween:0.2f}\")\n",
        "\n",
        "                advance_prev = turbo_prev_image is not None and tween_frame_idx > turbo_prev_frame_idx\n",
        "                advance_next = tween_frame_idx > turbo_next_frame_idx\n",
        "\n",
        "                if depth_model is not None:\n",
        "                    assert(turbo_next_image is not None)\n",
        "                    depth = depth_model.predict(turbo_next_image, anim_args)\n",
        "\n",
        "                if anim_args.animation_mode == '2D':\n",
        "                    if advance_prev:\n",
        "                        turbo_prev_image = anim_frame_warp_2d(turbo_prev_image, args, anim_args, keys, tween_frame_idx)\n",
        "                    if advance_next:\n",
        "                        turbo_next_image = anim_frame_warp_2d(turbo_next_image, args, anim_args, keys, tween_frame_idx)\n",
        "                else: # '3D'\n",
        "                    if advance_prev:\n",
        "                        turbo_prev_image = anim_frame_warp_3d(turbo_prev_image, depth, anim_args, keys, tween_frame_idx)\n",
        "                    if advance_next:\n",
        "                        turbo_next_image = anim_frame_warp_3d(turbo_next_image, depth, anim_args, keys, tween_frame_idx)\n",
        "                turbo_prev_frame_idx = turbo_next_frame_idx = tween_frame_idx\n",
        "\n",
        "                if turbo_prev_image is not None and tween < 1.0:\n",
        "                    img = turbo_prev_image*(1.0-tween) + turbo_next_image*tween\n",
        "                else:\n",
        "                    img = turbo_next_image\n",
        "\n",
        "                filename = f\"{args.timestring}_{tween_frame_idx:05}.png\"\n",
        "                cv2.imwrite(os.path.join(args.outdir, filename), cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
        "                if anim_args.save_depth_maps:\n",
        "                    depth_model.save(os.path.join(args.outdir, f\"{args.timestring}_depth_{tween_frame_idx:05}.png\"), depth)\n",
        "            if turbo_next_image is not None:\n",
        "                prev_sample = sample_from_cv2(turbo_next_image)\n",
        "\n",
        "        # apply transforms to previous frame\n",
        "        if prev_sample is not None:\n",
        "            if anim_args.animation_mode == '2D':\n",
        "                prev_img = anim_frame_warp_2d(sample_to_cv2(prev_sample), args, anim_args, keys, frame_idx)\n",
        "            else: # '3D'\n",
        "                prev_img_cv2 = sample_to_cv2(prev_sample)\n",
        "                depth = depth_model.predict(prev_img_cv2, anim_args) if depth_model else None\n",
        "                prev_img = anim_frame_warp_3d(prev_img_cv2, depth, anim_args, keys, frame_idx)\n",
        "\n",
        "            # apply color matching\n",
        "            if anim_args.color_coherence != 'None':\n",
        "                if color_match_sample is None:\n",
        "                    color_match_sample = prev_img.copy()\n",
        "                else:\n",
        "                    prev_img = maintain_colors(prev_img, color_match_sample, anim_args.color_coherence)\n",
        "\n",
        "            # apply scaling\n",
        "            contrast_sample = prev_img * contrast\n",
        "            # apply frame noising\n",
        "            noised_sample = add_noise(sample_from_cv2(contrast_sample), noise)\n",
        "\n",
        "            # use transformed previous frame as init for current\n",
        "            args.use_init = True\n",
        "            if half_precision:\n",
        "                args.init_sample = noised_sample.half().to(device)\n",
        "            else:\n",
        "                args.init_sample = noised_sample.to(device)\n",
        "            args.strength = max(0.0, min(1.0, strength))\n",
        "\n",
        "        # grab prompt for current frame\n",
        "        args.prompt = prompt_series[frame_idx]\n",
        "        print(f\"Prompt: {args.prompt}, Seed: {args.seed}\")\n",
        "        if not using_vid_init:\n",
        "            print(f\"Angle: {keys.angle_series[frame_idx]} Zoom: {keys.zoom_series[frame_idx]}\")\n",
        "            print(f\"Tx: {keys.translation_x_series[frame_idx]} Ty: {keys.translation_y_series[frame_idx]} Tz: {keys.translation_z_series[frame_idx]}\")\n",
        "            print(f\"Rx: {keys.rotation_3d_x_series[frame_idx]} Ry: {keys.rotation_3d_y_series[frame_idx]} Rz: {keys.rotation_3d_z_series[frame_idx]}\")\n",
        "\n",
        "        # grab init image for current frame\n",
        "        if using_vid_init:\n",
        "            init_frame = os.path.join(args.outdir, 'inputframes', f\"{frame_idx+1:05}.jpg\")            \n",
        "            print(f\"Using video init frame {init_frame}\")\n",
        "            args.init_image = init_frame\n",
        "            if anim_args.use_mask_video:\n",
        "                mask_frame = os.path.join(args.outdir, 'maskframes', f\"{frame_idx+1:05}.jpg\")\n",
        "                args.mask_file = mask_frame\n",
        "\n",
        "        # sample the diffusion model\n",
        "        sample, image = generate(args, frame_idx, return_latent=False, return_sample=True)\n",
        "        if not using_vid_init:\n",
        "            prev_sample = sample\n",
        "\n",
        "        if turbo_steps > 1:\n",
        "            turbo_prev_image, turbo_prev_frame_idx = turbo_next_image, turbo_next_frame_idx\n",
        "            turbo_next_image, turbo_next_frame_idx = sample_to_cv2(sample, type=np.float32), frame_idx\n",
        "            frame_idx += turbo_steps\n",
        "        else:    \n",
        "            filename = f\"{args.timestring}_{frame_idx:05}.png\"\n",
        "            image.save(os.path.join(args.outdir, filename))\n",
        "            if anim_args.save_depth_maps:\n",
        "                if depth is None:\n",
        "                    depth = depth_model.predict(sample_to_cv2(sample), anim_args)\n",
        "                depth_model.save(os.path.join(args.outdir, f\"{args.timestring}_depth_{frame_idx:05}.png\"), depth)\n",
        "            frame_idx += 1\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(image)\n",
        "\n",
        "        args.seed = next_seed(args)\n",
        "\n",
        "def vid2frames(video_path, frames_path, n=1, overwrite=True):      \n",
        "    if not os.path.exists(frames_path) or overwrite: \n",
        "      try:\n",
        "          for f in pathlib.Path(video_in_frame_path).glob('*.jpg'):\n",
        "              f.unlink()\n",
        "      except:\n",
        "          pass\n",
        "      assert os.path.exists(video_path), f\"Video input {video_path} does not exist\"\n",
        "          \n",
        "      vidcap = cv2.VideoCapture(video_path)\n",
        "      success,image = vidcap.read()\n",
        "      count = 0\n",
        "      t=1\n",
        "      success = True\n",
        "      while success:\n",
        "        if count % n == 0:\n",
        "            cv2.imwrite(frames_path + os.path.sep + f\"{t:05}.jpg\" , image)     # save frame as JPEG file\n",
        "            t += 1\n",
        "        success,image = vidcap.read()\n",
        "        count += 1\n",
        "      print(\"Converted %d frames\" % count)\n",
        "    else: print(\"Frames already unpacked\")\n",
        "\n",
        "def render_input_video(args, anim_args):\n",
        "    # create a folder for the video input frames to live in\n",
        "    video_in_frame_path = os.path.join(args.outdir, 'inputframes') \n",
        "    os.makedirs(video_in_frame_path, exist_ok=True)\n",
        "    \n",
        "    # save the video frames from input video\n",
        "    print(f\"Exporting Video Frames (1 every {anim_args.extract_nth_frame}) frames to {video_in_frame_path}...\")\n",
        "    vid2frames(anim_args.video_init_path, video_in_frame_path, anim_args.extract_nth_frame, anim_args.overwrite_extracted_frames)\n",
        "\n",
        "    # determine max frames from length of input frames\n",
        "    anim_args.max_frames = len([f for f in pathlib.Path(video_in_frame_path).glob('*.jpg')])\n",
        "    args.use_init = True\n",
        "    print(f\"Loading {anim_args.max_frames} input frames from {video_in_frame_path} and saving video frames to {args.outdir}\")\n",
        "\n",
        "    if anim_args.use_mask_video:\n",
        "        # create a folder for the mask video input frames to live in\n",
        "        mask_in_frame_path = os.path.join(args.outdir, 'maskframes') \n",
        "        os.makedirs(mask_in_frame_path, exist_ok=True)\n",
        "\n",
        "        # save the video frames from mask video\n",
        "        print(f\"Exporting Video Frames (1 every {anim_args.extract_nth_frame}) frames to {mask_in_frame_path}...\")\n",
        "        vid2frames(anim_args.video_mask_path, mask_in_frame_path, anim_args.extract_nth_frame, anim_args.overwrite_extracted_frames)\n",
        "        args.use_mask = True\n",
        "        args.overlay_mask = True\n",
        "\n",
        "    render_animation(args, anim_args)\n",
        "\n",
        "def render_interpolation(args, anim_args):\n",
        "    # animations use key framed prompts\n",
        "    args.prompts = animation_prompts\n",
        "\n",
        "    # create output folder for the batch\n",
        "    os.makedirs(args.outdir, exist_ok=True)\n",
        "    print(f\"Saving animation frames to {args.outdir}\")\n",
        "\n",
        "    # save settings for the batch\n",
        "    settings_filename = os.path.join(args.outdir, f\"{args.timestring}_settings.txt\")\n",
        "    with open(settings_filename, \"w+\", encoding=\"utf-8\") as f:\n",
        "        s = {**dict(args.__dict__), **dict(anim_args.__dict__)}\n",
        "        json.dump(s, f, ensure_ascii=False, indent=4)\n",
        "    \n",
        "    # Interpolation Settings\n",
        "    args.n_samples = 1\n",
        "    args.seed_behavior = 'fixed' # force fix seed at the moment bc only 1 seed is available\n",
        "    prompts_c_s = [] # cache all the text embeddings\n",
        "\n",
        "    print(f\"Preparing for interpolation of the following...\")\n",
        "\n",
        "    for i, prompt in animation_prompts.items():\n",
        "      args.prompt = prompt\n",
        "\n",
        "      # sample the diffusion model\n",
        "      results = generate(args, return_c=True)\n",
        "      c, image = results[0], results[1]\n",
        "      prompts_c_s.append(c) \n",
        "      \n",
        "      # display.clear_output(wait=True)\n",
        "      display.display(image)\n",
        "      \n",
        "      args.seed = next_seed(args)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    print(f\"Interpolation start...\")\n",
        "\n",
        "    frame_idx = 0\n",
        "\n",
        "    if anim_args.interpolate_key_frames:\n",
        "      for i in range(len(prompts_c_s)-1):\n",
        "        dist_frames = list(animation_prompts.items())[i+1][0] - list(animation_prompts.items())[i][0]\n",
        "        if dist_frames <= 0:\n",
        "          print(\"key frames duplicated or reversed. interpolation skipped.\")\n",
        "          return\n",
        "        else:\n",
        "          for j in range(dist_frames):\n",
        "            # interpolate the text embedding\n",
        "            prompt1_c = prompts_c_s[i]\n",
        "            prompt2_c = prompts_c_s[i+1]  \n",
        "            args.init_c = prompt1_c.add(prompt2_c.sub(prompt1_c).mul(j * 1/dist_frames))\n",
        "\n",
        "            # sample the diffusion model\n",
        "            results = generate(args)\n",
        "            image = results[0]\n",
        "\n",
        "            filename = f\"{args.timestring}_{frame_idx:05}.png\"\n",
        "            image.save(os.path.join(args.outdir, filename))\n",
        "            frame_idx += 1\n",
        "\n",
        "            display.clear_output(wait=True)\n",
        "            display.display(image)\n",
        "\n",
        "            args.seed = next_seed(args)\n",
        "\n",
        "    else:\n",
        "      for i in range(len(prompts_c_s)-1):\n",
        "        for j in range(anim_args.interpolate_x_frames+1):\n",
        "          # interpolate the text embedding\n",
        "          prompt1_c = prompts_c_s[i]\n",
        "          prompt2_c = prompts_c_s[i+1]  \n",
        "          args.init_c = prompt1_c.add(prompt2_c.sub(prompt1_c).mul(j * 1/(anim_args.interpolate_x_frames+1)))\n",
        "\n",
        "          # sample the diffusion model\n",
        "          results = generate(args)\n",
        "          image = results[0]\n",
        "\n",
        "          filename = f\"{args.timestring}_{frame_idx:05}.png\"\n",
        "          image.save(os.path.join(args.outdir, filename))\n",
        "          frame_idx += 1\n",
        "\n",
        "          display.clear_output(wait=True)\n",
        "          display.display(image)\n",
        "\n",
        "          args.seed = next_seed(args)\n",
        "\n",
        "    # generate the last prompt\n",
        "    args.init_c = prompts_c_s[-1]\n",
        "    results = generate(args)\n",
        "    image = results[0]\n",
        "    filename = f\"{args.timestring}_{frame_idx:05}.png\"\n",
        "    image.save(os.path.join(args.outdir, filename))\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    display.display(image)\n",
        "    args.seed = next_seed(args)\n",
        "\n",
        "    #clear init_c\n",
        "    args.init_c = None\n",
        "\n",
        "\n",
        "args_dict = DeforumArgs()\n",
        "anim_args_dict = DeforumAnimArgs()\n",
        "\n",
        "if override_settings_with_file:\n",
        "    print(f\"reading custom settings from {custom_settings_file}\")\n",
        "    if not os.path.isfile(custom_settings_file):\n",
        "        print('The custom settings file does not exist. The in-notebook settings will be used instead')\n",
        "    else:\n",
        "        with open(custom_settings_file, \"r\") as f:\n",
        "            jdata = json.loads(f.read())\n",
        "            animation_prompts = jdata[\"prompts\"]\n",
        "            for i, k in enumerate(args_dict):\n",
        "                if k in jdata:\n",
        "                    args_dict[k] = jdata[k]\n",
        "                else:\n",
        "                    print(f\"key {k} doesn't exist in the custom settings data! using the default value of {args_dict[k]}\")\n",
        "            for i, k in enumerate(anim_args_dict):\n",
        "                if k in jdata:\n",
        "                    anim_args_dict[k] = jdata[k]\n",
        "                else:\n",
        "                    print(f\"key {k} doesn't exist in the custom settings data! using the default value of {anim_args_dict[k]}\")\n",
        "            print(args_dict)\n",
        "            print(anim_args_dict, args.timestring)\n",
        "\n",
        "args = SimpleNamespace(**args_dict)\n",
        "anim_args = SimpleNamespace(**anim_args_dict)\n",
        "\n",
        "args.timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "args.strength = max(0.0, min(1.0, args.strength))\n",
        "\n",
        "if args.seed == -1:\n",
        "    args.seed = random.randint(0, 2**32 - 1)\n",
        "if not args.use_init:\n",
        "    args.init_image = None\n",
        "if args.sampler == 'plms' and (args.use_init or anim_args.animation_mode != 'None'):\n",
        "    print(f\"Init images aren't supported with PLMS yet, switching to KLMS\")\n",
        "    args.sampler = 'klms'\n",
        "if args.sampler != 'ddim':\n",
        "    args.ddim_eta = 0\n",
        "\n",
        "if anim_args.animation_mode == 'None':\n",
        "    anim_args.max_frames = 1\n",
        "elif anim_args.animation_mode == 'Video Input':\n",
        "    args.use_init = True\n",
        "\n",
        "# clean up unused memory\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# dispatch to appropriate renderer\n",
        "if anim_args.animation_mode == '2D' or anim_args.animation_mode == '3D':\n",
        "    render_animation(args, anim_args)\n",
        "elif anim_args.animation_mode == 'Video Input':\n",
        "    render_input_video(args, anim_args)\n",
        "elif anim_args.animation_mode == 'Interpolation':\n",
        "    render_interpolation(args, anim_args)\n",
        "else:\n",
        "    render_image_batch(args)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5SwltX68Get",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!rm -rf '/content/drive/MyDrive/AI/StableDiffusion/2022-11/wizard'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3j6DD8ttFBsJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "%cd '/content/drive/MyDrive/AI/StableDiffusion/2022-11/disturbed'\n",
        "!ffmpeg -y -framerate 12 -pattern_type glob -i '*.png' -y \"/content/drive/MyDrive/disturbed.mp4\" -loglevel trace\n",
        "%cd '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wigsPBR9Tq5n",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "%cd '/content/'\n",
        "!ffmpeg -i '/content/drive/MyDrive/bokinator.mp4' -c:v libx264 -rc vbr -cq 21 -pix_fmt yuv420p -b:v 0 '/content/drive/MyDrive/bokinator_capcut.mp4' -loglevel trace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NMAoubrHG653"
      },
      "outputs": [],
      "source": [
        "output_filename = '/content/test.mp4'\n",
        "\n",
        "download_video = False # @param {type:'boolean'}\n",
        "compress_video = False # @param {type:'boolean'}\n",
        "\n",
        "# @markdown Compressing to `*.tar.gz`` format can reduce filesize, which in turn reduces\n",
        "# @markdown your download time. You may need to install additional software\n",
        "# @markdown to \"decompress\" the file after downloading to view your video.\n",
        "\n",
        "# @markdown NB: Your video will probably download way faster from https://drive.google.com\n",
        "\n",
        "#  NB: only embed short videos\n",
        "embed_video_in_notebook = True\n",
        "\n",
        "if compress_video:\n",
        "    uncompressed_fname = output_filename\n",
        "    output_filename = f\"{output_filename}.tar.gz\"\n",
        "    print(f\"Compressing to: {output_filename}\")\n",
        "    !tar -czvf {output_filename} {uncompressed_fname}\n",
        "\n",
        "if download_video:\n",
        "    from google.colab import files\n",
        "    files.download(output_filename)\n",
        "\n",
        "if embed_video_in_notebook:\n",
        "    from IPython.display import display, Video\n",
        "    display(Video(output_filename, embed=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yKQ5IIKpSvZa"
      },
      "outputs": [],
      "source": [
        "#@markdown **CONCEPTUALIZERS??Select and Load Model**\n",
        "model_config = \"v1-inference.yaml\" #@param [\"custom\",\"v1-inference.yaml\"]\n",
        "model_checkpoint =  \"custom\" #@param [\"custom\",\"v1-5-pruned\",\"sd-v1-4-full-ema.ckpt\",\"sd-v1-4.ckpt\",\"sd-v1-3-full-ema.ckpt\",\"sd-v1-3.ckpt\",\"sd-v1-2-full-ema.ckpt\",\"sd-v1-2.ckpt\",\"sd-v1-1-full-ema.ckpt\",\"sd-v1-1.ckpt\", \"robo-diffusion-v1.ckpt\",\"waifu-diffusion-v1-3.ckpt\"]\n",
        "if model_checkpoint == \"waifu-diffusion-v1-3.ckpt\":\n",
        "    model_checkpoint = \"model-epoch05-float16.ckpt\"\n",
        "custom_config_path = \"/content/drive/MyDrive/AI/models/vae-ft-mse-840000-ema-pruned.pt\" #@param {type:\"string\"}\n",
        "custom_checkpoint_path = \"/content/drive/MyDrive/AI/models/v1-5-pruned.ckpt\" #@param {type:\"string\"}\n",
        "custom_vae_path = \"/content/drive/MyDrive/AI/models/vae-ft-mse-840000-ema-pruned.ckpt\" #@param {type:\"string\"}\n",
        "\n",
        "repo_id_embeds = \"sd-concepts-library/vkuoo1\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown (Optional) in case you have a `learned_embeds.bin` file and not a `repo_id`, add the path to `learned_embeds.bin` to the `embeds_url` variable \n",
        "embeds_url = \"/content/drive/MyDrive/AI/models/learned_embeds.bin\" #Add the URL or path to a learned_embeds.bin file in case you have one\n",
        "placeholder_token_string = \"/content/drive/MyDrive/AI/models/token_identifier.txt\" #Add what is the token string in case you are uploading your own embed\n",
        "\n",
        "with open('/content/drive/MyDrive/AI/models/token_identifier.txt', 'r') as file:\n",
        "    placeholder_token_string = file.read()\n",
        "\n",
        "learned_embeds_path = embeds_url\n",
        "\n",
        "load_on_run_all = True #@param {type: 'boolean'}\n",
        "half_precision = False # check\n",
        "check_sha256 = True #@param {type:\"boolean\"}\n",
        "\n",
        "model_map = {\n",
        "    \"sd-v1-4-full-ema.ckpt\": {\n",
        "        'sha256': '14749efc0ae8ef0329391ad4436feb781b402f4fece4883c7ad8d10556d8a36a',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-2-original/blob/main/sd-v1-4-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-4.ckpt\": {\n",
        "        'sha256': 'fe4efff1e174c627256e44ec2991ba279b3816e364b49f9be2abc0b3ff3f8556',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-3-full-ema.ckpt\": {\n",
        "        'sha256': '54632c6e8a36eecae65e36cb0595fab314e1a1545a65209f24fde221a8d4b2ca',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-3-original/blob/main/sd-v1-3-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-3.ckpt\": {\n",
        "        'sha256': '2cff93af4dcc07c3e03110205988ff98481e86539c51a8098d4f2236e41f7f2f',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-3-original/resolve/main/sd-v1-3.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-2-full-ema.ckpt\": {\n",
        "        'sha256': 'bc5086a904d7b9d13d2a7bccf38f089824755be7261c7399d92e555e1e9ac69a',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-2-original/blob/main/sd-v1-2-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-2.ckpt\": {\n",
        "        'sha256': '3b87d30facd5bafca1cbed71cfb86648aad75d1c264663c0cc78c7aea8daec0d',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-2-original/resolve/main/sd-v1-2.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-1-full-ema.ckpt\": {\n",
        "        'sha256': 'efdeb5dc418a025d9a8cc0a8617e106c69044bc2925abecc8a254b2910d69829',\n",
        "        'url':'https://huggingface.co/CompVis/stable-diffusion-v-1-1-original/resolve/main/sd-v1-1-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-1.ckpt\": {\n",
        "        'sha256': '86cd1d3ccb044d7ba8db743d717c9bac603c4043508ad2571383f954390f3cea',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-1-original/resolve/main/sd-v1-1.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"vae-ft-mse-840000-ema-pruned.ckpt\": {\n",
        "        'sha256': 'c6a580b13a5bc05a5e16e4dbb80608ff2ec251a162311590c1f34c013d7f3dab',\n",
        "        'url': 'https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt',\n",
        "        'requires_login': False,\n",
        "        },    \n",
        "    \"robo-diffusion-v1.ckpt\": {\n",
        "        'sha256': '244dbe0dcb55c761bde9c2ac0e9b46cc9705ebfe5f1f3a7cc46251573ea14e16',\n",
        "        'url': 'https://huggingface.co/nousr/robo-diffusion/resolve/main/models/robo-diffusion-v1.ckpt',\n",
        "        'requires_login': False,\n",
        "        },\n",
        "    \"model-epoch05-float16.ckpt\": {\n",
        "        'sha256': '26cf2a2e30095926bb9fd9de0c83f47adc0b442dbfdc3d667d43778e8b70bece',\n",
        "        'url': 'https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/model-epoch05-float16.ckpt',\n",
        "        'requires_login': False,\n",
        "        },\n",
        "}\n",
        "\n",
        "# config path\n",
        "ckpt_config_path = custom_config_path if model_config == \"custom\" else os.path.join(models_path, model_config)\n",
        "if os.path.exists(ckpt_config_path):\n",
        "    print(f\"{ckpt_config_path} exists\")\n",
        "else:\n",
        "    ckpt_config_path = \"./stable-diffusion/configs/stable-diffusion/v1-inference.yaml\"\n",
        "print(f\"Using config: {ckpt_config_path}\")\n",
        "\n",
        "# checkpoint path or download\n",
        "ckpt_path = custom_checkpoint_path if model_checkpoint == \"custom\" else os.path.join(models_path, model_checkpoint)\n",
        "ckpt_valid = True\n",
        "if os.path.exists(ckpt_path):\n",
        "    print(f\"{ckpt_path} exists\")\n",
        "elif 'url' in model_map[model_checkpoint]:\n",
        "    url = model_map[model_checkpoint]['url']\n",
        "\n",
        "vae_path = custom_vae_path if model_checkpoint == \"custom\" else os.path.join(models_path, model_checkpoint)\n",
        "ckpt_valid = True\n",
        "if os.path.exists(vae_path):\n",
        "    print(f\"{vae_path} exists\")\n",
        "elif 'url' in model_map[model_checkpoint]:\n",
        "    url = model_map[model_checkpoint]['url']\n",
        "\n",
        "    # CLI dialogue to authenticate download\n",
        "    if model_map[model_checkpoint]['requires_login']:\n",
        "        print(\"This model requires an authentication token\")\n",
        "        print(\"Please ensure you have accepted its terms of service before continuing.\")\n",
        "\n",
        "        username = input(\"What is your huggingface username?:\")\n",
        "        token = input(\"What is your huggingface token?:\")\n",
        "\n",
        "        _, path = url.split(\"https://\")\n",
        "\n",
        "        url = f\"https://{username}:{token}@{path}\"\n",
        "\n",
        "    # contact server for model\n",
        "    print(f\"Attempting to download {model_checkpoint}...this may take a while\")\n",
        "    ckpt_request = requests.get(url)\n",
        "    request_status = ckpt_request.status_code\n",
        "\n",
        "    # inform user of errors\n",
        "    if request_status == 403:\n",
        "      raise ConnectionRefusedError(\"You have not accepted the license for this model.\")\n",
        "    elif request_status == 404:\n",
        "      raise ConnectionError(\"Could not make contact with server\")\n",
        "    elif request_status != 200:\n",
        "      raise ConnectionError(f\"Some other error has ocurred - response code: {request_status}\")\n",
        "\n",
        "    # write to model path\n",
        "    with open(os.path.join(models_path, model_checkpoint), 'wb') as model_file:\n",
        "        model_file.write(ckpt_request.content)\n",
        "else:\n",
        "    print(f\"Please download model checkpoint and place in {os.path.join(models_path, model_checkpoint)}\")\n",
        "    ckpt_valid = False\n",
        "\n",
        "if check_sha256 and model_checkpoint != \"custom\" and ckpt_valid:\n",
        "    import hashlib\n",
        "    print(\"\\n...checking sha256\")\n",
        "    with open(ckpt_path, \"rb\") as f:\n",
        "        bytes = f.read() \n",
        "        hash = hashlib.sha256(bytes).hexdigest()\n",
        "        del bytes\n",
        "    if model_map[model_checkpoint][\"sha256\"] == hash:\n",
        "        print(\"hash is correct\\n\")\n",
        "    else:\n",
        "        print(\"hash in not correct\\n\")\n",
        "        ckpt_valid = False\n",
        "\n",
        "if ckpt_valid:\n",
        "    print(f\"Using ckpt: {ckpt_path}\")\n",
        "\n",
        "#pretrained_model_name_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
        "pretrained_model_name_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
        "use_auth_token = \"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\"\n",
        "tokenizer = CLIPTokenizer.from_pretrained(pretrained_model_name_or_path, subfolder=\"tokenizer\", use_auth_token=True)\n",
        "text_encoder = CLIPTextModel.from_pretrained(pretrained_model_name_or_path, subfolder=\"text_encoder\", use_auth_token=True, torch_dtype=torch.float16)\n",
        "\n",
        "def load_model_from_config(config, ckpt, verbose=False, device='cuda', half_precision=False):\n",
        "    map_location = \"cuda\" #@param [\"cpu\", \"cuda\"]\n",
        "    print(f\"Loading model from {ckpt}\")\n",
        "    pl_sd = torch.load(ckpt, map_location=map_location)\n",
        "    if \"global_step\" in pl_sd:\n",
        "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
        "    sd = pl_sd[\"state_dict\"]\n",
        "    model = instantiate_from_config(config.model)\n",
        "    m, u = model.load_state_dict(sd, strict=False)\n",
        "    if len(m) > 0 and verbose:\n",
        "        print(\"missing keys:\")\n",
        "        print(m)\n",
        "    if len(u) > 0 and verbose:\n",
        "        print(\"unexpected keys:\")\n",
        "        print(u)\n",
        "\n",
        "    if half_precision:\n",
        "        model = model.half().to(device)\n",
        "    else:\n",
        "        model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def load_vae_from_config(config, vae, verbose=False, device='cuda'):\n",
        "    map_location = \"cuda\" #@param [\"cpu\", \"cuda\"]\n",
        "    print(f\"Loading vae from {vae}\")\n",
        "    pl_sd = torch.load(vae, map_location=map_location)\n",
        "    if \"global_step\" in pl_sd:\n",
        "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
        "    sd = pl_sd[\"state_dict\"]\n",
        "    vae = instantiate_from_config(config.model)\n",
        "    m, u = vae.load_state_dict(sd, strict=False)\n",
        "    if len(m) > 0 and verbose:\n",
        "        print(\"missing keys:\")\n",
        "        print(m)\n",
        "    if len(u) > 0 and verbose:\n",
        "        print(\"unexpected keys:\")\n",
        "        print(u)\n",
        "        vae = vae.to(device)\n",
        "    vae.eval()\n",
        "    return vae\n",
        "\n",
        "def load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer, token=None):\n",
        "  loaded_learned_embeds = torch.load(learned_embeds_path, map_location=\"cuda\")\n",
        "  \n",
        "  # separate token and the embeds\n",
        "  trained_token = list(loaded_learned_embeds.keys())[0]\n",
        "  embeds = loaded_learned_embeds[trained_token]\n",
        "\n",
        "  # cast to dtype of text_encoder\n",
        "  dtype = text_encoder.get_input_embeddings().weight.dtype\n",
        "  embeds.to(dtype)\n",
        "\n",
        "  # add the token in tokenizer\n",
        "  token = token if token is not None else trained_token\n",
        "  num_added_tokens = tokenizer.add_tokens(token)\n",
        "  if num_added_tokens == 0:\n",
        "    raise ValueError(f\"The tokenizer already contains the token {token}. Please pass a different `token` that is not already in the tokenizer.\")\n",
        "  \n",
        "  # resize the token embeddings\n",
        "  text_encoder.resize_token_embeddings(len(tokenizer))\n",
        "  \n",
        "  # get the id for the token and assign the embeds\n",
        "  token_id = tokenizer.convert_tokens_to_ids(token)\n",
        "  text_encoder.get_input_embeddings().weight.data[token_id] = embeds\n",
        "load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer)\n",
        "\n",
        "if load_on_run_all and ckpt_valid:\n",
        "    local_config = OmegaConf.load(f\"{ckpt_config_path}\")\n",
        "    vae = load_vae_from_config(local_config, f\"{vae_path}\")\n",
        "    vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\", text_encoder=text_encoder, tokenizer=tokenizer)\n",
        "    model = load_model_from_config(local_config, f\"{ckpt_path}\", f\"{vae}\", half_precision=half_precision)\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "#if ckpt_valid:\n",
        "    #local_config = OmegaConf.load(f\"{ckpt_config_path}\")\n",
        "    #vae = AutoencoderKL.from_pretrained(\"/content/drive/MyDrive/AI/models/vae-ft-mse-840000-ema-pruned.ckpt\")\n",
        "    #model = load_model_from_config(local_config, f\"{ckpt_path}\", half_precision=half_precision)\n",
        "    #device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    #model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrNwqctec4QZ"
      },
      "source": [
        "# Create video from frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BqwntvC1c4Qa"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "skip_video_for_run_all = False #@param {type: 'boolean'}\n",
        "fps = 30 #@param {type:\"number\"}\n",
        "#@markdown **Manual Settings**\n",
        "use_manual_settings = True #@param {type:\"boolean\"}\n",
        "image_path = \"/content/drive/MyDrive/frames_storage/upscaled_frame_storage/%05d_out.png\" #@param {type:\"string\"}\n",
        "mp4_path = \"/content/drive/MyDrive/samsmith.mp4\" #@param {type:\"string\"}\n",
        "render_steps = True  #@param {type: 'boolean'}\n",
        "path_name_modifier = \"x0_pred\" #@param [\"x0_pred\",\"x\"]\n",
        "\n",
        "\n",
        "if skip_video_for_run_all == True:\n",
        "    print('Skipping video creation, uncheck skip_video_for_run_all if you want to run it')\n",
        "else:\n",
        "    import os\n",
        "    import subprocess\n",
        "    from base64 import b64encode\n",
        "    from tqdm.autonotebook import tqdm\n",
        "\n",
        "    print(f\"{image_path} -> {mp4_path}\")\n",
        "\n",
        "    if use_manual_settings:\n",
        "        max_frames = \"876\" #@param {type:\"string\"}\n",
        "    else:\n",
        "        if render_steps: # render steps from a single image\n",
        "            fname = f\"{path_name_modifier}_%05d.png\"\n",
        "            all_step_dirs = [os.path.join(args.outdir, d) for d in os.listdir(args.outdir) if os.path.isdir(os.path.join(args.outdir,d))]\n",
        "            newest_dir = max(all_step_dirs, key=os.path.getmtime)\n",
        "            image_path = os.path.join(newest_dir, fname)\n",
        "            print(f\"Reading images from {image_path}\")\n",
        "            mp4_path = os.path.join(newest_dir, f\"{args.timestring}_{path_name_modifier}.mp4\")\n",
        "            max_frames = str(args.steps)\n",
        "        else: # render images for a video\n",
        "            image_path = os.path.join(args.outdir, f\"{args.timestring}_%05d.png\")\n",
        "            mp4_path = os.path.join(args.outdir, f\"{args.timestring}.mp4\")\n",
        "            max_frames = str(anim_args.max_frames)\n",
        "\n",
        "    # make video\n",
        "    cmd = [\n",
        "        'ffmpeg',\n",
        "        '-y',\n",
        "        '-vcodec', 'png',\n",
        "        '-r', str(fps),\n",
        "        '-start_number', str(0),\n",
        "        '-i', image_path,\n",
        "        '-frames:v', max_frames,\n",
        "        '-c:v', 'libx264',\n",
        "        '-vf',\n",
        "        f'fps={fps}',\n",
        "        '-pix_fmt', 'yuv420p',\n",
        "        '-crf', '17',\n",
        "        '-preset', 'veryfast',\n",
        "        '-pattern_type', 'sequence',\n",
        "        mp4_path\n",
        "    ]\n",
        "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    stdout, stderr = process.communicate()\n",
        "    if process.returncode != 0:\n",
        "      print(stderr)\n",
        "      raise RuntimeError(stderr)\n",
        "\n",
        "    mp4 = open(mp4_path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display.display( display.HTML(f'<video controls loop><source src=\"{data_url}\" type=\"video/mp4\"></video>') )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUUWd0FDc4QI"
      },
      "source": [
        "# **Miscellaneous Credits and Licences below**\n",
        "\n",
        "# **Deforum Stable Diffusion v0.5**\n",
        "[Stable Diffusion](https://github.com/CompVis/stable-diffusion) by Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer and the [Stability.ai](https://stability.ai/) Team. [K Diffusion](https://github.com/crowsonkb/k-diffusion) by [Katherine Crowson](https://twitter.com/RiversHaveWings). You need to get the ckpt file and put it on your Google Drive first to use this. It can be downloaded from [HuggingFace](https://huggingface.co/CompVis/stable-diffusion).\n",
        "\n",
        "Notebook by [deforum](https://discord.gg/upmXXsrwZc)\n",
        "\n",
        "By using this Notebook, you agree to the following Terms of Use, and license:\n",
        "\n",
        "**Stablity.AI Model Terms of Use**\n",
        "\n",
        "This model is open access and available to all, with a CreativeML OpenRAIL-M license further specifying rights and usage.\n",
        "\n",
        "The CreativeML OpenRAIL License specifies:\n",
        "\n",
        "You can't use the model to deliberately produce nor share illegal or harmful outputs or content\n",
        "CompVis claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license\n",
        "You may re-distribute the weights and use the model commercially and/or as a service. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully)\n",
        "\n",
        "\n",
        "Please read the full license here: https://huggingface.co/spaces/CompVis/stable-diffusion-license"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVu_TleBiHhY"
      },
      "source": [
        "# VKTRS LICENSES\n",
        "\n",
        "# ⚖️ I put on my robe and lawyer hat\n",
        "\n",
        "All other VKTRS code can be found attached here.\n",
        "\n",
        "### Notebook license\n",
        "\n",
        "This notebook and the accompanying [git repository](https://github.com/dmarx/video-killed-the-radio-star/) and its contents are shared under the MIT license.\n",
        "\n",
        "<!-- Note to self: lawyers should really be forced to use some sort of markup or pseudocode to eliminate ambiguity \n",
        "\n",
        "...oh shit, if laws were actually described in code, we could just run queries against it\n",
        "-->\n",
        "\n",
        "```\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2022 David Marx\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "```\n",
        "\n",
        "### DreamStudio API TOS\n",
        "\n",
        "The default behavior of this notebook uses the [DreamStudio](https://beta.dreamstudio.ai/) API to generate images. Users of the DreamStudio API are subject to the DreamStudio usage terms: https://beta.dreamstudio.ai/terms-of-service\n",
        "\n",
        "### Stable Diffusion\n",
        "\n",
        "As of the date of this writing (2022-09-29), all publicly available model checkpoints are subject to the restrictions of the Open RAIL license: https://huggingface.co/spaces/CompVis/stable-diffusion-license. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "INKWAB1a9hJU"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import datetime as dt\n",
        "from pathlib import Path\n",
        "import random\n",
        "import string\n",
        "\n",
        "from bokeh.models.widgets.tables import (\n",
        "    NumberFormatter, \n",
        "    BooleanFormatter,\n",
        "    CheckboxEditor,\n",
        ")\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf, DictConfig\n",
        "import pandas as pd\n",
        "import panel as pn\n",
        "import PIL\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "from vktrs.tsp import (\n",
        "    tsp_permute_frames,\n",
        "    batched_tsp_permute_frames,\n",
        ")\n",
        "\n",
        "from vktrs.utils import (\n",
        "    add_caption2image,\n",
        "    save_frame,\n",
        "    remove_punctuation,\n",
        "    get_image_sequence,\n",
        "    archive_images,\n",
        ")\n",
        "\n",
        "# to do: is there a way to check if this is in the env already?\n",
        "pn.extension('tabulator')\n",
        "\n",
        "# this processes optional edits to the transcription (above) \n",
        "if ('prompt_starts' in locals()) \\\n",
        "and ('df_pre' in locals()):\n",
        "    if isinstance(prompt_starts, DictConfig):\n",
        "        prompt_starts = OmegaConf.to_container(prompt_starts)\n",
        "    # update prompt_starts if any changes were made above\n",
        "    if not np.all(df_pre.values == df.values):\n",
        "        df_pre = copy.deepcopy(df)\n",
        "        for i, rec in enumerate(prompt_starts):\n",
        "            rec['ts'] = float(df.loc[i,'Timestamp (sec)'])\n",
        "            rec['prompt'] = df.loc[i,'Lyric']\n",
        "            rec['override_prompt'] = df.loc[i,'override_prompt']\n",
        "        \n",
        "        # ...actually, I think the above code might not do anything\n",
        "        # probably need to checkpoint prompt_starts into the storyboard on disk.\n",
        "        # let's do that here just to be safe.    \n",
        "        workspace = OmegaConf.load('config.yaml')\n",
        "        root = Path(workspace.project_root)\n",
        "\n",
        "        storyboard_fname = root / 'storyboard.yaml'\n",
        "        storyboard = OmegaConf.load(storyboard_fname)\n",
        "\n",
        "        storyboard.prompt_starts = prompt_starts\n",
        "        with open(storyboard_fname) as fp:\n",
        "            OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "\n",
        "#####################################\n",
        "# @title ## 🎨 Generate init images\n",
        "#####################################\n",
        "\n",
        "workspace = OmegaConf.load('config.yaml')\n",
        "root = Path(workspace.project_root)\n",
        "\n",
        "storyboard_fname = root / 'storyboard.yaml'\n",
        "storyboard = OmegaConf.load(storyboard_fname)\n",
        "\n",
        "prompt_starts = storyboard.prompt_starts\n",
        "use_stability_api = workspace.use_stability_api\n",
        "use_custom_model = False # @param {type: 'boolean'}\n",
        "model_dir = workspace.model_dir\n",
        "\n",
        "# if use_stability_api:\n",
        "#     from vktrs.api import get_image_for_prompt\n",
        "\n",
        "# elif use_custom_model:\n",
        "#   model_path='/content/drive/MyDrive/AI/models/v1-5-pruned.ckpt/'\n",
        "\n",
        "# else 'hf_helper' not in locals():\n",
        "#   from vktrs.hf import HfHelper\n",
        "#     # this needs to not be in the same cell as the login.\n",
        "#     # some sort of stupid race condition.\n",
        "#   try:\n",
        "#       hf_helper = HfHelper(\n",
        "#           download=False,\n",
        "#           model_path=str(Path(model_dir) / 'huggingface' / 'diffusers')\n",
        "#       )\n",
        "#   except:\n",
        "#       hf_helper = HfHelper(\n",
        "#           download=True,\n",
        "#           model_path=str(Path(model_dir) / 'huggingface' / 'diffusers')\n",
        "#       )\n",
        "\n",
        "# I give up.\n",
        "#def get_image_for_prompt(*args, **kargs):\n",
        "#        result = hf_helper.get_image_for_prompt(*args, **kargs)\n",
        "#        return result.images\n",
        "\n",
        "\n",
        "#def get_variations_w_init(prompt, init_image, **kargs):\n",
        "#    return list(get_image_for_prompt(prompt=prompt, init_image=init_image, **kargs))\n",
        "\n",
        "#def get_close_variations_from_prompt(prompt, n_variations=2, image_consistency=.7):\n",
        "#    \"\"\"\n",
        "#    prompt: a text prompt\n",
        "#    n_variations: total number of images to return\n",
        "#    image_consistency: float in [0,1], controls similarity between images generated by the prompt.\n",
        "#                        you can think of this as controlling how much \"visual vibration\" there will be.\n",
        "#                        - 0=regenerate each iandely identical\n",
        "#    \"\"\"\n",
        "#   images = list(get_image_for_prompt(prompt))\n",
        "#    for _ in range(n_variations - 1):\n",
        "#        img = get_variations_w_init(prompt, images[0], start_schedule=(1-image_consistency))[0]\n",
        "#        images.append(img)\n",
        "#    return images\n",
        "\n",
        "\n",
        "d_ = dict(\n",
        "    _=''\n",
        "    , theme_prompt = \"radioactive, very very detailed, cinematic, 4k, 8k, 32k, trending on artstation, very very aesthetic, ultra high quality\" # @param {type:'string'}\n",
        "    , height = 512 # @param {type:'integer'}\n",
        "    , width = 896 # @param {type:'integer'}\n",
        "    , display_frames_as_we_get_them = False # @param {type:'boolean'}\n",
        ")\n",
        "d_.pop('_')\n",
        "\n",
        "regenerate_all_init_images = False # @param {type:'boolean'}\n",
        "\n",
        "prompt_lag = True # @param {type:'boolean'}\n",
        "\n",
        "# @markdown `theme_prompt` - Text that will be appended to the end of each lyric, useful for e.g. applying a consistent aesthetic style\n",
        "\n",
        "# @markdown `display_frames_as_we_get_them` - Displaying frames will make the notebook slightly slower\n",
        "\n",
        "# regenerate all images if the theme prompt has changed or user specifies\n",
        "\n",
        "# @markdown `prompt_lag` - Extend prompt with lyrics from previous frame. Can improve temporal consistency of narrative. \n",
        "# @markdown  Especially useful for lyrics segmented into short prompts.\n",
        "\n",
        "if d_['theme_prompt'] != storyboard.params.get('theme_prompt'):\n",
        "    regenerate_all_init_images = True\n",
        "\n",
        "storyboard.params.update(d_)\n",
        "\n",
        "# if regenerate_all_init_images:\n",
        "#     for i, rec in enumerate(prompt_starts):\n",
        "#         rec['frame0_fpath'] = None\n",
        "#         archive_images(i, root=root)\n",
        "#     print(\"archival process complete\")\n",
        "\n",
        "# anchor images will be regenerated if there's no associated frame0_fpath\n",
        "# regenerate specific images if\n",
        "# * manually tagged by user in df_regen\n",
        "# * associated fpath doesn't exist (i.e. deleted)\n",
        "# if 'df_regen' in locals():\n",
        "#     for i, _ in df_regen.iterrows():\n",
        "#         rec = prompt_starts[i]\n",
        "#         regen = not _['keep']\n",
        "#         if rec.get('frame0_fpath') is None:\n",
        "#             regen = True\n",
        "#         elif not Path(rec['frame0_fpath']).exists():\n",
        "#             regen=True\n",
        "#         if regen:\n",
        "#             rec['frame0_fpath'] = None\n",
        "#             rec['prompt'] = df_regen.loc[i, 'Lyric']\n",
        "#             rec['override_prompt'] = df_regen.loc[i, 'override_prompt']\n",
        "#             print(rec)\n",
        "#             archive_images(i, root=root)\n",
        "#     print(\"archival process complete\")\n",
        "\n",
        "\n",
        "theme_prompt = storyboard.params.theme_prompt\n",
        "display_frames_as_we_get_them = storyboard.params.display_frames_as_we_get_them\n",
        "height = storyboard.params.height\n",
        "width = storyboard.params.width\n",
        "\n",
        "proj_name = workspace.active_project\n",
        "\n",
        "# print(\"Ensuring each prompt has an associated image\")\n",
        "# for idx, rec in enumerate(prompt_starts):\n",
        "#     lyric = rec['prompt']\n",
        "#     prompt = f\"{lyric}, {theme_prompt}\"\n",
        "#     override = rec.get('override_prompt','').strip()\n",
        "#     if override:\n",
        "#         print('override prompt detected')\n",
        "#         prompt = override\n",
        "#     print(\n",
        "#         f\"\\n[{idx} | {rec['ts']}] - {lyric} - {prompt}\"\n",
        "#     )\n",
        "for idx, rec in enumerate(prompt_starts):\n",
        "  lyric = rec['prompt']\n",
        "prompt = f\"{lyric}, {theme_prompt}\"\n",
        "override = rec.get('override_prompt','').strip()\n",
        "if override:\n",
        "  print('override prompt detected')\n",
        "  prompt = override\n",
        "  print(\n",
        "    f\"\\n[{rec['ts']}] - {lyric} - {prompt}\"\n",
        "  )\n",
        "\n",
        "#     if prompt_lag and (idx > 0):\n",
        "#         rec_prev = prompt_starts[idx -1]\n",
        "#         prev_prompt = rec_prev.get('override_prompt','').strip()\n",
        "#         if not prev_prompt:\n",
        "#             prev_prompt = rec_prev['prompt']\n",
        "#         prompt = f\"{prev_prompt}, {prompt}\"\n",
        "#     if rec.get('frame0_fpath') is None:\n",
        "#         init_image = list(get_image_for_prompt(\n",
        "#               prompt,\n",
        "#               height=height,\n",
        "#               width=width,\n",
        "#               )\n",
        "#           )[0]\n",
        "#     # this shouldn't be necessary, but is a consequence of\n",
        "#     # the globbing thing we're doing atm\n",
        "#     if 'anchor' not in str(rec.get('frame0_fpath')):\n",
        "#         rec['frame0_fpath'] = save_frame(\n",
        "#             init_image,\n",
        "#             idx,\n",
        "#             root_path = root / 'frames',\n",
        "#             name='anchor',\n",
        "#             )\n",
        "\n",
        "#         if display_frames_as_we_get_them:\n",
        "#             print(lyric)\n",
        "#             display(init_image)\n",
        "\n",
        "\n",
        "##############\n",
        "# checkpoint #\n",
        "##############\n",
        "\n",
        "prompt_starts_copy = copy.deepcopy(prompt_starts)\n",
        "storyboard.prompt_starts = prompt_starts_copy\n",
        "\n",
        "with open(storyboard_fname) as fp:\n",
        "    OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "\n",
        "###############\n",
        "# flag regens #\n",
        "###############\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown NB: When this cell finishes running, a table will appear at the bottom of the output window. This table is editable and can be used to correct errors in the transcription (see above).\n",
        "\n",
        "# @markdown Additionally, this table can be used to trigger regeneration of\n",
        "# @markdown images you don't want to keep. On the far left of the table, you\n",
        "# @markdown you should see a `keep` column that defaults to \"true\". Double \n",
        "# @markdown clicking this value should flip it to \"false\". Rerunning this cell\n",
        "# @markdown will regenerate the `init_image` for all scenes where `keep=false`.\n",
        "# @markdown Images that are flagged for regeneration will be moved to the\n",
        "# @markdown project's `archive` folder.\n",
        "\n",
        "# @markdown Image regeneration can also be triggered by deleting the image from \n",
        "# @markdown the `frames` folder.\n",
        "\n",
        "\n",
        "# df_regen = pd.DataFrame(prompt_starts)\n",
        "# if 'override_prompt' not in df_regen:\n",
        "#     df_regen['override_prompt'] = ''\n",
        "\n",
        "# df_regen = df_regen[['ts','prompt','override_prompt']].rename(\n",
        "#     columns={\n",
        "#         'ts':'Timestamp (sec)',\n",
        "#         'prompt':'Lyric',\n",
        "#     }\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "# df_regen['keep'] = True\n",
        "\n",
        "# # move the \"keep\" column to the front\n",
        "# df_regen= df_regen[['keep', 'Timestamp (sec)', 'Lyric', 'override_prompt']]\n",
        "\n",
        "pn.widgets.Tabulator(\n",
        "    #df_regen,\n",
        "    formatters={'bool': BooleanFormatter()},\n",
        "    editors={'bool':CheckboxEditor()}\n",
        "    )\n",
        "\n",
        "print(\n",
        "    f\"\\n[{rec['ts']}] - {lyric} - {prompt}\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RTUFeyQqCfd"
      },
      "source": [
        "## $3.$ 🎬 Animate for VKTRS, null for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Sh514DGj_sua"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import datetime as dt\n",
        "from pathlib import Path\n",
        "import random\n",
        "import string\n",
        "\n",
        "from bokeh.models.widgets.tables import (\n",
        "    NumberFormatter, \n",
        "    BooleanFormatter,\n",
        "    CheckboxEditor,\n",
        ")\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf, DictConfig\n",
        "import pandas as pd\n",
        "import panel as pn\n",
        "import PIL\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "from vktrs.tsp import (\n",
        "    tsp_permute_frames,\n",
        "    batched_tsp_permute_frames,\n",
        ")\n",
        "\n",
        "from vktrs.utils import (\n",
        "    add_caption2image,\n",
        "    save_frame,\n",
        "    remove_punctuation,\n",
        "    get_image_sequence,\n",
        "    archive_images,\n",
        ")\n",
        "\n",
        "# to do: is there a way to check if this is in the env already?\n",
        "pn.extension('tabulator')\n",
        "\n",
        "# this processes optional edits to the transcription (above) \n",
        "if ('prompt_starts' in locals()) \\\n",
        "and ('df_pre' in locals()):\n",
        "    if isinstance(prompt_starts, DictConfig):\n",
        "        prompt_starts = OmegaConf.to_container(prompt_starts)\n",
        "    # update prompt_starts if any changes were made above\n",
        "    if not np.all(df_pre.values == df.values):\n",
        "        df_pre = copy.deepcopy(df)\n",
        "        for i, rec in enumerate(prompt_starts):\n",
        "            rec['ts'] = float(df.loc[i,'Timestamp (sec)'])\n",
        "            rec['prompt'] = df.loc[i,'Lyric']\n",
        "            rec['override_prompt'] = df.loc[i,'override_prompt']\n",
        "        \n",
        "        # ...actually, I think the above code might not do anything\n",
        "        # probably need to checkpoint prompt_starts into the storyboard on disk.\n",
        "        # let's do that here just to be safe.    \n",
        "        workspace = OmegaConf.load('config.yaml')\n",
        "        root = Path(workspace.project_root)\n",
        "\n",
        "        storyboard_fname = root / 'storyboard.yaml'\n",
        "        storyboard = OmegaConf.load(storyboard_fname)\n",
        "\n",
        "        storyboard.prompt_starts = prompt_starts\n",
        "        with open(storyboard_fname) as fp:\n",
        "            OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "\n",
        "#####################################\n",
        "# @title ## 🎨 Generate init images\n",
        "#####################################\n",
        "\n",
        "workspace = OmegaConf.load('config.yaml')\n",
        "root = Path(workspace.project_root)\n",
        "\n",
        "storyboard_fname = root / 'storyboard.yaml'\n",
        "storyboard = OmegaConf.load(storyboard_fname)\n",
        "\n",
        "prompt_starts = storyboard.prompt_starts\n",
        "use_stability_api = workspace.use_stability_api\n",
        "use_custom_model = False # @param {type: 'boolean'}\n",
        "model_dir = workspace.model_dir\n",
        "\n",
        "if use_stability_api:\n",
        "    from vktrs.api import get_image_for_prompt\n",
        "\n",
        "elif use_custom_model:\n",
        "  model_path='/content/drive/MyDrive/AI/models/v1-5-pruned.ckpt/'\n",
        "\n",
        "elif 'hf_helper' not in locals():\n",
        "  from vktrs.hf import HfHelper\n",
        "    # this needs to not be in the same cell as the login.\n",
        "    # some sort of stupid race condition.\n",
        "  try:\n",
        "      hf_helper = HfHelper(\n",
        "          download=False,\n",
        "          model_path=str(Path(model_dir) / 'huggingface' / 'diffusers')\n",
        "      )\n",
        "  except:\n",
        "      hf_helper = HfHelper(\n",
        "          download=True,\n",
        "          model_path=str(Path(model_dir) / 'huggingface' / 'diffusers')\n",
        "      )\n",
        "\n",
        "# I give up.\n",
        "def get_image_for_prompt(*args, **kargs):\n",
        "        result = hf_helper.get_image_for_prompt(*args, **kargs)\n",
        "        return result.images\n",
        "\n",
        "\n",
        "def get_variations_w_init(prompt, init_image, **kargs):\n",
        "    return list(get_image_for_prompt(prompt=prompt, init_image=init_image, **kargs))\n",
        "\n",
        "def get_close_variations_from_prompt(prompt, n_variations=2, image_consistency=.7):\n",
        "    \"\"\"\n",
        "    prompt: a text prompt\n",
        "    n_variations: total number of images to return\n",
        "    image_consistency: float in [0,1], controls similarity between images generated by the prompt.\n",
        "                        you can think of this as controlling how much \"visual vibration\" there will be.\n",
        "                        - 0=regenerate each iandely identical\n",
        "    \"\"\"\n",
        "    images = list(get_image_for_prompt(prompt))\n",
        "    for _ in range(n_variations - 1):\n",
        "        img = get_variations_w_init(prompt, images[0], start_schedule=(1-image_consistency))[0]\n",
        "        images.append(img)\n",
        "    return images\n",
        "\n",
        "\n",
        "d_ = dict(\n",
        "    _=''\n",
        "    , theme_prompt = \"very very detailed, super resolution, cinematic, 4k, 8k, 32k, trending on artstation, very very aesthetic, ultra high quality\" # @param {type:'string'}\n",
        "    , height = 512 # @param {type:'integer'}\n",
        "    , width = 896 # @param {type:'integer'}\n",
        "    , display_frames_as_we_get_them = False # @param {type:'boolean'}\n",
        ")\n",
        "d_.pop('_')\n",
        "\n",
        "regenerate_all_init_images = False # @param {type:'boolean'}\n",
        "\n",
        "prompt_lag = True # @param {type:'boolean'}\n",
        "\n",
        "# @markdown `theme_prompt` - Text that will be appended to the end of each lyric, useful for e.g. applying a consistent aesthetic style\n",
        "\n",
        "# @markdown `display_frames_as_we_get_them` - Displaying frames will make the notebook slightly slower\n",
        "\n",
        "# regenerate all images if the theme prompt has changed or user specifies\n",
        "\n",
        "# @markdown `prompt_lag` - Extend prompt with lyrics from previous frame. Can improve temporal consistency of narrative. \n",
        "# @markdown  Especially useful for lyrics segmented into short prompts.\n",
        "\n",
        "if d_['theme_prompt'] != storyboard.params.get('theme_prompt'):\n",
        "    regenerate_all_init_images = True\n",
        "\n",
        "storyboard.params.update(d_)\n",
        "\n",
        "if regenerate_all_init_images:\n",
        "    for i, rec in enumerate(prompt_starts):\n",
        "        rec['frame0_fpath'] = None\n",
        "        archive_images(i, root=root)\n",
        "    print(\"archival process complete\")\n",
        "\n",
        "# anchor images will be regenerated if there's no associated frame0_fpath\n",
        "# regenerate specific images if\n",
        "# * manually tagged by user in df_regen\n",
        "# * associated fpath doesn't exist (i.e. deleted)\n",
        "if 'df_regen' in locals():\n",
        "    for i, _ in df_regen.iterrows():\n",
        "        rec = prompt_starts[i]\n",
        "        regen = not _['keep']\n",
        "        if rec.get('frame0_fpath') is None:\n",
        "            regen = True\n",
        "        elif not Path(rec['frame0_fpath']).exists():\n",
        "            regen=True\n",
        "        if regen:\n",
        "            rec['frame0_fpath'] = None\n",
        "            rec['prompt'] = df_regen.loc[i, 'Lyric']\n",
        "            rec['override_prompt'] = df_regen.loc[i, 'override_prompt']\n",
        "            print(rec)\n",
        "            archive_images(i, root=root)\n",
        "    print(\"archival process complete\")\n",
        "\n",
        "\n",
        "theme_prompt = storyboard.params.theme_prompt\n",
        "display_frames_as_we_get_them = storyboard.params.display_frames_as_we_get_them\n",
        "height = storyboard.params.height\n",
        "width = storyboard.params.width\n",
        "\n",
        "proj_name = workspace.active_project\n",
        "\n",
        "print(\"Ensuring each prompt has an associated image\")\n",
        "for idx, rec in enumerate(prompt_starts):\n",
        "    lyric = rec['prompt']\n",
        "    prompt = f\"{lyric}, {theme_prompt}\"\n",
        "    override = rec.get('override_prompt','').strip()\n",
        "    if override:\n",
        "        print('override prompt detected')\n",
        "        prompt = override\n",
        "    print(\n",
        "        f\"\\n[{idx} | {rec['ts']}] - {lyric} - {prompt}\"\n",
        "    )\n",
        "    \n",
        "    if prompt_lag and (idx > 0):\n",
        "        rec_prev = prompt_starts[idx -1]\n",
        "        prev_prompt = rec_prev.get('override_prompt','').strip()\n",
        "        if not prev_prompt:\n",
        "            prev_prompt = rec_prev['prompt']\n",
        "        prompt = f\"{prev_prompt}, {prompt}\"\n",
        "    if rec.get('frame0_fpath') is None:\n",
        "        init_image = list(get_image_for_prompt(\n",
        "              prompt,\n",
        "              height=height,\n",
        "              width=width,\n",
        "              )\n",
        "          )[0]\n",
        "    # this shouldn't be necessary, but is a consequence of\n",
        "    # the globbing thing we're doing atm\n",
        "    if 'anchor' not in str(rec.get('frame0_fpath')):\n",
        "        rec['frame0_fpath'] = save_frame(\n",
        "            init_image,\n",
        "            idx,\n",
        "            root_path = root / 'frames',\n",
        "            name='anchor',\n",
        "            )\n",
        "\n",
        "        if display_frames_as_we_get_them:\n",
        "            print(lyric)\n",
        "            display(init_image)\n",
        "\n",
        "\n",
        "##############\n",
        "# checkpoint #\n",
        "##############\n",
        "\n",
        "prompt_starts_copy = copy.deepcopy(prompt_starts)\n",
        "storyboard.prompt_starts = prompt_starts_copy\n",
        "\n",
        "with open(storyboard_fname) as fp:\n",
        "    OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "\n",
        "###############\n",
        "# flag regens #\n",
        "###############\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown NB: When this cell finishes running, a table will appear at the bottom of the output window. This table is editable and can be used to correct errors in the transcription (see above).\n",
        "\n",
        "# @markdown Additionally, this table can be used to trigger regeneration of\n",
        "# @markdown images you don't want to keep. On the far left of the table, you\n",
        "# @markdown you should see a `keep` column that defaults to \"true\". Double \n",
        "# @markdown clicking this value should flip it to \"false\". Rerunning this cell\n",
        "# @markdown will regenerate the `init_image` for all scenes where `keep=false`.\n",
        "# @markdown Images that are flagged for regeneration will be moved to the\n",
        "# @markdown project's `archive` folder.\n",
        "\n",
        "# @markdown Image regeneration can also be triggered by deleting the image from \n",
        "# @markdown the `frames` folder.\n",
        "\n",
        "\n",
        "df_regen = pd.DataFrame(prompt_starts)\n",
        "if 'override_prompt' not in df_regen:\n",
        "    df_regen['override_prompt'] = ''\n",
        "\n",
        "df_regen = df_regen[['ts','prompt','override_prompt']].rename(\n",
        "    columns={\n",
        "        'ts':'Timestamp (sec)',\n",
        "        'prompt':'Lyric',\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "df_regen['keep'] = True\n",
        "\n",
        "# move the \"keep\" column to the front\n",
        "df_regen= df_regen[['keep', 'Timestamp (sec)', 'Lyric', 'override_prompt']]\n",
        "\n",
        "pn.widgets.Tabulator(\n",
        "    df_regen,\n",
        "    formatters={'bool': BooleanFormatter()},\n",
        "    editors={'bool':CheckboxEditor()}\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4AgMgvYusAo4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# @title ## 🚀 Generate animation frames\n",
        "\n",
        "###################\n",
        "# improved resume #\n",
        "###################\n",
        "\n",
        "import copy\n",
        "import datetime as dt\n",
        "from itertools import cycle\n",
        "from pathlib import Path\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from vktrs.utils import (\n",
        "    add_caption2image,\n",
        "    get_image_sequence,\n",
        ")\n",
        "\n",
        "\n",
        "workspace = OmegaConf.load('config.yaml')\n",
        "root = Path(workspace.project_root)\n",
        "\n",
        "storyboard_fname = root / 'storyboard.yaml'\n",
        "storyboard = OmegaConf.load(storyboard_fname)\n",
        "\n",
        "if not 'prompt_starts' in locals():\n",
        "    prompt_starts = OmegaConf.to_container(storyboard.prompt_starts)\n",
        "else:\n",
        "    ##########################\n",
        "    # checkpoint any changes #\n",
        "    ##########################\n",
        "    prompt_starts_copy = copy.deepcopy(prompt_starts)\n",
        "\n",
        "    storyboard.prompt_starts = prompt_starts_copy\n",
        "\n",
        "    with open(storyboard_fname) as fp:\n",
        "        OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Math                                          #\n",
        "#                                               #\n",
        "#    This block computes how many frames are    #\n",
        "#    needed for each segment based on the start #\n",
        "#    times for each prompt                      #\n",
        "#################################################\n",
        "\n",
        "# to do: \n",
        "# * make this more portable and add to vktrs lib\n",
        "\n",
        "fps = 30 # @param {type:'integer'}\n",
        "storyboard.params.fps = fps\n",
        "\n",
        "ifps = 1/fps\n",
        "\n",
        "# estimate video end\n",
        "video_duration = storyboard.params['video_duration']\n",
        "\n",
        "# dummy prompt for last scene duration\n",
        "prompt_starts = OmegaConf.to_container(storyboard.prompt_starts)\n",
        "prompt_starts.append({'ts':video_duration})\n",
        "\n",
        "# make sure we respect the duration of the previous phrase\n",
        "frame_start=0\n",
        "prompt_starts[0]['anim_start']=frame_start\n",
        "for i, rec in enumerate(prompt_starts[1:], start=1):\n",
        "    rec_prev = prompt_starts[i-1]\n",
        "    k=0\n",
        "    while (rec_prev['anim_start'] + k*ifps) < rec['ts']:\n",
        "        k+=1\n",
        "    k-=1\n",
        "    rec_prev['frames'] = k\n",
        "    rec_prev['anim_duration'] = k*ifps\n",
        "    frame_start+=k*ifps\n",
        "    rec['anim_start']=frame_start\n",
        "\n",
        "# drop the dummy frame\n",
        "prompt_starts = prompt_starts[:-1]\n",
        "\n",
        "# to do: given a 0 duration prompt, assume its duration is captured in the next prompt \n",
        "#        and guesstimate a corrected prompt start time and duration \n",
        "\n",
        "\n",
        "##############\n",
        "# checkpoint #\n",
        "##############\n",
        "\n",
        "prompt_starts_copy = copy.deepcopy(prompt_starts)\n",
        "\n",
        "storyboard.prompt_starts = prompt_starts_copy\n",
        "\n",
        "with open(storyboard_fname) as fp:\n",
        "    OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "\n",
        "##################################\n",
        "# Generate animation frames #\n",
        "##################################\n",
        "\n",
        "d_ = dict(\n",
        "    _=''\n",
        "    , n_variations=5 # @param {type:'integer'}\n",
        "    , image_consistency=0.8 # @param {type:\"slider\", min:0, max:1, step:0.01}  \n",
        "    , max_video_duration_in_seconds = 300 # @param {type:'integer'}\n",
        ")\n",
        "d_.pop('_')\n",
        "\n",
        "\n",
        "# @markdown `fps` - Frames-per-second of generated animations\n",
        "\n",
        "# @markdown `n_variations` - How many unique variations to generate for a given text prompt. This determines the frequency of the visual \"pulsing\" effect\n",
        "\n",
        "# @markdown `image_consistency` - controls similarity between images generated by the prompt.\n",
        "# @markdown - 0: ignore the init image\n",
        "# @markdown - 1: true as possible to the init image\n",
        "\n",
        "# @markdown `max_video_duration_in_seconds` - Early stopping if you don't want to generate a video the full duration of the provided audio. Default = 5min.\n",
        "\n",
        "\n",
        "storyboard.params.update(d_)\n",
        "storyboard.params.max_frames = storyboard.params.fps * storyboard.params.max_video_duration_in_seconds\n",
        "\n",
        "# to do: compute and report unique of image generations\n",
        "\n",
        "display_frames_as_we_get_them = storyboard.params.display_frames_as_we_get_them\n",
        "image_consistency = storyboard.params.image_consistency\n",
        "max_frames = storyboard.params.max_frames\n",
        "\n",
        "n_variations = storyboard.params.n_variations\n",
        "theme_prompt = storyboard.params.get('theme_prompt')\n",
        "\n",
        "\n",
        "# load init_images and generate variations as needed\n",
        "# to do: request multiple images in single request\n",
        "print(\"Fetching variations\")\n",
        "for idx, rec in enumerate(prompt_starts):\n",
        "    new_images = []\n",
        "    images_fpaths = get_image_sequence(idx, root=root)\n",
        "    curr_variation_count = len(images_fpaths)\n",
        "    print(curr_variation_count)\n",
        "    if curr_variation_count < n_variations:\n",
        "        # to do: \n",
        "        # * prompt lag\n",
        "        lyric = rec['prompt']\n",
        "        prompt = f\"{lyric}, {theme_prompt}\"\n",
        "        if rec.get('override_prompt'):\n",
        "            prompt = rec['override_prompt']\n",
        "\n",
        "        init_image = Image.open(rec['frame0_fpath'])\n",
        "        # next line is here to permit user to specify more variations for a specific entry\n",
        "        tot_variations = rec.get('n_variations', n_variations)\n",
        "        tot_variations = min(tot_variations, rec['frames']) # don't generate variations we won't use\n",
        "        tot_variations -= curr_variation_count  # only generate variations we still need\n",
        "        for _ in range(tot_variations):\n",
        "            img = get_variations_w_init(prompt, init_image, start_schedule=(1-image_consistency))[0]\n",
        "            save_frame(\n",
        "                img,\n",
        "                idx,\n",
        "                root_path= root / 'frames',\n",
        "            )\n",
        "            if display_frames_as_we_get_them:\n",
        "                display(img)\n",
        "\n",
        "\n",
        "##############\n",
        "# checkpoint #\n",
        "##############\n",
        "\n",
        "prompt_starts_copy = copy.deepcopy(prompt_starts)\n",
        "\n",
        "storyboard.prompt_starts = prompt_starts_copy\n",
        "\n",
        "# to do: deal with these td objects\n",
        "with open(storyboard_fname) as fp:\n",
        "    OmegaConf.save(config=storyboard, f=fp.name)\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Running this cell will generate as many variation frames as required \n",
        "# @markdown per `n_variations`. To trigger regeneration of images that didn't\n",
        "# @markdown generate correctly (e.g. because a nsfw classifier was triggered),\n",
        "# @markdown just delete those images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cEwFI6kA_2SH"
      },
      "outputs": [],
      "source": [
        "# @title ## 🎞️ Compile your video!\n",
        "\n",
        "import shutil\n",
        "from subprocess import Popen, PIPE\n",
        "\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from itertools import cycle\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "try:\n",
        "    from prefetch_generator import BackgroundGenerator\n",
        "except:\n",
        "    !pip install prefetch_generator\n",
        "    from prefetch_generator import BackgroundGenerator\n",
        "\n",
        "from vktrs.tsp import (\n",
        "    tsp_permute_frames,\n",
        "    batched_tsp_permute_frames,\n",
        ")\n",
        "\n",
        "from vktrs.utils import (\n",
        "    add_caption2image,\n",
        "    get_image_sequence,\n",
        "    save_frame,\n",
        "    remove_punctuation,\n",
        ")\n",
        "\n",
        "\n",
        "# reload config\n",
        "workspace = OmegaConf.load('config.yaml')\n",
        "root = Path(workspace.project_root)\n",
        "\n",
        "storyboard_fname = root / 'storyboard.yaml'\n",
        "storyboard = OmegaConf.load(storyboard_fname)\n",
        "\n",
        "########################\n",
        "# rendering parameters #\n",
        "########################\n",
        "\n",
        "output_filename = 'godzilla1.mp4' # @param {type:'string'}\n",
        "add_caption = True # @param {type:'boolean'}\n",
        "optimal_ordering = True # @param {type:'boolean'}\n",
        "upscale = False # @param {type:'boolean'}\n",
        "\n",
        "# @markdown `add_caption` - Whether or not to overlay the prompt text on the image\n",
        "\n",
        "# @markdown `optimal_ordering` - Intelligently permutes animation frames to provide a smoother animation.\n",
        "\n",
        "# @markdown  `upscale`: Naively (lanczos interpolation) upscale video 2x. This can be a way to force\n",
        "# @markdown  services like youtube to deliver your video without mangling it with compression\n",
        "# @markdown  artifacts. Thanks [@gandamu_ml](https://twitter.com/gandamu_ml) for this trick!\n",
        "\n",
        "\n",
        "# this parameter is currently not exposed in the form\n",
        "max_variations_per_opt_pass = 15\n",
        "\n",
        "if optimal_ordering:\n",
        "    opt_batch_size = min(storyboard.params.n_variations, max_variations_per_opt_pass)\n",
        "\n",
        "# I think it might be more efficient to write the video to the local disk first, then move it\n",
        "# afterwards, rather than writing into google drive\n",
        "final_output_filename = str( root / output_filename )\n",
        "storyboard.params.output_filename = final_output_filename\n",
        "\n",
        "# to do: move/duplicate fps computations here (?)\n",
        "fps = storyboard.params.fps\n",
        "input_audio = storyboard.params.audio_fpath\n",
        "\n",
        "#####################################\n",
        "\n",
        "# helper function for readability\n",
        "def process_sequence(idx):\n",
        "    im_paths = get_image_sequence(idx, root)\n",
        "    images = [Image.open(fp) for fp in im_paths]\n",
        "    \n",
        "    if add_caption:\n",
        "        rec = prompt_starts[idx]\n",
        "        images = [add_caption2image(im, rec['prompt']) for im in images]\n",
        "\n",
        "    # to do: persist the ordering in the storyboard\n",
        "    if optimal_ordering:\n",
        "        images = batched_tsp_permute_frames(\n",
        "            images,\n",
        "            #max_variations_per_opt_pass\n",
        "            opt_batch_size\n",
        "        )\n",
        "    return images\n",
        "\n",
        "############################\n",
        "\n",
        "cmd_in = ['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-']\n",
        "cmd_out = ['-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '1', '-preset', 'veryslow', '-shortest', output_filename]\n",
        "\n",
        "if input_audio:\n",
        "  cmd_in += ['-i', str(input_audio)]\n",
        "\n",
        "# NB: it might be more efficient to perform this upscaling step as a \n",
        "# separate step after compiling the video frames\n",
        "if upscale:\n",
        "    height=storyboard.params.height\n",
        "    width=storyboard.params.width\n",
        "    cmd_out = ['-vf', f'scale={2*width}x{2*height}:flags=lanczos'] + cmd_out\n",
        "\n",
        "\n",
        "cmd = cmd_in + cmd_out\n",
        "\n",
        "prompt_starts = storyboard.prompt_starts\n",
        "batch_gen = BackgroundGenerator(\n",
        "    [(idx, rec, process_sequence(idx))\n",
        "        for idx, rec in enumerate(prompt_starts)]\n",
        "    ,max_prefetch=2)\n",
        "\n",
        "p = Popen(cmd, stdin=PIPE)\n",
        "for idx, rec, batch in tqdm(batch_gen, total=len(prompt_starts)): \n",
        "    frame_factory = cycle(batch)\n",
        "    k = 0\n",
        "    while k < rec['frames']:\n",
        "        im = next(frame_factory)\n",
        "        im.save(p.stdin, 'png')\n",
        "        k+=1\n",
        "p.stdin.close()\n",
        "\n",
        "print(\"Encoding video...\")\n",
        "p.wait()\n",
        "\n",
        "if output_filename != final_output_filename:\n",
        "    print(f\"Local video compilation complete. Moving video to: {final_output_filename}\")\n",
        "    shutil.move(output_filename, final_output_filename)\n",
        "print(\"Video complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBqICfHP896f",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#!ffmpeg -y -f image2pipe -vcodec png -r 30 -i input_audio -vcodec libx264 -r str(fps) -pix_fmt yuv420p -crf 1 -preset veryslow -shortest output_filename"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mgXxoDhMAiti",
        "sM147HP4kAdY",
        "rt9Mu97fk_bp",
        "7eTPNhcBomtL",
        "MV8RqARZ4UPI",
        "ByGXyiHZWM_q",
        "UA8-efH-WM_t",
        "6JxwhBwtWM_t",
        "gJ88kZ2-WM_v",
        "gzqhU6rufVr7",
        "16oOlkttT98d",
        "Vne-az6HUPvP",
        "xg0BjqbpmqeM",
        "Za124iWvdMsZ",
        "ml6wOhwqhGiI",
        "QjindPTItq75",
        "_yJ90ESZiT_S",
        "FUyhiJg03dj6",
        "_l1Gd2SStt0E",
        "C4NOldY83wG1",
        "m2jmbSD430Ws",
        "DOJ3miW63ywA",
        "Az25TPUDjT2l",
        "KYbcutcI_Jxx",
        "G0WUG_Bc_Jx4",
        "5o3SMIo1_Jx7",
        "Ze7wd_pY_Jx8",
        "_dyA_gsQ_Jx9",
        "d6vJsJ0U_Jx_",
        "HzwO6qQNHA28",
        "6LWsNd3_M3MP",
        "FAqrSIWgLyP0",
        "Ku-dA4DKoeXk",
        "_ZuDrj_ioqHE",
        "Zlgi8fPdpRF0",
        "ZksegYQepkFg",
        "Ws_YkPKsLgo-",
        "rVTf7aSpdPmP",
        "0cKdTCuv4tXh",
        "IYtWMzOvLQ3s",
        "BDg_jiQ9adQe",
        "JuVn21kt40Gw",
        "hqwOlJG4MdLC",
        "tUNVcbujhm00",
        "WTuyUxgdLA13",
        "avAcSL_uvtq_",
        "R0wWe_VO4I79",
        "KI8VGHi6c4QK",
        "QOf2K0Qec4QT",
        "UtuXdJi6c4QU",
        "WIH-fYcoc4QW",
        "GdIFOSyAc4QW",
        "yrNwqctec4QZ",
        "qUUWd0FDc4QI",
        "aVu_TleBiHhY",
        "_RTUFeyQqCfd"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMyGegQRXLPW/AkKoWfNL8W",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}